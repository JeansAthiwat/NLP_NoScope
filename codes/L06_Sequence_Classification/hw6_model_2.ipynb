{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8FRFIYMc5X"
      },
      "source": [
        "# HOMEWORK 6: TEXT CLASSIFICATION\n",
        "In this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n",
        "1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancle)\n",
        "2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming)\n",
        "\n",
        "We will focus only on the Object Classification task for this homework.\n",
        "\n",
        "In this homework, you are asked compare different text classification models in terms of accuracy and inference time.\n",
        "\n",
        "You will need to build 3 different models.\n",
        "\n",
        "1. A model based on tf-idf\n",
        "2. A model based on MUSE\n",
        "3. A model based on wangchanBERTa\n",
        "\n",
        "**You will be ask to submit 3 different files (.pdf from .ipynb) that does the 3 different models. Finally, answer the accuracy and runtime numbers in MCV.**\n",
        "\n",
        "This homework is quite free form, and your answer may vary. We hope that the processing during the course of this assignment will make you think more about the design choices in text classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRlx5Mb5zkXw",
        "outputId": "18d913e0-aa6d-435b-931d-591386cb4ba8"
      },
      "outputs": [],
      "source": [
        "# !wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv\n",
        "# !pip install pythainlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YprqbOPMc5a"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "heICP79cMc5e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from IPython.display import display\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#My import \n",
        "np.random.seed(42)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaUf4PLMc5k"
      },
      "source": [
        "## Loading cleaned dataset from my folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('template_cleaned_dataset.pkl', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "# Extract tokenized text and labels\n",
        "label_2_num_map, num_2_label_map = dataset[\"label_2_num_map\"], dataset[\"num_2_label_map\"]\n",
        "train_texts, train_labels = dataset[\"train\"][\"input\"], dataset[\"train\"][\"label\"]\n",
        "val_texts, val_labels = dataset[\"val\"][\"input\"], dataset[\"val\"][\"label\"]\n",
        "test_texts, test_labels = dataset[\"test\"][\"input\"], dataset[\"test\"][\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wql2YeU8qFQ6"
      },
      "source": [
        "# Model 2 MUSE\n",
        "\n",
        "Build a simple logistic regression model using features from the MUSE model.\n",
        "\n",
        "Which MUSE model will you use? Why?\n",
        "\n",
        "**Ans:** \n",
        "\n",
        "- I use sentence-transformers/use-cmlm-multilingual. as there are more likes and the other one doesn't have native support for hugging face.\n",
        "\n",
        "MUSE is typically used with tensorflow. However, there are some pytorch conversions made by some people.\n",
        "\n",
        "- https://huggingface.co/sentence-transformers/use-cmlm-multilingual\n",
        "- https://huggingface.co/dayyass/universal-sentence-encoder-multilingual-large-3-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libs for MUSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d3UtkpaLnctH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ตาม', 'ค่อนมาทาง', 'เคยๆ', 'ในช่วง', 'แต่', 'ด้วยเช่นกัน', 'มีแต่', 'เช่นไร', 'ไม่ค่อยเป็น', 'จำเป็น', 'ด้วยเหตุว่า', 'รึว่า', 'ถ้าจะ', 'เสร็จ', 'แห่งไหน', 'กันเถอะ', 'ยิ่ง', 'นอกนั้น', 'ทําให้', 'แล้วแต่', 'ประมาณ', 'จึงจะ', 'ใต้', 'ตลอดถึง', 'ถูกๆ', 'รวด', 'ยิ่งขึ้นไป', 'ได้ที่', 'เพียงพอ', 'เพิ่งจะ', 'ถูก', 'เอง', 'แก้ไข', 'จัดแจง', 'เดียวกัน', 'นี่แหละ', 'คุณ', 'ตลอดกาล', 'นี่เอง', 'เสียจนกระทั่ง', 'ใครๆ', 'ตลอดไป', 'มาก', 'ทุกแห่ง', 'ครา', 'จวบ', 'เสีย', 'อย่างน้อย', 'ต่างๆ', 'ตลอดระยะเวลา', 'ที่แท้', 'เล็กๆ', 'ขวางๆ', 'เพียงแต่', 'ทุกวันนี้', 'อาจ', 'เมื่อ', 'ยิ่งจน', 'เพียงไร', 'ถึงเมื่อใด', 'ครั้งไหน', 'ใหญ่', 'ทุกที', 'ดั่ง', 'เป็นแต่', 'ภายใน', 'เช่นดังว่า', '\\ufeffๆ', 'ทั้งนั้น', 'กลุ่ม', 'บัดดล', 'ถ้าหาก', 'เถิด', 'เพราะว่า', 'นับจากนี้', 'ตลอดวัน', 'เช่นดัง', 'ใคร', 'ประการ', 'สุด', 'นิดหน่อย', 'รือ', 'แต่เมื่อ', 'ราย', 'กันไหม', 'ลง', 'ก็ต่อเมื่อ', 'พยายาม', 'เปิด', 'จึง', 'ของ', 'พูด', 'ก็แค่', 'เมื่อไร', 'ภายภาคหน้า', 'คราไหน', 'พอ', 'ทีละ', 'ครัน', 'ยัง', 'ทุกที่', 'บัดนั้น', 'เห็นควร', 'เป็นต้นมา', 'ช่วงระหว่าง', 'จังๆ', 'ตลอดทั่วถึง', 'ส่วนที่', 'ได้แต่', 'เสมือนกับ', 'โดย', 'เพียง', 'เผื่อว่า', 'ให้ดี', 'แสดง', 'ใช้', 'จากนี้', 'วันนี้', 'คะ', 'ก่อนหน้านี้', 'ต่อกัน', 'ตามที่', 'สูงๆ', 'เป็น', 'ภาย', 'เช่นนี้', 'กว้างขวาง', 'เมื่อเย็น', 'นับแต่นี้', 'เมื่อคราว', 'ขณะเดียวกัน', 'กันและกัน', 'นี้', 'นี่แน่ะ', 'เสียจนถึง', 'แม้นว่า', 'กลุ่มก้อน', 'นาย', 'ด้วยกัน', 'เท่าไหร่', 'เป็นเพื่อ', 'เพียงใด', 'ทำให้', 'ยังคง', 'ที่ไหน', 'ยาก', 'ยิ่งขึ้น', 'เพิ่มเติม', 'จริงๆ', 'เท่านั้น', 'ครั้งหลังสุด', 'วันนั้น', 'ช่วงนี้', 'เฉยๆ', 'สุดๆ', 'ฉะนั้น', 'มี', 'ถ้า', 'สูง', 'กระทำ', 'เสร็จแล้ว', 'พวกคุณ', 'เป็นเพียงว่า', 'หมดกัน', 'อีก', 'ฉะนี้', 'ก็แล้วแต่', 'โต', 'แล้วเสร็จ', 'นํา', 'พวก', 'ยังโง้น', 'นั้นๆ', 'เกินๆ', 'เช่นเดียวกับ', 'เป็นอัน', 'ล้วน', 'หลังจาก', 'แท้', 'จนแม้', 'ส่วนใด', 'ออก', 'เช่นดังที่', 'มุ่งเน้น', 'จนเมื่อ', 'เกิน', 'เสียด้วย', 'ย่อม', 'ยิ่งใหญ่', 'คล้ายว่า', 'จัดการ', 'และ', 'ครบถ้วน', 'มั้ยนะ', 'เกี่ยวกัน', 'หรือ', 'เท่าที่', 'ทั้งหลาย', 'คราวนั้น', 'เสมือนว่า', 'ทีเถอะ', 'แค่ไหน', 'อย่างมาก', 'นำ', 'ที่', 'ต้อง', 'ซึ่งกัน', 'สิ่งนี้', 'เผื่อที่', 'ทันใดนั้น', 'ถึงอย่างไร', 'นับแต่', 'อันที่จะ', 'อันใด', 'ทีๆ', 'ค่อย', 'ช้า', 'ครั้งที่', 'ล่าสุด', 'เสร็จกัน', 'ยิ่งจะ', 'นอกจาก', 'ตลอดปี', 'เมื่อเช้า', 'เช่นที่', 'อย่างยิ่ง', 'เสียก่อน', 'แม้แต่', 'ในเมื่อ', 'แต่ต้อง', 'เช่นก่อน', 'ได้', 'ฝ่าย', 'เอ็ง', 'เช่นกัน', 'จวบจน', 'คิดว่า', 'ซึ่งกันและกัน', 'ทั้ง', 'ด้วยประการฉะนี้', 'จัดตั้ง', 'รวมถึง', 'คราวหลัง', 'นั่นไง', 'ทุกคราว', 'หนอย', 'ช่วงนั้น', 'ช่วงแรก', 'ปัจจุบัน', 'พร้อมที่', 'เป็นด้วย', 'นับ', 'จัดหา', 'ได้รับ', 'ระหว่าง', 'แต่ก่อน', 'มา', 'พร้อมทั้ง', 'นำพา', 'คล้ายกัน', 'นอกจากที่', 'เป็นต้นไป', 'ที่แห่งนั้น', 'ครั้งใด', 'หรือเปล่า', 'ยอม', 'ทีไร', 'ขึ้น', 'ส่วนด้อย', 'ครั้งครา', 'แต่อย่างใด', 'ด้วย', 'จู่ๆ', 'ทันทีทันใด', 'ครั้งหนึ่ง', 'คล้ายกับว่า', 'นี่นา', 'จัดให้', 'พอๆ', 'กันดีกว่า', 'ใหม่', 'พวกเขา', 'วันใด', 'ตลอดทั่วทั้ง', 'ซึ่ง', 'จรด', 'มองว่า', 'เป็นที', 'เสียยิ่ง', 'ช้านาน', 'คล้ายกับ', 'ครานั้น', 'ฯลฯ', 'แต่ละ', 'แต่จะ', 'ต่อ', 'พวกนี้', 'เหตุนั้น', 'ดั่งกับว่า', 'ทั้งคน', 'เมื่อคราวที่', 'เนี่ยเอง', 'ก็จะ', 'แค่ว่า', 'ซะจนถึง', 'ตรงๆ', 'อันได้แก่', 'คราใด', 'เดียว', 'รวมทั้ง', 'เหตุนี้', 'ถึงบัดนี้', 'เช่นที่ว่า', 'ดังกับว่า', 'นับจากนั้น', 'เสร็จสมบูรณ์', 'กัน', 'เมื่อวันวาน', 'เหตุ', 'เพิ่ม', 'คราวที่', 'ซะ', 'มิได้', 'ด้วยว่า', 'เถอะ', 'เริ่ม', 'พอสมควร', 'ทั้งตัว', 'ค่ะ', 'นิดๆ', 'คงอยู่', 'กันดีไหม', 'หรือยัง', 'เปลี่ยน', 'อย่างนี้', 'กว่า', 'ส่วนมาก', 'นอกจากนั้น', 'ยืนยาว', 'ไป่', 'น้อย', 'เป็นแต่เพียง', 'วัน', 'พอจะ', 'เสียนี่กระไร', 'ถึงบัดนั้น', 'อดีต', 'อันละ', 'เยอะแยะ', 'ด้วยเหมือนกัน', 'นู้น', 'รวม', 'เสียนั่นเอง', 'สําหรับ', 'ให้', 'ตลอดมา', 'กลับ', 'นอกเหนือจาก', 'การ', 'ค่อยๆ', 'ช่วงต่อไป', 'ด้วยเหตุนี้', 'อันจะ', 'คราวหนึ่ง', 'ตน', 'คำ', 'ยังงี้', 'นั่นแหละ', 'เพียงแค่', 'คง', 'ทำๆ', 'คุณๆ', 'โตๆ', 'เสียนั่น', 'จวนจะ', 'ปรากฏ', 'คราวโน้น', 'ดังเคย', 'จึงเป็น', 'เป็นอาทิ', 'เพียงไหน', 'ยก', 'ในระหว่าง', 'ไว้', 'ยิ่งแล้ว', 'ตั้ง', 'ในที่', 'ที่ว่า', 'บน', 'ข้างเคียง', 'ส่วนนั้น', 'แห่งนี้', 'อัน', 'ด้วยเพราะ', 'เพื่อที่จะ', 'รับ', 'สั้นๆ', 'เห็นว่า', 'เพื่อว่า', 'ใหญ่ๆ', 'ใคร่จะ', 'ค่อยไปทาง', 'นอกเหนือ', 'ถึงแม้ว่า', 'ทั้งๆ', 'รือว่า', 'เหตุไร', 'ทาง', 'ประกอบ', 'พวกที่', 'ร่วมมือ', 'ชาว', 'เต็มๆ', 'เสียแล้ว', 'กำลังจะ', 'ตนเอง', 'บางครั้ง', 'ผู้ใด', 'อย่างๆ', 'มิฉะนั้น', 'พร้อม', 'คงจะ', 'นะ', 'ควร', 'เป็นเพราะ', 'แห่งโน้น', 'ครั้งคราว', 'ตลอดเวลา', 'คิด', 'มั้ย', 'จริงจัง', 'ทุกครั้ง', 'แค่เพียง', 'อย่างไรเสีย', 'สิ่งใด', 'แค่จะ', 'เป็นอันมาก', 'ทุกคน', 'ล้วนจน', 'เท่านี้', 'พร้อมด้วย', 'อื่น', 'สิ้น', 'ยังงั้น', 'บางๆ', 'หาความ', 'ครบครัน', 'พอดี', 'จนตลอด', 'เมื่อนี้', 'ทุก', 'ทั้งสิ้น', 'นอกจากว่า', 'แต่ก็', 'ถึงแก่', 'ใดๆ', 'คราหนึ่ง', 'เฉกเช่น', 'ไม่ใช่', 'ระยะๆ', 'เน้น', 'หนอ', 'เมื่อคืน', 'อยู่', 'นาน', 'ถือว่า', 'ทุกชิ้น', 'พอกัน', 'พึ่ง', 'ทั้งนั้นเพราะ', 'ถึงเมื่อไร', 'พวกนั้น', 'คราว', 'เสียจน', 'บ่อยครั้ง', 'ค่อนข้างจะ', 'เพียงเพื่อ', 'เชื่อว่า', 'อย่างไรก็ได้', 'เพื่อ', 'ถือ', 'ต่างก็', 'แม้', 'เมื่อใด', 'ข้า', 'ที่ใด', 'ตนฯ', 'นอก', 'ประการใด', 'ช้าๆ', 'ไร', 'อย่างดี', 'ไกล', 'แต่ไหน', 'เหล่านี้', 'เขา', 'จริง', 'พบว่า', 'แสดงว่า', 'ครั้งนี้', 'นิด', 'จนถึง', 'ส่วนน้อย', 'เนื่องจาก', 'ใกล้', 'พื้นๆ', 'มากกว่า', 'สิ่ง', 'ซึ่งก็', 'ได้แก่', 'เยอะๆ', 'ร่วม', 'นี้เอง', 'ไหน', 'พวกเธอ', 'ที่แล้ว', 'คราวๆ', 'สมัย', 'บอกแล้ว', 'คล้ายกันกับ', 'หากแม้น', 'เล่าว่า', 'กว้างๆ', 'สมัยก่อน', 'ครั้งก่อน', 'จนกว่า', 'จนกระทั่ง', 'นั่นเอง', 'อันที่จริง', 'ฯ', 'เช่นดังเก่า', 'หน่อย', 'ตามแต่', 'ช่วย', 'เมื่อวาน', 'คราวนี้', 'คราวละ', 'แต่ทว่า', 'ต่าง', 'เปิดเผย', 'ถึงแม้', 'กระผม', 'จำพวก', 'แค่นั้น', 'ตามด้วย', 'ใช่', 'เกี่ยวๆ', 'อย่าง', 'ได้มา', 'มักจะ', 'หารือ', 'ที่นี้', 'ทุกหน', 'ไม่ว่า', 'สูงกว่า', 'ยิ่งนัก', 'วันไหน', 'นี่', 'มิ', 'ทั้งมวล', 'นำมา', 'หมดสิ้น', 'เหลือเกิน', 'จ้ะ', 'คราวใด', 'เราๆ', 'ครับ', 'ส่ง', 'กับ', 'ดังกับ', 'ครั้งหลัง', 'สมัยนี้', 'เป็นดัง', 'สบาย', 'ดังเก่า', 'แท้จริง', 'ขณะที่', 'เป็นที่', 'ช่วงท้าย', 'ค่อนข้าง', 'ไม่ค่อย', 'อย่างนั้น', 'ทั่ว', 'แต่เพียง', 'ตรง', 'นู่น', 'ต่างหาก', 'ภายนอก', 'ใหญ่โต', 'ทั้งที่', 'อย่างไร', 'ครั้งกระนั้น', 'ข้างต้น', 'เร็วๆ', 'ส่วนเกิน', 'เรื่อยๆ', 'ยอมรับ', 'เช่นเคย', 'นักๆ', 'อย่างที่', 'มัน', 'หลัง', 'แยะๆ', 'จัดทำ', 'เรื่อย', 'ช่วงที่', 'ใกล้ๆ', 'ผิดๆ', 'ช่วงหน้า', 'ไป', 'ขณะนั้น', 'ที่ละ', 'ตลอดทั่ว', 'สิ้นกาลนาน', 'อย่างเดียว', 'ขวาง', 'แค่นี้', 'อย่างไหน', 'ทำไร', 'เสร็จสิ้น', 'กันนะ', 'หลาย', 'แล้วกัน', 'แห่ง', 'รับรอง', 'เข้าใจ', 'เธอ', 'อย่างใด', 'ยิ่งเมื่อ', 'น้อยๆ', 'ตั้งแต่', 'แก่', 'ยาว', 'พวกมัน', 'จนบัดนี้', 'บัดเดี๋ยวนี้', 'จำ', 'เป็นที่สุด', 'แก', 'เมื่อครั้ง', 'บ่อยกว่า', 'อาจเป็น', 'เป็นต้น', 'พร้อมเพียง', 'ใคร่', 'ภาคฯ', 'ยังไง', 'กระทั่ง', 'ข้างๆ', 'ช่วงถัดไป', 'ยืนยัน', 'นี้แหล่', 'รวดเร็ว', 'บางที', 'สิ่งนั้น', 'จาก', 'แหละ', 'พอตัว', 'เช่นที่เคย', 'ว่า', 'ขณะใด', 'อันๆ', 'ทุกทาง', 'เมื่อคราวก่อน', 'อยาก', 'จะได้', 'ยืนนาน', 'ซึ่งๆ', 'เกือบๆ', 'ไม่เป็นไร', 'เหล่า', 'สูงสุด', 'ข้าง', 'เกี่ยวกับ', 'เป็นการ', 'ปรากฏว่า', 'เกี่ยวเนื่อง', 'ตลอดทั้ง', 'ก็', 'ข้าพเจ้า', 'บางขณะ', 'อาจเป็นด้วย', 'ง่าย', 'เป็นอันๆ', 'บ่อย', 'แห่งนั้น', 'เล็ก', 'ช่วง', 'พวกมึง', 'เหตุผล', 'จัดงาน', 'เช่นดังก่อน', 'อันที่', 'เช่นใด', 'แต่ที่', 'ซึ่งได้แก่', 'ผล', 'ด้วยที่', 'คือ', 'สั้น', 'ส่วนใหญ่', 'มุ่ง', 'คราวหน้า', 'ที่จริง', 'อย่างละ', 'จับ', 'มั้ยนั่น', 'ทุกๆ', 'ข้างบน', 'ภาค', 'เป็นอันว่า', 'กำลัง', 'บอกว่า', 'ให้ไป', 'เกี่ยวข้อง', 'น่ะ', 'เนี่ย', 'ทว่า', 'พร้อมกับ', 'เผื่อ', 'บางคราว', 'จง', 'คราที่', 'ขอ', 'บัดนี้', 'น่า', 'ละ', 'พบ', 'มั้ยล่ะ', 'แต่เดิม', 'กู', 'ทัน', 'ช่วงๆ', 'หรือไง', 'เชื่อถือ', 'ขั้น', 'ฝ่ายใด', 'ทีใด', 'ไหนๆ', 'เพียงเพราะ', 'คราวไหน', 'มุ่งหมาย', 'จัง', 'เพราะฉะนั้น', 'จ๋า', 'ตลอดจน', 'ทั้งเป็น', 'ส่วน', 'พอเหมาะ', 'บางกว่า', 'หรือไม่', 'ที', 'ค่อน', 'ก่อน', 'ผ่าน', 'ทุกเมื่อ', 'มันๆ', 'ขาด', 'ที่สุด', 'เก็บ', 'นั่นเป็น', 'เยอะ', 'ที่ได้', 'เกือบจะ', 'ที่ๆ', 'พวกนู้น', 'บางแห่ง', 'จน', 'ตลอดกาลนาน', 'เช่นเมื่อ', 'เป็นๆ', 'ให้มา', 'เมื่อก่อน', 'ถูกต้อง', 'ด้าน', 'แล้ว', 'เพิ่ง', 'อย่างโน้น', 'ก็ตามที', 'มัก', 'ไง', 'จวน', 'ซึ่งก็คือ', 'อะไร', 'พอแล้ว', 'ดั่งเคย', 'กล่าว', 'ก่อนๆ', 'อาจจะ', 'หากว่า', 'ทั้งปวง', 'ณ', 'นับแต่ที่', 'เชื่อมั่น', 'ตลอด', 'เข้า', 'กำหนด', 'กันเอง', 'ด้วยเหตุเพราะ', 'ยังแต่', 'จากนั้น', 'ทุกครา', 'ให้แก่', 'ถึงจะ', 'ทีเดียว', 'เฉย', 'เพื่อที่', 'หมด', 'ระยะ', 'เท่ากัน', 'คราวก่อน', 'อันไหน', 'ซะจนกระทั่ง', 'เชื่อ', 'เห็น', 'ทุกสิ่ง', 'หากแม้นว่า', 'ไกลๆ', 'ผิด', 'เท่าใด', 'นับตั้งแต่', 'ประการหนึ่ง', 'บอก', 'มั้ยเนี่ย', 'ข้าฯ', 'ที่นั้น', 'ไม่ค่อยจะ', 'ขณะใดๆ', 'จากนี้ไป', 'ครั้งๆ', 'เป็นเพราะว่า', 'เคย', 'เฉพาะ', 'แต่ว่า', 'พอสม', 'มากมาย', 'ผ่านๆ', 'ทรง', 'นานๆ', 'เร็ว', 'รวมกัน', 'สูงส่ง', 'เรา', 'ทุกอย่าง', 'พอที่', 'นางสาว', 'อย่างหนึ่ง', 'ทุกอัน', 'หนึ่ง', 'เสียนี่', 'ภายหลัง', 'ทำไม', 'หาใช่', 'ทั้งนี้', 'แยะ', 'แบบ', 'ยืนยง', 'ที่แท้จริง', 'เผื่อจะ', 'นับแต่นั้น', 'น้อยกว่า', 'จด', 'เพื่อให้', 'เช่นนั้น', 'จ้า', 'ช่วงหลัง', 'เกิด', 'ภายภาค', 'สิ่งไหน', 'เช่นเดียวกัน', 'ทันที', 'เห็นแก่', 'พวกกัน', 'ดัง', 'ง่ายๆ', 'ตลอดศก', 'ฯล', 'พร้อมกัน', 'นั้นไว', 'ส่วนดี', 'พวกกู', 'นั่น', 'ทุกตัว', 'มิใช่', 'มึง', 'บ้าง', 'เขียน', 'บางที่', 'ยาวนาน', 'ครั้งนั้น', 'สามารถ', 'ก็ดี', 'ให้แด่', 'ฉัน', 'จวนเจียน', 'ใหม่ๆ', 'ด้วยเหตุนั้น', 'อนึ่ง', 'เกือบ', 'กระนั้น', 'กล่าวคือ', 'เท่า', 'สืบเนื่อง', 'แม้กระทั่ง', 'ทั้งหมด', 'เต็มไปหมด', 'มอง', 'เรียบ', 'ครบ', 'ดั่งกับ', 'อย่างไรก็', 'ขณะหนึ่ง', 'แรก', 'เปลี่ยนแปลง', 'ยิ่งกว่า', 'ก็คือ', 'จนทั่ว', 'ไม่', 'เท่ากับ', 'ร่วมกัน', 'ทั้งนั้นด้วย', 'ก็ได้', 'ครั้งละ', 'แต่ถ้า', 'แต่นั้น', 'นาง', 'เสียยิ่งนัก', 'ซะก่อน', 'ดังกล่าว', 'เพราะ', 'ความ', 'พวกฉัน', 'จนขณะนี้', 'สมัยโน้น', 'เช่นนั้นเอง', 'บาง', 'ตามๆ', 'แห่งใด', 'เล็กน้อย', 'เห็นจะ', 'ประการฉะนี้', 'ใน', 'เมื่อครั้งก่อน', 'ข้างล่าง', 'เป็นเพียง', 'แค่', 'เท่าไร', 'ปฏิบัติ', 'พอเพียง', 'เหลือ', 'ด้วยเหตุที่', 'พอควร', 'ร่วมด้วย', 'รวมด้วย', 'จะ', 'นั้น', 'ภายหน้า', 'ๆ', 'ล้วนแต่', 'บางครา', 'ขณะนี้', 'เรียก', 'ช่วงก่อน', 'ภายใต้', 'เหล่านั้น', 'พอที', 'รึ', 'ถึง', 'ก่อนหน้า', 'กลุ่มๆ', 'เมื่อไหร่', 'ปรับ', 'อย่างเช่น', 'จรดกับ', 'ทุกวัน', 'ยังจะ', 'ก็ตามแต่', 'ย่อย', 'ดั่งเก่า', 'ถึงแม้จะ', 'ขณะ', 'ทํา', 'หน', 'พวกแก', 'น่าจะ', 'ซะจน', 'นอกจากนี้', 'ถึงเมื่อ', 'ไฉน', 'ครั้ง', 'กว้าง', 'หาก', 'ครานี้', 'พวกท่าน', 'พวกโน้น', 'รวมๆ', 'แต่ไร', 'มั๊ย', 'แม้ว่า', 'พึง', 'พา', 'ที่ซึ่ง', 'จริงๆจังๆ', 'นัก', 'สู่', 'คล้าย', 'ทั้งที', 'ยกให้', 'จวบกับ', 'บ่อยๆ', 'อื่นๆ', 'ผู้', 'เลย', 'อันเนื่องมาจาก', 'นี่ไง', 'จ๊ะ', 'หากแม้', 'จนแม้น', 'สำคัญ', 'ปิด', 'สมัยนั้น', 'เมื่อนั้น', 'ก็ตาม', 'ประสบ', 'หรือไร', 'เอา', 'เต็มไปด้วย', 'เช่น', 'ใช่ไหม', 'จัด'}\n"
          ]
        }
      ],
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.corpus.common import thai_stopwords\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(set(thai_stopwords()))\n",
        "\n",
        "MODEL_NAME = 'sentence-transformers/use-cmlm-multilingual'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initializing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at sentence-transformers/use-cmlm-multilingual were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SentenceTransformer(\n",
              "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
              "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
              "  (2): Normalize()\n",
              ")"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SentenceTransformer('sentence-transformers/use-cmlm-multilingual')\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.01540179 -0.02176822 -0.01264849 ...  0.05045101 -0.02573791\n",
            "   0.01540428]\n",
            " [ 0.00617291 -0.01532528 -0.03717829 ...  0.02221827 -0.02915066\n",
            "  -0.09352502]]\n"
          ]
        }
      ],
      "source": [
        "sentences = [\"This is an example sentence\", \"Each sentence is converted\"]\n",
        "\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "def encode_split(texts, model=model):\n",
        "    embeddings = model.encode(texts)\n",
        "    return embeddings\n",
        "\n",
        "emb_train = encode_split(train_texts)\n",
        "emb_val = encode_split(val_texts)\n",
        "emb_test = encode_split(test_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((10710, 768), (1339, 768), (1340, 768))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "emb_train.shape, emb_val.shape, emb_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build simple logistic regression model grid search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    \"C\": [0.01, 0.1, 1, 10],\n",
        "    \"penalty\": [\"l1\", \"l2\"],\n",
        "    \"solver\": [\"liblinear\"]\n",
        "}\n",
        "\n",
        "# Initialize the GridSearchCV object\n",
        "grid_search = GridSearchCV( estimator=LogisticRegression(max_iter=1000, class_weight=\"balanced\"), \n",
        "                            param_grid=param_grid, \n",
        "                            cv=5, \n",
        "                            n_jobs=-1, \n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=  15.0s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=  15.1s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=  15.7s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=  15.8s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=  16.1s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  25.2s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  26.0s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  26.1s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  27.5s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=  27.7s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=  39.7s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=  39.9s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=  42.3s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=  42.5s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=  43.2s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  59.6s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  57.2s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  58.4s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=  59.2s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time= 1.0min\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time= 1.1min\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time= 1.0min\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time= 1.0min\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time= 1.0min\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time= 1.1min\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time= 1.5min\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time= 1.5min\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time= 1.5min\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time= 1.5min\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time= 1.5min\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time= 1.8min\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time= 1.8min\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time= 1.7min\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time= 1.7min\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time= 1.7min\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 3.4min\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 3.2min\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 3.0min\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 3.0min\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time= 3.0min\n"
          ]
        }
      ],
      "source": [
        "# Fit the GridSearchCV object on the training data\n",
        "grid_search.fit(emb_train, train_labels)\n",
        "\n",
        "# get the best model\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=10, class_weight='balanced', max_iter=1000,\n",
              "                   solver='liblinear')"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.6915608663181478\n",
            "Test Accuracy: 0.6828358208955224\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        payment       0.58      0.77      0.66        64\n",
            "        package       0.70      0.57      0.63       180\n",
            "        suspend       0.72      0.75      0.74        73\n",
            "       internet       0.71      0.75      0.73       179\n",
            "   phone_issues       0.63      0.67      0.65        58\n",
            "        service       0.85      0.65      0.74       211\n",
            "    nontruemove       0.36      0.48      0.41        25\n",
            "        balance       0.88      0.77      0.82       149\n",
            "         detail       0.29      0.42      0.34        33\n",
            "           bill       0.66      0.69      0.67        54\n",
            "         credit       0.83      0.88      0.86        17\n",
            "      promotion       0.69      0.69      0.69       115\n",
            " mobile_setting       0.40      0.50      0.44        28\n",
            "       iservice       0.33      0.50      0.40         2\n",
            "        roaming       0.76      0.76      0.76        25\n",
            "      truemoney       0.82      0.72      0.77        25\n",
            "    information       0.49      0.70      0.58        30\n",
            "    lost_stolen       0.72      0.91      0.81        23\n",
            "balance_minutes       0.29      0.40      0.33         5\n",
            "            idd       0.83      0.75      0.79        20\n",
            "        garbage       0.10      0.20      0.13         5\n",
            "       ringtone       0.60      0.75      0.67         8\n",
            "           rate       0.11      0.33      0.17         3\n",
            "   loyalty_card       0.75      1.00      0.86         6\n",
            "        contact       0.00      0.00      0.00         1\n",
            "        officer       0.00      0.00      0.00         1\n",
            "\n",
            "       accuracy                           0.68      1340\n",
            "      macro avg       0.54      0.60      0.56      1340\n",
            "   weighted avg       0.71      0.68      0.69      1340\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the best model on the validation data\n",
        "val_preds = best_model.predict(emb_val)\n",
        "val_acc = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_acc)\n",
        "\n",
        "test_preds = best_model.predict(emb_test)\n",
        "test_acc = accuracy_score(test_labels, test_preds)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "\n",
        "# Generate classification report on test data\n",
        "print(classification_report(test_labels, test_preds, target_names=num_2_label_map.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDHfX377rnp_"
      },
      "source": [
        "# Model 3 WangchanBERTa\n",
        "\n",
        "We ask you to train a WangchanBERTa-based model.\n",
        "\n",
        "We recommend you use the thaixtransformers fork (which we used in the PoS homework).\n",
        "https://github.com/PyThaiNLP/thaixtransformers\n",
        "\n",
        "The structure of the code will be very similar to the PoS homework. You will also find the huggingface [tutorial](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) useful. Or you can also add a softmax layer by yourself just like in the previous homework.\n",
        "\n",
        "Which WangchanBERTa model will you use? Why? (Don't forget to clean your text accordingly).\n",
        "\n",
        "**Ans:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI8SvILyub0m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D7qsVL0BaXS"
      },
      "source": [
        "After you"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr9_0DnMBcFZ"
      },
      "source": [
        "# Comparison\n",
        "\n",
        "After you have completed the 3 models, compare the accuracy, ease of implementation, and inference speed (from cleaning, tokenization, till model compute) between the three models in mycourseville."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
