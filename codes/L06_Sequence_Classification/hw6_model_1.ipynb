{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8FRFIYMc5X"
      },
      "source": [
        "# HOMEWORK 6: TEXT CLASSIFICATION\n",
        "In this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n",
        "1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancle)\n",
        "2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming)\n",
        "\n",
        "We will focus only on the Object Classification task for this homework.\n",
        "\n",
        "In this homework, you are asked compare different text classification models in terms of accuracy and inference time.\n",
        "\n",
        "You will need to build 3 different models.\n",
        "\n",
        "1. A model based on tf-idf\n",
        "2. A model based on MUSE\n",
        "3. A model based on wangchanBERTa\n",
        "\n",
        "**You will be ask to submit 3 different files (.pdf from .ipynb) that does the 3 different models. Finally, answer the accuracy and runtime numbers in MCV.**\n",
        "\n",
        "This homework is quite free form, and your answer may vary. We hope that the processing during the course of this assignment will make you think more about the design choices in text classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRlx5Mb5zkXw",
        "outputId": "18d913e0-aa6d-435b-931d-591386cb4ba8"
      },
      "outputs": [],
      "source": [
        "# !wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv\n",
        "# !pip install pythainlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YprqbOPMc5a"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "heICP79cMc5e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from IPython.display import display\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#My import \n",
        "np.random.seed(42)\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaUf4PLMc5k"
      },
      "source": [
        "## Loading data\n",
        "First, we load the data from disk into a Dataframe.\n",
        "\n",
        "A Dataframe is essentially a table, or 2D-array/Matrix with a name for each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JhZ2eBAWMc5l"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('clean-phone-data-for-students.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cje3yruTMc5p"
      },
      "source": [
        "Let's preview the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "aNqRNz1PMc5q",
        "outputId": "e129a502-1420-476c-dc50-46c293a01b56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>payment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>package</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n",
              "      <td>report</td>\n",
              "      <td>suspend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>internet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n",
              "      <td>report</td>\n",
              "      <td>phone_issues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Sentence Utterance   Action        Object\n",
              "0   <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire       payment\n",
              "1               internet ยังความเร็วอยุ่เท่าไหร ครับ  enquire       package\n",
              "2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   report       suspend\n",
              "3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...  enquire      internet\n",
              "4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   report  phone_issues"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show the top 5 rows\n",
        "display(data_df.head())\n",
        "# Summarize the data\n",
        "data_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGd8BNvMMc5y"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "We call the DataFrame.describe() again.\n",
        "Notice that there are 33 unique labels/classes for object and 10 unique labels for action that the model will try to predict.\n",
        "But there are unwanted duplications e.g. Idd,idd,lotalty_card,Lotalty_card\n",
        "\n",
        "Also note that, there are 13389 unqiue sentence utterances from 16175 utterances. You have to clean that too!\n",
        "\n",
        "## #TODO 0.1:\n",
        "You will have to remove unwanted label duplications as well as duplications in text inputs.\n",
        "Also, you will have to trim out unwanted whitespaces from the text inputs.\n",
        "This shouldn't be too hard, as you have already seen it in the demo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "V0bGLblVMc5z",
        "outputId": "1a65aff5-6196-4674-fb5d-36aa1afcfdba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
              "       'service', 'nonTrueMove', 'balance', 'detail', 'bill', 'credit',\n",
              "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
              "       'information', 'lost_stolen', 'balance_minutes', 'idd',\n",
              "       'TrueMoney', 'garbage', 'Payment', 'IDD', 'ringtone', 'Idd',\n",
              "       'rate', 'loyalty_card', 'contact', 'officer', 'Balance', 'Service',\n",
              "       'Loyalty_card'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['enquire', 'report', 'cancel', 'Enquire', 'buy', 'activate',\n",
              "       'request', 'Report', 'garbage', 'change'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(data_df.describe())\n",
        "display(data_df.Object.unique())\n",
        "display(data_df.Action.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "19onNNUZMc54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>clean_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13389</td>\n",
              "      <td>13389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       input clean_label\n",
              "count                                  13389       13389\n",
              "unique                                 13389          26\n",
              "top     สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ     service\n",
              "freq                                       1        2111"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO.1: Data cleaning\n",
        "\n",
        "# select only the columns that we need\n",
        "data_df = data_df[['Sentence Utterance', 'Object']]\n",
        "data_df.columns = ['input', 'raw_label']\n",
        "\n",
        "# remove duplicate labels\n",
        "data_df['clean_label'] = data_df['raw_label'].str.lower().copy()\n",
        "data_df.drop('raw_label', axis=1, inplace=True)\n",
        "\n",
        "# remove duplicate input rows\n",
        "data_df = data_df.drop_duplicates(\"input\", keep=\"first\")\n",
        "display(data_df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# map label to number and convert to numpy \"data\"\n",
        "data = data_df.to_numpy()\n",
        "unique_label = data_df.clean_label.unique()\n",
        "\n",
        "label_2_num_map = dict(zip(unique_label, range(len(unique_label))))\n",
        "num_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n",
        "\n",
        "# convert label to number\n",
        "data[:,1] = np.vectorize(label_2_num_map.get)(data[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input string cleaning\n",
        "def strip_str(string):\n",
        "    return string.strip()\n",
        "     \n",
        "# Trim of extra begining and trailing whitespace in the string\n",
        "data[:,0] = np.vectorize(strip_str)(data[:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Keep in mind class is imbalance type shi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIxnPRiAmrhN"
      },
      "source": [
        "Split data into train, valdation, and test sets (normally the ratio will be 80:10:10 , respectively). We recommend to use train_test_spilt from scikit-learn to split the data into train, validation, test set.\n",
        "\n",
        "In addition, it should split the data that distribution of the labels in train, validation, test set are similar. There is **stratify** option to handle this issue.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "Make sure the same data splitting is used for all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EYzMrvb7nYR2"
      },
      "outputs": [],
      "source": [
        "X = data[:,0]\n",
        "y = data[:,1]\n",
        "\n",
        "X_class_24, y_class_24 = X[y == 24], y[y == 24] #handle class 24 with only 4 samples\n",
        "X, y = X[y != 24], y[y != 24] # remove class 24 from the data to add it later\n",
        "\n",
        "random_idx = np.random.choice(len(X_class_24), 2, replace=False)\n",
        "\n",
        "X_class_24_val, X_class_24_test = X_class_24[random_idx[0]], X_class_24[random_idx[1]]\n",
        "y_class_24_val, y_class_24_test = y_class_24[random_idx[0]], y_class_24[random_idx[1]]\n",
        "\n",
        "X_class_24_train = np.delete(X_class_24, random_idx)\n",
        "y_class_24_train = np.delete(y_class_24, random_idx)\n",
        "\n",
        "# train val test split 80:10:10\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42)\n",
        "\n",
        "# add class 24 to the train, val, test set\n",
        "X_train, y_train = np.append(X_train, X_class_24_train), np.append(y_train, y_class_24_train)\n",
        "X_val, y_val = np.append(X_val, X_class_24_val), np.append(y_val, y_class_24_val)\n",
        "X_test, y_test = np.append(X_test, X_class_24_test), np.append(y_test, y_class_24_test)\n",
        "\n",
        "#check label distribution\n",
        "# display(np.unique(y_train, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['เดือนละ 150 บาทเล่นได้ทั้งวันหรือเปล่า', 'ครับ มีการชำระค่าบริการมาแล้ว ดูสัญญาณให้หน่อย', 'จ่ายค่าทรูมูฟค่ะ สัญญาณใช้ได้วันนี้เลยหรือเปล่าค่ะ', 'ขายบัตรทรูมันนี่ ที่ไหน', 'เมื่อคืนนี้ผมโทรมาแจ้งเรื่องโทรศัพท์หาไม่เจอ และระงับไว้ ตอนนี้เจอ อยู่ใต้เบาะรถ ต้องการเปิดสัญญาณการใช้งาน']\n",
            "[1, 0, 0, 15, 5]\n",
            "{'payment': 0, 'package': 1, 'suspend': 2, 'internet': 3, 'phone_issues': 4, 'service': 5, 'nontruemove': 6, 'balance': 7, 'detail': 8, 'bill': 9, 'credit': 10, 'promotion': 11, 'mobile_setting': 12, 'iservice': 13, 'roaming': 14, 'truemoney': 15, 'information': 16, 'lost_stolen': 17, 'balance_minutes': 18, 'idd': 19, 'garbage': 20, 'ringtone': 21, 'rate': 22, 'loyalty_card': 23, 'contact': 24, 'officer': 25}\n"
          ]
        }
      ],
      "source": [
        "def create_dataset_dict(dataset, data_split, split_name, keep_ws=False):\n",
        "    for input_str, label in data_split:\n",
        "        dataset[split_name][\"input\"].append(input_str)\n",
        "        dataset[split_name][\"label\"].append(label)\n",
        "\n",
        "dataset = { \"train\": {\"input\": [], \"label\": []},\n",
        "            \"val\": {\"input\": [], \"label\": []},\n",
        "            \"test\": {\"input\": [], \"label\": []} ,\n",
        "            'label_2_num_map': label_2_num_map,\n",
        "            'num_2_label_map': num_2_label_map\n",
        "            }\n",
        "\n",
        "create_dataset_dict(dataset, zip(X_train, y_train), \"train\")\n",
        "create_dataset_dict(dataset, zip(X_val, y_val), \"val\")\n",
        "create_dataset_dict(dataset, zip(X_test, y_test), \"test\")\n",
        "\n",
        "# save as pickle\n",
        "import pickle\n",
        "with open('template_cleaned_dataset.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset, f)\n",
        "\n",
        "print(dataset[\"train\"][\"input\"][:5])\n",
        "print(dataset[\"train\"][\"label\"][:5])\n",
        "print(dataset[\"label_2_num_map\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx6gllzrnVVU"
      },
      "source": [
        "# Model 1 TF-IDF\n",
        "\n",
        "Build a model to train a tf-idf text classifier. Use a simple logistic regression model for the classifier.\n",
        "\n",
        "For this part, you may find this [tutorial](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py) helpful.\n",
        "\n",
        "Below are some design choices you need to consider to accomplish this task. Be sure to answer them when you submit your model.\n",
        "\n",
        "What tokenizer will you use? Why?\n",
        "\n",
        "**Ans:** -> **\"newmm\"** . fast and efficient (Good enough acc on BEST test benchmark word level tokenization)\n",
        "\n",
        "Will you ignore some stop words (a, an, the, to, etc. for English) in your tf-idf? Is it important?\n",
        "PythaiNLP provides a list of stopwords if you want to use (https://pythainlp.org/docs/2.0/api/corpus.html#pythainlp.corpus.common.thai_stopwords)\n",
        "\n",
        "**Ans:** I will not ignore thai stop word. but instead use the TfidfVectorizer()'s 'max_df' to cut out too frequent words.\n",
        "\n",
        "The dictionary of TF-IDF is usually based on the training data. How many words in the test set are OOVs?\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "- Number of OOV words in validation set: 212\n",
        "- Number of OOV words in test set: 187\n",
        "- OOV ratio in validation set: 0.05898720089037284\n",
        "- OOV ratio in test set: 0.05203116304952699"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9vOqTqmfufsT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ฯล', 'ให้แด่', 'พอกัน', 'ประการ', 'มองว่า', 'ดั่งเคย', 'คงอยู่', 'เช่น', 'อย่างนี้', 'แท้', 'หรือไง', 'รึ', 'คิดว่า', 'สั้น', 'ฉะนั้น', 'ที่สุด', 'ล้วนจน', 'เล็กน้อย', 'มี', 'ง่ายๆ', 'ทั้งนี้', 'เมื่อครั้งก่อน', 'กว่า', 'ที่แล้ว', 'ยิ่งขึ้นไป', 'ข้างๆ', 'ความ', 'ใดๆ', 'ค่อยไปทาง', 'เป็นอันว่า', 'ถูกต้อง', 'เสียนั่น', 'จรดกับ', 'ภายหลัง', 'เมื่อเย็น', 'ทั้งมวล', 'นางสาว', 'เขียน', 'เท่าที่', 'ค่อย', 'สมัยก่อน', 'แม้แต่', 'คงจะ', 'บ่อยกว่า', 'ทว่า', 'รือว่า', 'ทุกแห่ง', 'ข้างล่าง', 'ให้แก่', 'น่า', 'ครั้งละ', 'ด้วยเหตุนี้', 'เหล่านั้น', 'ผิด', 'ใคร่', 'พอสม', 'จนแม้', 'เช่นก่อน', 'จริงๆ', 'เกือบๆ', 'ถือ', 'ส่วนที่', 'ปัจจุบัน', 'ช่วงๆ', 'เหล่า', 'อัน', 'นอกเหนือ', 'ภาค', 'ตลอด', 'นำมา', 'พวกที่', 'พร้อม', 'ส่วนมาก', 'ทุก', 'ซึ่ง', 'รับรอง', 'คล้ายกับว่า', 'วันนี้', 'ใหญ่ๆ', 'นัก', 'พวกเขา', 'ถ้า', 'ถือว่า', 'ตลอดกาล', 'พอๆ', 'ด้วยเหตุนั้น', 'อย่าง', 'เกือบ', 'ถ้าหาก', 'อันที่จะ', 'อย่างเช่น', 'เกี่ยวกับ', 'เกี่ยวเนื่อง', 'ก็ได้', 'ออก', 'นอกจากที่', 'มัน', 'แค่ไหน', 'พวกนี้', 'ตลอดศก', 'จัดการ', 'ที่นั้น', 'ทั้งที', 'มุ่งหมาย', 'เฉย', 'ไกลๆ', 'เพราะว่า', 'ฝ่าย', 'สบาย', 'เสียนี่', 'ตลอดทั่วถึง', 'ฝ่ายใด', 'ถึงบัดนี้', 'เผื่อจะ', 'ภายใน', 'ยอม', 'เพียงเพราะ', 'อย่างโน้น', 'รวมกัน', 'ไกล', 'บางที่', 'หากแม้', 'พวกกัน', 'เช่นกัน', 'ก็จะ', 'เป็นด้วย', 'วันไหน', 'ร่วมด้วย', 'บางครา', 'พอดี', 'พวกท่าน', 'รวมทั้ง', 'จาก', 'ทันใดนั้น', 'แต่นั้น', 'ยิ่งจน', 'เช่นที่', 'แต่อย่างใด', 'เป็นๆ', 'ได้รับ', 'ในช่วง', 'ประการใด', 'ต่างหาก', 'เมื่อคืน', 'ต่อ', 'สุด', 'เริ่ม', 'จนขณะนี้', 'ใหญ่โต', 'ภายภาคหน้า', 'ยืนนาน', 'หาใช่', 'ถึงเมื่อใด', 'จัดแจง', 'เช่นดัง', 'ครั้งหลังสุด', 'แม้', 'เมื่อนั้น', 'แล้วเสร็จ', 'นี่นา', 'ครัน', 'เพื่อที่จะ', 'ทาง', 'มากมาย', 'เป็นอัน', 'ทั้งนั้น', 'ใช่', 'ทั้งๆ', 'อย่างๆ', 'ทุกเมื่อ', 'เหตุนั้น', 'แยะ', 'ครั้งหลัง', 'ยิ่งขึ้น', 'เช่นเดียวกัน', 'บ่อยครั้ง', 'เสีย', 'เท่านี้', 'จากนี้', 'ตลอดทั่ว', 'เฉกเช่น', 'มั้ยนะ', 'ตามที่', 'ไป', 'อันที่', 'ก็ตามแต่', 'ซะจน', 'คราไหน', 'ประการฉะนี้', 'จำ', 'ช่วง', 'แยะๆ', 'ตน', 'บอกว่า', 'เกี่ยวข้อง', 'เท่าใด', 'แล้วแต่', 'ผล', 'ช่วงนั้น', 'ดังกับว่า', 'จวน', 'ด้วยที่', 'เห็น', 'นำพา', 'พึ่ง', 'แท้จริง', 'จึง', 'เมื่อครั้ง', 'กันเอง', 'มิ', 'จริงๆจังๆ', 'ขณะนั้น', 'ภายใต้', 'เมื่อ', 'สูงสุด', 'ก็ตามที', 'ตั้ง', 'ก็แล้วแต่', 'พวกมัน', 'เพียง', 'พอที่', 'กระทำ', 'ไป่', 'เป็นต้นไป', 'พบว่า', 'ทั่ว', 'เสมือนว่า', 'เพียงใด', 'แก้ไข', 'สมัยนั้น', 'คราวละ', 'กว้างขวาง', 'หากว่า', 'อย่างดี', 'ด้วยเช่นกัน', 'เป็นเพียง', 'ยังโง้น', 'มิฉะนั้น', 'ขณะ', 'ที่แท้จริง', 'มุ่ง', 'หรือไม่', 'ครั้งนั้น', 'หรือเปล่า', 'ใกล้', 'คราวโน้น', 'ดั่งเก่า', 'แค่', 'เฉพาะ', 'เมื่อไหร่', 'ทันที', 'ครั้งกระนั้น', 'อันไหน', 'อนึ่ง', 'ทีละ', 'เดียว', 'แต่ก็', 'ต่อกัน', 'ภาคฯ', 'เสียจนถึง', 'กลับ', 'ที่', 'ใช้', 'ณ', 'เอ็ง', 'วันใด', 'ทุกตัว', 'ครั้งๆ', 'ได้แก่', 'อย่างไร', 'นั่นเอง', 'จัดหา', 'เหตุนี้', 'เป็นเพราะ', 'จำพวก', 'ส่วน', 'ค่อนข้าง', 'ช่วงหน้า', 'แต่ที่', 'ซะจนถึง', 'เท่าไร', 'ใครๆ', 'เท่ากัน', 'ครา', 'บางแห่ง', 'รวมด้วย', 'ยาว', 'ใหญ่', 'เห็นควร', 'จะได้', 'ยก', 'ทีไร', 'บ่อย', 'เห็นว่า', 'ตลอดระยะเวลา', 'ข้าพเจ้า', 'เป็นการ', 'ใต้', 'นักๆ', 'เป็นอันๆ', 'ทั้งที่', 'เรื่อย', 'ตลอดปี', 'ส่วนด้อย', 'เมื่อคราวที่', 'จ๊ะ', 'กำลังจะ', 'พอจะ', 'ข้าฯ', 'พอ', 'ทํา', 'เชื่อ', 'เท่านั้น', 'เป็นที่สุด', 'กันดีไหม', 'คุณๆ', 'ยังงั้น', 'ตลอดจน', 'พึง', 'อันจะ', 'หนึ่ง', 'บน', 'เสร็จสิ้น', 'ที่ไหน', 'จวนเจียน', 'เช่นไร', 'นอกจากนั้น', 'หลาย', 'ย่อย', 'มัก', 'ถึงเมื่อไร', 'แค่นั้น', 'ซึ่งกัน', 'ที่ใด', 'ถึงแม้', 'ยังไง', 'เต็มๆ', 'ครั้งหนึ่ง', 'ไว้', 'เก็บ', 'เป็นที', 'นี่', 'สูงส่ง', 'รึว่า', 'ดังกับ', 'หมด', 'มากกว่า', 'เชื่อมั่น', 'แต่ละ', 'เสียนั่นเอง', 'สูง', 'เพียงแค่', 'นี่ไง', 'บ้าง', 'ทำๆ', 'หมดกัน', 'สิ้น', 'หาความ', 'ทั้งตัว', 'มิใช่', 'ซึ่งก็คือ', 'เพราะฉะนั้น', 'ส่ง', 'เพียงไร', 'กันและกัน', 'พบ', 'เช่นใด', 'ก็ต่อเมื่อ', 'ล้วน', 'เช่นเดียวกับ', 'ยังคง', 'จ้า', 'ละ', 'ไม่', 'แห่งโน้น', 'จริง', 'ไหน', 'คล้ายกัน', 'ด้วยว่า', 'เมื่อก่อน', 'ซึ่งได้แก่', 'แล้ว', 'พวกนู้น', 'อาจเป็นด้วย', 'มึง', 'กำหนด', 'แต่ว่า', 'ขณะเดียวกัน', 'เป็นต้น', 'ยอมรับ', 'ในระหว่าง', 'นอก', 'จัดงาน', 'อย่างใด', 'และ', 'เปิดเผย', 'นั่นไง', 'จะ', 'ทุกวันนี้', 'ค่อนมาทาง', 'เรา', 'เมื่อนี้', 'นับแต่นั้น', 'ช้านาน', 'เผื่อที่', 'ไง', 'เชื่อถือ', 'ถึงอย่างไร', 'ยังงี้', 'ทีเดียว', 'ปรับ', 'แสดงว่า', 'รวมถึง', 'ขั้น', 'พวกกู', 'สิ่งนั้น', 'ต้อง', 'แก่', 'แห่งใด', 'นั่นแหละ', 'คุณ', 'ยืนยาว', 'ถูกๆ', 'เอา', 'ขณะที่', 'ที่ละ', 'คล้าย', 'เป็นอันมาก', 'บัดเดี๋ยวนี้', 'ซึ่งกันและกัน', 'อย่างมาก', 'ปิด', 'สมัยนี้', 'ถึงเมื่อ', 'ของ', 'นอกเหนือจาก', 'ช่วงถัดไป', 'กับ', 'เมื่อเช้า', 'ช่วงนี้', 'โดย', 'อย่างไรก็', 'ซึ่งก็', 'นั้น', 'ทั้งหลาย', 'ขวาง', 'ด้วยเพราะ', 'คะ', 'มิได้', 'ตามแต่', 'เร็วๆ', 'ผิดๆ', 'เนี่ย', 'คล้ายว่า', 'นับ', 'ด้วยเหตุเพราะ', 'คือ', 'รวม', 'ประมาณ', 'สิ้นกาลนาน', 'เปลี่ยน', 'เกิน', 'ได้แต่', 'เปลี่ยนแปลง', 'พวกเธอ', 'ด้วยเหตุว่า', 'ขวางๆ', 'เช่นดังว่า', 'จนบัดนี้', 'นอกนั้น', 'ครั้งที่', 'เข้า', 'ถึงจะ', 'โตๆ', 'กันไหม', 'คราวที่', 'จนแม้น', 'เผื่อ', 'แรก', 'ยิ่งกว่า', 'พวกนั้น', 'พอตัว', 'เช่นนั้นเอง', 'หาก', 'อาจเป็น', 'กระผม', 'เท่ากับ', 'พอแล้ว', 'เสร็จ', 'จัดให้', 'ช่วงที่', 'คราวๆ', 'เคย', 'อย่างเดียว', 'ข้างต้น', 'เนี่ยเอง', 'นับแต่ที่', 'จัดตั้ง', 'ส่วนเกิน', 'ตลอดเวลา', 'จากนี้ไป', 'ทุกที', 'มักจะ', 'ปฏิบัติ', 'เป็นเพียงว่า', 'เช่นนั้น', 'ทุกอย่าง', 'ควร', 'ข้าง', 'นอกจาก', 'คราวนี้', 'จังๆ', 'ชาว', 'เพื่อ', 'เยอะ', 'นับจากนี้', 'ตรง', 'ๆ', 'ทั้งหมด', 'อันๆ', 'สมัย', 'นับแต่', 'ผู้', 'อยาก', 'ดังเก่า', 'นำ', 'มั้ยนั่น', 'สู่', 'หนอ', 'เล็ก', 'ตลอดทั้ง', 'ที่จริง', 'ค่ะ', 'นาย', 'อย่างไรเสีย', 'บางขณะ', 'ที่ว่า', 'จำเป็น', 'ไฉน', 'จง', 'ใหม่', 'กันเถอะ', 'นานๆ', 'กัน', 'ล้วนแต่', 'เมื่อวาน', 'ยิ่ง', 'เพิ่งจะ', 'จรด', 'ยิ่งใหญ่', 'ข้า', 'แล้วกัน', 'พูด', 'เมื่อคราวก่อน', 'ทั้งปวง', 'ถ้าจะ', 'ไม่ค่อยเป็น', 'คราวก่อน', 'เสร็จกัน', 'ส่วนดี', 'แต่เพียง', 'ซึ่งๆ', 'เช่นดังเก่า', 'เสียนี่กระไร', 'หน่อย', 'น่าจะ', 'กันดีกว่า', 'ทำไม', 'ยาวนาน', 'เพิ่ง', 'เพิ่มเติม', 'ไม่ใช่', 'หนอย', 'ล่าสุด', 'ที่นี้', 'สืบเนื่อง', 'จนเมื่อ', 'จนทั่ว', 'เป็นแต่', 'เอง', 'จับ', 'ให้', 'พร้อมกับ', 'พร้อมเพียง', 'แต่ต้อง', 'พวกแก', 'ใคร่จะ', 'มุ่งเน้น', 'เช่นนี้', 'เดียวกัน', 'เพียงไหน', 'นั่นเป็น', 'นิด', 'เถิด', 'ไร', 'นาน', 'ใคร', 'ร่วมกัน', 'ดั่ง', 'ส่วนน้อย', 'บอก', 'กล่าวคือ', 'หรือ', 'แบบ', 'เยอะแยะ', 'จัง', 'ปรากฏว่า', 'เห็นจะ', 'ทุกอัน', 'อื่นๆ', 'เช่นเมื่อ', 'แต่จะ', 'นอกจากว่า', 'ตนเอง', 'ทั้ง', 'เป็นแต่เพียง', 'เล่าว่า', 'สิ่ง', 'แต่เดิม', 'สูงกว่า', 'ประสบ', 'ตามๆ', 'หรือไร', 'คราใด', 'จน', 'ทุกครา', 'ถึงบัดนั้น', 'กลุ่มก้อน', 'หลัง', 'ทุกสิ่ง', 'อันละ', 'ยิ่งแล้ว', 'พร้อมกัน', 'แต่ก่อน', 'พวกฉัน', 'ก่อนๆ', 'ที่ซึ่ง', 'หลังจาก', 'คราวหนึ่ง', 'ที', 'เข้าใจ', 'นั่น', 'สามารถ', '\\ufeffๆ', 'ได้มา', 'ขณะใด', 'นั้นไว', 'อย่างยิ่ง', 'บอกแล้ว', 'ทีๆ', 'พวกคุณ', 'เสร็จสมบูรณ์', 'หมดสิ้น', 'เต็มไปด้วย', 'แสดง', 'บางที', 'ใหม่ๆ', 'ยกให้', 'มา', 'อันใด', 'เกิด', 'คราหนึ่ง', 'เขา', 'เรียก', 'ช่วงระหว่าง', 'ทีใด', 'พอเพียง', 'หรือยัง', 'คำ', 'แค่นี้', 'แต่ไหน', 'ตั้งแต่', 'เผื่อว่า', 'ก็ตาม', 'ตนฯ', 'อดีต', 'เราๆ', 'สั้นๆ', 'ถึงแม้ว่า', 'ดังเคย', 'พอที', 'พื้นๆ', 'นับแต่นี้', 'เกินๆ', 'ค่อยๆ', 'จนตลอด', 'เหล่านี้', 'ในที่', 'เหลือ', 'เป็นเพื่อ', 'ดังกล่าว', 'จ้ะ', 'แต่', 'แห่งไหน', 'พร้อมที่', 'ฉะนี้', 'แม้กระทั่ง', 'ใน', 'ช่วย', 'ดัง', 'นิดๆ', 'รวมๆ', 'ดั่งกับว่า', 'เช่นดังก่อน', 'เสียก่อน', 'น้อยๆ', 'ครบ', 'เช่นดังที่', 'ครั้ง', 'ครั้งครา', 'อื่น', 'เชื่อว่า', 'ส่วนใหญ่', 'ทุกที่', 'ภายภาค', 'ช่วงต่อไป', 'ร่วม', 'ช่วงท้าย', 'ก่อนหน้า', 'เป็นอาทิ', 'เรียบ', 'อันได้แก่', 'ต่างๆ', 'ร่วมมือ', 'น่ะ', 'อย่างละ', 'เนื่องจาก', 'พวก', 'เสียจน', 'มั๊ย', 'นี้', 'เท่าไหร่', 'ทรง', 'กระทั่ง', 'อาจจะ', 'ครั้งก่อน', 'จ๋า', 'ทุกหน', 'อย่างนั้น', 'กู', 'มั้ยเนี่ย', 'เหตุ', 'ต่าง', 'สมัยโน้น', 'จนถึง', 'เสียแล้ว', 'พร้อมทั้ง', 'ยืนยัน', 'จด', 'บัดดล', 'ด้วยเหตุที่', 'ด้าน', 'รับ', 'เหตุผล', 'ได้', 'ทุกคน', 'ทุกๆ', 'แก', 'เพราะ', 'ที่แห่งนั้น', 'หากแม้นว่า', 'ส่วนใด', 'ครั้งใด', 'เสมือนกับ', 'คราวหน้า', 'นี้แหล่', 'สิ่งใด', 'ข้างเคียง', 'ทุกชิ้น', 'อีก', 'เปิด', 'แค่เพียง', 'ยิ่งเมื่อ', 'ประการหนึ่ง', 'ในเมื่อ', 'คราว', 'หน', 'คราวนั้น', 'แห่งนั้น', 'เกือบจะ', 'ยาก', 'ตลอดถึง', 'เธอ', 'ยัง', 'ตลอดวัน', 'ที่ๆ', 'ภายนอก', 'ที่ได้', 'อย่างไรก็ได้', 'เท่า', 'ขึ้น', 'นับตั้งแต่', 'ขณะใดๆ', 'จู่ๆ', 'ที่แท้', 'ระหว่าง', 'นํา', 'มั้ยล่ะ', 'ได้ที่', 'ครบถ้วน', 'ไม่ค่อยจะ', 'มีแต่', 'คิด', 'เถอะ', 'ให้ดี', 'ทุกครั้ง', 'แม้ว่า', 'แต่ทว่า', 'นับจากนั้น', 'ยังจะ', 'วัน', 'ต่างก็', 'มาก', 'บางครั้ง', 'รวดเร็ว', 'เพียงเพื่อ', 'บางๆ', 'กลุ่มๆ', 'บาง', 'เสียยิ่ง', 'เช่นที่เคย', 'มันๆ', 'ทันทีทันใด', 'จวบ', 'ปรากฏ', 'ลง', 'เมื่อคราว', 'น้อยกว่า', 'ครั้งไหน', 'เพื่อที่', 'มอง', 'อยู่', 'ระยะ', 'แห่ง', 'นอกจากนี้', 'ไม่ว่า', 'เลย', 'แห่งนี้', 'ผ่านๆ', 'คราวไหน', 'ถึง', 'บัดนี้', 'พวกโน้น', 'ฉัน', 'เหตุไร', 'ช่วงแรก', 'เป็น', 'ครบครัน', 'เมื่อไร', 'ยังแต่', 'พยายาม', 'เป็นต้นมา', 'นั้นๆ', 'อะไร', 'ตลอดไป', 'เสียยิ่งนัก', 'ทุกวัน', 'พอสมควร', 'แต่เมื่อ', 'เกี่ยวกัน', 'ใช่ไหม', 'ขณะนี้', 'ยืนยง', 'ถึงแก่', 'โต', 'กำลัง', 'เป็นเพราะว่า', 'จัดทำ', 'นู่น', 'ค่อน', 'น้อย', 'หารือ', 'จนกว่า', 'เกี่ยวๆ', 'เพียงพอ', 'รวด', 'เสียจนกระทั่ง', 'เคยๆ', 'จวบกับ', 'เช่นเคย', 'กว้างๆ', 'หากแม้น', 'ช้าๆ', 'ข้างบน', 'เสียด้วย', 'ผ่าน', 'ใกล้ๆ', 'ภาย', 'คราวใด', 'นี่แหละ', 'ครับ', 'ยิ่งจะ', 'เป็นที่', 'รือ', 'กลุ่ม', 'ซะก่อน', 'อย่างน้อย', 'เป็นดัง', 'เล็กๆ', 'แหละ', 'ครานี้', 'จริงจัง', 'ผู้ใด', 'จึงจะ', 'นู้น', 'ด้วยเหมือนกัน', 'ตาม', 'พวกมึง', 'แค่ว่า', 'ตามด้วย', 'เต็มไปหมด', 'เมื่อใด', 'นี้เอง', 'สูงๆ', 'สิ่งนี้', 'พอควร', 'เน้น', 'การ', 'ทัน', 'ดั่งกับ', 'ครั้งคราว', 'อย่างไหน', 'ด้วยประการฉะนี้', 'อาจ', 'เหลือเกิน', 'ด้วยกัน', 'เพียงแต่', 'จึงเป็น', 'พอเหมาะ', 'บ่อยๆ', 'ให้ไป', 'ทําให้', 'คล้ายกันกับ', 'ครั้งนี้', 'คราวหลัง', 'แม้นว่า', 'นี่แน่ะ', 'ไหนๆ', 'พา', 'ยิ่งนัก', 'ส่วนนั้น', 'ก่อนหน้านี้', 'ทำให้', 'แค่จะ', 'ให้มา', 'ย่อม', 'ภายหน้า', 'ประกอบ', 'ทั้งเป็น', 'ตรงๆ', 'ว่า', 'กล่าว', 'ตลอดทั่วทั้ง', 'จัด', 'พร้อมด้วย', 'ขณะหนึ่ง', 'ทั้งนั้นด้วย', 'เพื่อว่า', 'ขาด', 'ทั้งคน', 'เสร็จแล้ว', 'นิดหน่อย', 'สิ่งไหน', 'ฯ', 'ช่วงหลัง', 'อย่างหนึ่ง', 'อย่างที่', 'เพื่อให้', 'กันนะ', 'ก่อน', 'ระยะๆ', 'ตลอดมา', 'ไม่เป็นไร', 'กระนั้น', 'ทุกคราว', 'เมื่อวันวาน', 'นี่เอง', 'เร็ว', 'คง', 'กว้าง', 'เช่นที่ว่า', 'สุดๆ', 'ราย', 'ทุกทาง', 'อันเนื่องมาจาก', 'ฯลฯ', 'ถูก', 'ก็ดี', 'อันที่จริง', 'ถึงแม้จะ', 'แต่ถ้า', 'ครานั้น', 'เพิ่ม', 'นาง', 'จากนั้น', 'นะ', 'บัดนั้น', 'ช้า', 'เฉยๆ', 'ทีเถอะ', 'ซะจนกระทั่ง', 'ไม่ค่อย', 'จวนจะ', 'คล้ายกับ', 'ก็แค่', 'เรื่อยๆ', 'สำคัญ', 'บางคราว', 'ทำไร', 'แต่ไร', 'เยอะๆ', 'ช่วงก่อน', 'วันนั้น', 'ซะ', 'ด้วย', 'จวบจน', 'ทั้งสิ้น', 'เห็นแก่', 'ก็', 'ขอ', 'สําหรับ', 'มั้ย', 'จนกระทั่ง', 'ก็คือ', 'ง่าย', 'คราที่', 'ทั้งนั้นเพราะ', 'ตลอดกาลนาน', 'ค่อนข้างจะ', 'บางกว่า'}\n"
          ]
        }
      ],
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.corpus.common import thai_stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(set(thai_stopwords()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (10710, 3594)\n",
            "Val shape: (1339, 3594)\n",
            "Test shape: (1340, 3594)\n",
            "Number of features: 3594\n",
            "Sample TF-IDF Features (First 5 training samples):\n",
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 8 stored elements and shape (1, 3594)>\n",
            "  Coords\tValues\n",
            "  (0, 2856)\t0.2885629413746919\n",
            "  (0, 2174)\t0.3644740882130535\n",
            "  (0, 127)\t0.45100667026141533\n",
            "  (0, 1677)\t0.28148034536449795\n",
            "  (0, 3122)\t0.28025673780847243\n",
            "  (0, 3522)\t0.16197780948030555\n",
            "  (0, 1455)\t0.5452004308679377\n",
            "  (0, 2514)\t0.31500429643097466\n"
          ]
        }
      ],
      "source": [
        "pythainlp_tokenizer = lambda x: word_tokenize(x, engine=\"newmm\", keep_whitespace=False)\n",
        "\n",
        "# Extract tokenized text and labels\n",
        "train_texts, train_labels = dataset[\"train\"][\"input\"], dataset[\"train\"][\"label\"]\n",
        "val_texts, val_labels = dataset[\"val\"][\"input\"], dataset[\"val\"][\"label\"]\n",
        "test_texts, test_labels = dataset[\"test\"][\"input\"], dataset[\"test\"][\"label\"]\n",
        "\n",
        "# map texts to lowercase\n",
        "train_texts = [text.lower() for text in train_texts]\n",
        "val_texts = [text.lower() for text in val_texts]\n",
        "test_texts = [text.lower() for text in test_texts]\n",
        "\n",
        "# Initialize and fit TF-IDF Vectorizer on training data\n",
        "vectorizer = TfidfVectorizer(tokenizer=pythainlp_tokenizer, max_df=0.7, min_df=1)\n",
        "X_train_tfidf = vectorizer.fit_transform(train_texts)  # Fit and transform training data\n",
        "\n",
        "X_val_tfidf = vectorizer.transform(val_texts)  # Transform validation data\n",
        "X_test_tfidf = vectorizer.transform(test_texts)  # Transform test data\n",
        "\n",
        "# Print shape of TF-IDF matrices\n",
        "print(\"Train shape:\", X_train_tfidf.shape)\n",
        "print(\"Val shape:\", X_val_tfidf.shape)\n",
        "print(\"Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# vectorizer get feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"Number of features:\", len(feature_names))\n",
        "\n",
        "# Print first 5 samples of processed train data\n",
        "print(\"Sample TF-IDF Features (First 5 training samples):\")\n",
        "print(X_train_tfidf[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of OOV words in validation set: 212\n",
            "Number of OOV words in test set: 187\n",
            "OOV ratio in validation set: 0.05898720089037284\n",
            "OOV ratio in test set: 0.05203116304952699\n"
          ]
        }
      ],
      "source": [
        "# check for oov in test and val set\n",
        "word_dict = vectorizer.get_feature_names_out()\n",
        "\n",
        "oov_set = set()\n",
        "\n",
        "def get_oov_words(texts):\n",
        "    oov_set = set()\n",
        "    for text in texts:\n",
        "        for word in pythainlp_tokenizer(text):\n",
        "            if word not in word_dict:\n",
        "                oov_set.add(word)\n",
        "    return oov_set\n",
        "\n",
        "oov_val = get_oov_words(val_texts)\n",
        "oov_test = get_oov_words(test_texts)\n",
        "\n",
        "print(\"Number of OOV words in validation set:\", len(oov_val))\n",
        "print(\"Number of OOV words in test set:\", len(oov_test))\n",
        "print(\"OOV ratio in validation set:\", len(oov_val) / len(word_dict))\n",
        "print(\"OOV ratio in test set:\", len(oov_test) / len(word_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define a LogisticRegression model with tf-idf as feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import from sklearn that automatically select the best hyperparameter\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
        "    \"penalty\": [\"l1\", \"l2\"],\n",
        "    \"solver\": [\"liblinear\"]\n",
        "}\n",
        "\n",
        "# Initialize the GridSearchCV object\n",
        "grid_search = GridSearchCV( estimator=LogisticRegression(max_iter=1000, class_weight=\"balanced\"), \n",
        "                            param_grid=param_grid, \n",
        "                            cv=5, \n",
        "                            n_jobs=-1, \n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.5s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.5s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.7s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.8s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.7s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.8s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.7s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.0s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.9s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.0s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.1s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.1s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.1s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.1s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.1s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.3s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.2s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.3s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.4s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.4s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.8s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.6s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   2.6s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   2.1s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.7s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   3.3s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.7s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.3s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.1s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   5.2s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.3s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   5.2s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   5.0s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   5.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=  13.6s\n"
          ]
        }
      ],
      "source": [
        "# Fit the GridSearchCV object on the training data\n",
        "grid_search.fit(X_train_tfidf, train_labels)\n",
        "\n",
        "# get the best model\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=10, class_weight='balanced', max_iter=1000,\n",
              "                   solver='liblinear')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7303958177744585\n",
            "Test Accuracy: 0.7231343283582089\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        payment       0.68      0.86      0.76        64\n",
            "        package       0.73      0.68      0.71       180\n",
            "        suspend       0.81      0.77      0.79        73\n",
            "       internet       0.72      0.77      0.74       179\n",
            "   phone_issues       0.63      0.76      0.69        58\n",
            "        service       0.82      0.69      0.75       211\n",
            "    nontruemove       0.39      0.44      0.42        25\n",
            "        balance       0.87      0.83      0.85       149\n",
            "         detail       0.46      0.39      0.43        33\n",
            "           bill       0.75      0.80      0.77        54\n",
            "         credit       0.83      0.88      0.86        17\n",
            "      promotion       0.69      0.69      0.69       115\n",
            " mobile_setting       0.42      0.46      0.44        28\n",
            "       iservice       0.50      0.50      0.50         2\n",
            "        roaming       0.87      0.80      0.83        25\n",
            "      truemoney       0.85      0.68      0.76        25\n",
            "    information       0.47      0.67      0.55        30\n",
            "    lost_stolen       0.88      0.91      0.89        23\n",
            "balance_minutes       0.50      0.60      0.55         5\n",
            "            idd       0.89      0.85      0.87        20\n",
            "        garbage       0.00      0.00      0.00         5\n",
            "       ringtone       0.60      0.75      0.67         8\n",
            "           rate       0.25      0.33      0.29         3\n",
            "   loyalty_card       0.71      0.83      0.77         6\n",
            "        contact       0.00      0.00      0.00         1\n",
            "        officer       0.00      0.00      0.00         1\n",
            "\n",
            "       accuracy                           0.72      1340\n",
            "      macro avg       0.59      0.61      0.60      1340\n",
            "   weighted avg       0.73      0.72      0.72      1340\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the best model on the validation data\n",
        "val_preds = best_model.predict(X_val_tfidf)\n",
        "val_acc = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_acc)\n",
        "\n",
        "test_preds = best_model.predict(X_test_tfidf)\n",
        "test_acc = accuracy_score(test_labels, test_preds)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "\n",
        "# Generate classification report on test data\n",
        "print(classification_report(test_labels, test_preds, target_names=num_2_label_map.values()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
