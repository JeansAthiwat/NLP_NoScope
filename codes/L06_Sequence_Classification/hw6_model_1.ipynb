{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8FRFIYMc5X"
      },
      "source": [
        "# HOMEWORK 6: TEXT CLASSIFICATION\n",
        "In this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n",
        "1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancle)\n",
        "2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming)\n",
        "\n",
        "We will focus only on the Object Classification task for this homework.\n",
        "\n",
        "In this homework, you are asked compare different text classification models in terms of accuracy and inference time.\n",
        "\n",
        "You will need to build 3 different models.\n",
        "\n",
        "1. A model based on tf-idf\n",
        "2. A model based on MUSE\n",
        "3. A model based on wangchanBERTa\n",
        "\n",
        "**You will be ask to submit 3 different files (.pdf from .ipynb) that does the 3 different models. Finally, answer the accuracy and runtime numbers in MCV.**\n",
        "\n",
        "This homework is quite free form, and your answer may vary. We hope that the processing during the course of this assignment will make you think more about the design choices in text classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHqkFSyaNvOt",
        "outputId": "879b17f1-0fb2-455c-ca37-b5a4aecd7b1c"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRlx5Mb5zkXw",
        "outputId": "18d913e0-aa6d-435b-931d-591386cb4ba8"
      },
      "outputs": [],
      "source": [
        "# !wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv\n",
        "# !pip install pythainlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YprqbOPMc5a"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "heICP79cMc5e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from IPython.display import display\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#My import \n",
        "np.random.seed(42)\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaUf4PLMc5k"
      },
      "source": [
        "## Loading data\n",
        "First, we load the data from disk into a Dataframe.\n",
        "\n",
        "A Dataframe is essentially a table, or 2D-array/Matrix with a name for each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JhZ2eBAWMc5l"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('clean-phone-data-for-students.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cje3yruTMc5p"
      },
      "source": [
        "Let's preview the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "aNqRNz1PMc5q",
        "outputId": "e129a502-1420-476c-dc50-46c293a01b56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>payment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>package</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n",
              "      <td>report</td>\n",
              "      <td>suspend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>internet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n",
              "      <td>report</td>\n",
              "      <td>phone_issues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Sentence Utterance   Action        Object\n",
              "0   <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire       payment\n",
              "1               internet ยังความเร็วอยุ่เท่าไหร ครับ  enquire       package\n",
              "2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   report       suspend\n",
              "3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...  enquire      internet\n",
              "4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   report  phone_issues"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show the top 5 rows\n",
        "display(data_df.head())\n",
        "# Summarize the data\n",
        "data_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGd8BNvMMc5y"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "We call the DataFrame.describe() again.\n",
        "Notice that there are 33 unique labels/classes for object and 10 unique labels for action that the model will try to predict.\n",
        "But there are unwanted duplications e.g. Idd,idd,lotalty_card,Lotalty_card\n",
        "\n",
        "Also note that, there are 13389 unqiue sentence utterances from 16175 utterances. You have to clean that too!\n",
        "\n",
        "## #TODO 0.1:\n",
        "You will have to remove unwanted label duplications as well as duplications in text inputs.\n",
        "Also, you will have to trim out unwanted whitespaces from the text inputs.\n",
        "This shouldn't be too hard, as you have already seen it in the demo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "V0bGLblVMc5z",
        "outputId": "1a65aff5-6196-4674-fb5d-36aa1afcfdba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
              "       'service', 'nonTrueMove', 'balance', 'detail', 'bill', 'credit',\n",
              "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
              "       'information', 'lost_stolen', 'balance_minutes', 'idd',\n",
              "       'TrueMoney', 'garbage', 'Payment', 'IDD', 'ringtone', 'Idd',\n",
              "       'rate', 'loyalty_card', 'contact', 'officer', 'Balance', 'Service',\n",
              "       'Loyalty_card'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['enquire', 'report', 'cancel', 'Enquire', 'buy', 'activate',\n",
              "       'request', 'Report', 'garbage', 'change'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(data_df.describe())\n",
        "display(data_df.Object.unique())\n",
        "display(data_df.Action.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "19onNNUZMc54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>clean_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13385</td>\n",
              "      <td>13385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13385</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       input clean_label\n",
              "count                                  13385       13385\n",
              "unique                                 13385          26\n",
              "top     สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ     service\n",
              "freq                                       1        2108"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO.1: Data cleaning\n",
        "\n",
        "# select only the columns that we need\n",
        "data_df = data_df[['Sentence Utterance', 'Object']]\n",
        "data_df.columns = ['input', 'raw_label']\n",
        "\n",
        "# remove duplicate labels\n",
        "data_df['clean_label'] = data_df['raw_label'].str.lower().copy()\n",
        "data_df.drop('raw_label', axis=1, inplace=True)\n",
        "\n",
        "# ! input to lower case (helps with OOV token)\n",
        "data_df['input'] = data_df['input'].str.lower()\n",
        "\n",
        "# remove duplicate input rows\n",
        "data_df = data_df.drop_duplicates(\"input\", keep=\"first\")\n",
        "display(data_df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# map label to number and convert to numpy \"data\"\n",
        "data = data_df.to_numpy()\n",
        "unique_label = data_df.clean_label.unique()\n",
        "\n",
        "label_2_num_map = dict(zip(unique_label, range(len(unique_label))))\n",
        "num_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n",
        "\n",
        "# convert label to number\n",
        "data[:,1] = np.vectorize(label_2_num_map.get)(data[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input string cleaning\n",
        "def strip_str(string):\n",
        "    return string.strip()\n",
        "     \n",
        "# Trim of extra begining and trailing whitespace in the string\n",
        "data[:,0] = np.vectorize(strip_str)(data[:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Keep in mind class is imbalance type shi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIxnPRiAmrhN"
      },
      "source": [
        "Split data into train, valdation, and test sets (normally the ratio will be 80:10:10 , respectively). We recommend to use train_test_spilt from scikit-learn to split the data into train, validation, test set.\n",
        "\n",
        "In addition, it should split the data that distribution of the labels in train, validation, test set are similar. There is **stratify** option to handle this issue.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "Make sure the same data splitting is used for all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EYzMrvb7nYR2"
      },
      "outputs": [],
      "source": [
        "X = data[:,0]\n",
        "y = data[:,1]\n",
        "\n",
        "X_class_24, y_class_24 = X[y == 24], y[y == 24] #handle class 24 with only 4 samples\n",
        "X, y = X[y != 24], y[y != 24] # remove class 24 from the data to add it later\n",
        "\n",
        "random_idx = np.random.choice(len(X_class_24), 2, replace=False)\n",
        "\n",
        "X_class_24_val, X_class_24_test = X_class_24[random_idx[0]], X_class_24[random_idx[1]]\n",
        "y_class_24_val, y_class_24_test = y_class_24[random_idx[0]], y_class_24[random_idx[1]]\n",
        "\n",
        "X_class_24_train = np.delete(X_class_24, random_idx)\n",
        "y_class_24_train = np.delete(y_class_24, random_idx)\n",
        "\n",
        "# train val test split 80:10:10\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42)\n",
        "\n",
        "# add class 24 to the train, val, test set\n",
        "X_train, y_train = np.append(X_train, X_class_24_train), np.append(y_train, y_class_24_train)\n",
        "X_val, y_val = np.append(X_val, X_class_24_val), np.append(y_val, y_class_24_val)\n",
        "X_test, y_test = np.append(X_test, X_class_24_test), np.append(y_test, y_class_24_test)\n",
        "\n",
        "#check label distribution\n",
        "# display(np.unique(y_train, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['อยากจะสอบถามทรูมูฟ เอช 3g ที่ตำบลบ้านกลาง มีสัญญาณหรือเปล่าค่ะ', 'เติมเงินแล้วไม่ได้', 'จะเติมเงินต้องทำยังไง', 'ถ้าจะซื้อ เดอะ นิวไอแพด ใช้บัตรอะไรรูดได้บ้าง', 'เมื่อคืนนี้ผมโทรมาแจ้งเรื่องโทรศัพท์หาไม่เจอ และระงับไว้ ตอนนี้เจอ อยู่ใต้เบาะรถ ต้องการเปิดสัญญาณการใช้งาน']\n",
            "[4, 0, 0, 16, 5]\n"
          ]
        }
      ],
      "source": [
        "def create_dataset_dict(dataset, data_split, split_name, keep_ws=False):\n",
        "    for input_str, label in data_split:\n",
        "        dataset[split_name][\"input\"].append(input_str)\n",
        "        dataset[split_name][\"label\"].append(label)\n",
        "\n",
        "dataset = { \"train\": {\"input\": [], \"label\": []},\n",
        "            \"val\": {\"input\": [], \"label\": []},\n",
        "            \"test\": {\"input\": [], \"label\": []} }\n",
        "\n",
        "create_dataset_dict(dataset, zip(X_train, y_train), \"train\")\n",
        "create_dataset_dict(dataset, zip(X_val, y_val), \"val\")\n",
        "create_dataset_dict(dataset, zip(X_test, y_test), \"test\")\n",
        "\n",
        "print(dataset[\"train\"][\"input\"][:5])\n",
        "print(dataset[\"train\"][\"label\"][:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx6gllzrnVVU"
      },
      "source": [
        "# Model 1 TF-IDF\n",
        "\n",
        "Build a model to train a tf-idf text classifier. Use a simple logistic regression model for the classifier.\n",
        "\n",
        "For this part, you may find this [tutorial](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py) helpful.\n",
        "\n",
        "Below are some design choices you need to consider to accomplish this task. Be sure to answer them when you submit your model.\n",
        "\n",
        "What tokenizer will you use? Why?\n",
        "\n",
        "**Ans:** -> **\"newmm\"** . fast and efficient (Good enough acc on BEST test benchmark word level tokenization)\n",
        "\n",
        "Will you ignore some stop words (a, an, the, to, etc. for English) in your tf-idf? Is it important?\n",
        "PythaiNLP provides a list of stopwords if you want to use (https://pythainlp.org/docs/2.0/api/corpus.html#pythainlp.corpus.common.thai_stopwords)\n",
        "\n",
        "**Ans:** I will not use stop word. but instead use the TfidfVectorizer()'s 'max_df' to cut out to frequent words.\n",
        "\n",
        "The dictionary of TF-IDF is usually based on the training data. How many words in the test set are OOVs?\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "- Number of OOV words in validation set: 190\n",
        "- Number of OOV words in test set: 185\n",
        "- OOV ratio in validation set: 0.05255878284923928\n",
        "- OOV ratio in test set: 0.051175656984785614"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9vOqTqmfufsT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'ระยะ', 'นาน', 'สิ้นกาลนาน', 'ที่แห่งนั้น', 'ทว่า', 'นั่นเอง', 'อันที่', 'หนึ่ง', 'การ', 'ภายนอก', 'แห่งไหน', 'เปลี่ยนแปลง', 'เฉย', 'ทั้งนั้นเพราะ', 'ที่ไหน', 'ถึงแม้', 'นอกเหนือจาก', 'สิ่งใด', 'สุดๆ', 'รวม', 'ตลอดมา', 'มั้ยนะ', 'ขณะเดียวกัน', 'นั้นไว', 'เช่นนั้นเอง', 'ทุกคน', 'จู่ๆ', 'จง', 'ไฉน', 'เผื่อจะ', 'เสียนั่นเอง', 'บอกว่า', 'อดีต', 'ขอ', 'พึ่ง', 'แล้วเสร็จ', 'รวมด้วย', 'เหลือ', 'ช่วงที่', 'มีแต่', 'ปฏิบัติ', 'นาย', 'พอกัน', 'ใหม่', 'เมื่อครั้งก่อน', 'นี้แหล่', 'ช่วงท้าย', 'รวดเร็ว', 'หมด', 'จวบจน', 'วันใด', 'เป็นต้นไป', 'คล้ายว่า', 'ทุกหน', 'เช่นเมื่อ', 'ใคร่', 'เกือบจะ', 'หากว่า', 'คล้ายกัน', 'เกือบๆ', 'กลับ', 'ขณะใด', 'เมื่อเย็น', 'ผู้ใด', 'แต่ก็', 'ถึงแม้ว่า', 'ละ', 'เพียงแต่', 'ช่วงนี้', 'อย่างไร', 'เป็นการ', 'เสียยิ่ง', 'พวกฉัน', 'นี่', 'จัดหา', 'ดั่งเก่า', 'ก็ต่อเมื่อ', 'จริง', 'พอสม', 'กระผม', 'อัน', 'เพราะว่า', 'เป็นเพียง', 'นั่นเป็น', 'มุ่ง', 'กลุ่มๆ', 'เสีย', 'เป็นอาทิ', 'กำลังจะ', 'ที่ใด', 'ก็ตามแต่', 'รับ', 'เชื่อถือ', 'ด้วย', 'อันๆ', 'ขึ้น', 'น้อย', 'ภาคฯ', 'ด้วยเหตุที่', 'ทั้งสิ้น', 'รวด', 'ทุกคราว', 'ช่วง', 'เอา', 'เป็นที่สุด', 'เกี่ยวกับ', 'ข้าพเจ้า', 'เพื่อให้', 'ดังกับว่า', 'ได้ที่', 'นำพา', 'แห่ง', 'เรียบ', 'อย่างใด', 'กันเถอะ', 'ปรากฏ', 'ยังจะ', 'จนถึง', 'ถือ', 'ช่วย', 'ทั้งที่', 'มากกว่า', 'ปัจจุบัน', 'ภายภาคหน้า', 'สู่', 'บางขณะ', 'เห็นควร', 'ตลอดศก', 'เผื่อ', 'จำพวก', 'ส่ง', 'ผิดๆ', 'ยืนยาว', 'ส่วนด้อย', 'คราที่', 'คิดว่า', 'แค่เพียง', 'เริ่ม', 'ข้างๆ', 'มั้ยเนี่ย', 'บัดนั้น', 'ครั้งละ', 'กันเอง', 'ค่อน', 'ซึ่งกัน', 'จำเป็น', 'ตลอดไป', 'ใน', 'หลาย', 'เกิน', 'จากนี้ไป', 'ค่อยๆ', 'มันๆ', 'พวกมัน', 'ซึ่งกันและกัน', 'เช่นที่ว่า', 'เมื่อนั้น', 'สูงสุด', 'ก็แค่', 'เปลี่ยน', 'พอที', 'ผู้', 'เสร็จ', 'ขณะหนึ่ง', 'นอกจากนั้น', 'ประการฉะนี้', 'เราๆ', 'ทุกที่', 'ตน', 'กว้าง', 'คล้ายกับว่า', 'ทั้งหลาย', 'พูด', 'ดั่ง', 'ช้า', 'นี่แน่ะ', 'ครบ', 'ต่าง', 'ง่าย', 'นอกนั้น', 'กับ', 'กันไหม', 'คง', 'มั้ย', 'เล็ก', 'ฯลฯ', 'เกี่ยวๆ', 'เพียงเพื่อ', 'ใดๆ', 'เสียยิ่งนัก', 'จากนี้', 'กล่าวคือ', 'ผ่าน', 'ด้วยเหมือนกัน', 'เป็นที', 'ยิ่งใหญ่', 'ต้อง', 'เมื่อครั้ง', 'ล่าสุด', 'ครั้งกระนั้น', 'แต่ที่', 'ไง', 'เพื่อ', 'ในระหว่าง', 'หารือ', 'นอกจากว่า', 'อย่างดี', 'ยก', 'ปิด', 'ร่วมมือ', 'ส่วนน้อย', 'ทัน', 'ทีไร', 'ถูกต้อง', 'บาง', 'จนบัดนี้', 'นั่นแหละ', 'หนอย', 'ถึงอย่างไร', 'เช่นก่อน', 'จริงจัง', 'แสดง', 'พร้อมด้วย', 'ยิ่งจน', 'เธอ', 'ช่วงหน้า', 'ที่จริง', 'ทั้งคน', 'พบ', 'พึง', 'เป็นอันๆ', 'ทำไร', 'เช่นนั้น', 'ยอม', 'เยอะ', 'ตรง', 'คราว', 'ข้างล่าง', 'เสียด้วย', 'ๆ', 'มองว่า', 'เท่าไร', 'รวมทั้ง', 'ตั้งแต่', 'ง่ายๆ', 'จัดงาน', 'หาความ', 'ทั้งมวล', 'เสียนี่กระไร', 'จนแม้', 'ครั้งหลัง', 'ที่ได้', 'ยืนนาน', 'พวกคุณ', 'แยะ', 'เล็กๆ', 'ข้างบน', 'ก็ตาม', 'ก่อนหน้า', 'เท่านั้น', 'เต็มไปหมด', 'ทุกอัน', 'ปรากฏว่า', 'ว่า', 'อย่างนั้น', 'ทีเดียว', 'สิ่งนี้', 'พร้อมทั้ง', 'เป็นอันมาก', 'นิดหน่อย', 'ครั้งครา', 'สมัย', 'ดั่งเคย', 'แม้แต่', 'ถึง', 'กว้างขวาง', 'ยาว', 'หมดสิ้น', 'เป็นเพราะว่า', 'เช่นกัน', 'เหตุไร', 'เช่นดังเก่า', 'ฯ', 'สิ่ง', 'มอง', 'ส่วนที่', 'เกี่ยวกัน', 'บ่อย', 'แต่ละ', 'จัดแจง', 'นอก', 'ไม่ค่อย', 'พวกนู้น', 'กำหนด', 'จัดตั้ง', 'คราวโน้น', 'บางคราว', 'เห็นจะ', 'อันไหน', 'หน', 'กลุ่ม', 'ทุกที', 'เช่นดัง', 'เป็นดัง', 'ไว้', 'ขวาง', 'ทั้งๆ', 'อีก', 'ร่วม', 'ข้างต้น', 'แก', 'ฉะนี้', 'ที่ซึ่ง', 'ถึงเมื่อไร', 'ใหญ่', 'สมัยนั้น', 'ตลอดถึง', 'ด้วยเหตุเพราะ', 'หรือไง', 'พวกนั้น', 'ครั้งนั้น', 'เรื่อย', 'ขณะนั้น', 'น่า', 'พบว่า', 'เสมือนกับ', 'อนึ่ง', 'อันละ', 'อันเนื่องมาจาก', 'หาใช่', 'ตลอดกาล', 'เมื่อคราวที่', 'ยกให้', 'พร้อมที่', 'ตามแต่', 'ซึ่งๆ', 'ที่นั้น', 'พวกนี้', 'ประการใด', 'เรา', 'ทั้งนั้น', 'ช่วงแรก', 'ข้างเคียง', 'อาจเป็นด้วย', 'ทำๆ', 'คราวหลัง', 'ถ้าจะ', 'ให้แด่', 'หน่อย', 'ใคร', 'ส่วน', 'เขียน', 'แม้ว่า', 'อย่างนี้', 'บน', 'ส่วนเกิน', 'ที่ๆ', 'ทุกครา', 'บ่อยครั้ง', 'ข้าง', 'เพราะ', 'อันใด', 'ข้า', 'ทุกวัน', 'นอกจากนี้', 'ข้าฯ', 'หาก', 'ก่อน', 'เสมือนว่า', 'จ๊ะ', 'เพราะฉะนั้น', 'เสร็จกัน', 'ทีใด', 'จด', 'ให้ดี', 'ภายหน้า', 'พวกเธอ', 'เปิดเผย', 'ได้แต่', 'เล่าว่า', 'ตลอด', 'ภายใน', 'ทุกชิ้น', 'เป็นเพียงว่า', 'เช่น', 'เสียจนกระทั่ง', 'มิ', 'ในช่วง', 'หรือไร', 'ครั้งคราว', 'น้อยกว่า', 'ค่อยไปทาง', 'พวกกัน', 'ที่ละ', 'นี่นา', 'สมัยก่อน', 'เสียจน', 'ยาวนาน', 'จึง', 'จรดกับ', 'เข้าใจ', 'จึงเป็น', 'คะ', 'ไม่', 'เหตุ', 'ช่วงระหว่าง', 'ยังไง', 'เช่นเดียวกัน', 'นิดๆ', 'บัดนี้', 'พอแล้ว', 'เต็มไปด้วย', 'พวกกู', 'จวน', 'คราวก่อน', 'ประสบ', 'นำมา', 'เท่า', 'ยืนยง', 'เอ็ง', 'เมื่อไหร่', 'เพิ่งจะ', 'แต่ไหน', 'เท่ากับ', 'อย่างโน้น', 'คราวนี้', 'ตลอดเวลา', 'ส่วนนั้น', 'ไม่ว่า', 'ประการหนึ่ง', 'ตาม', 'ด้วยเหตุนี้', 'จริงๆจังๆ', 'นู่น', 'นับแต่นี้', 'ไป', 'จนเมื่อ', 'เฉพาะ', 'นับแต่', 'บอกแล้ว', 'ยิ่งนัก', 'แห่งโน้น', 'ทั้งนั้นด้วย', 'ต่อ', 'นานๆ', 'ใกล้', 'ทำไม', 'นำ', 'นับจากนั้น', 'จ้า', 'ถือว่า', 'แต่ทว่า', 'มึง', 'ที่แล้ว', 'ด้วยเหตุนั้น', 'พวก', 'วันนั้น', 'ทําให้', 'ซะก่อน', 'จนตลอด', 'เมื่อไร', 'บางที', 'ก็แล้วแต่', 'คราวนั้น', 'รือ', 'ให้', 'เห็น', '\\ufeffๆ', 'ถูกๆ', 'นับจากนี้', 'มี', 'พวกแก', 'เสียก่อน', 'ค่อย', 'เฉยๆ', 'อันที่จริง', 'ไหนๆ', 'ตลอดทั่วทั้ง', 'จนทั่ว', 'แค่ว่า', 'เช่นเคย', 'จรด', 'ใกล้ๆ', 'อันจะ', 'หากแม้', 'เมื่อนี้', 'พอดี', 'ที่นี้', 'ทรง', 'เคยๆ', 'เพียงไหน', 'จริงๆ', 'หากแม้นว่า', 'ถูก', 'ใครๆ', 'ถึงเมื่อใด', 'ยังคง', 'แต่ก่อน', 'โดย', 'เป็น', 'ทำให้', 'เดียว', 'เหล่า', 'ฯล', 'บางกว่า', 'แห่งใด', 'ผ่านๆ', 'จัดให้', 'จ้ะ', 'คราไหน', 'กันและกัน', 'คงอยู่', 'ใคร่จะ', 'สามารถ', 'ควร', 'ความ', 'เพิ่ม', 'มาก', 'ซะจน', 'จำ', 'ได้รับ', 'คือ', 'เผื่อว่า', 'ที่แท้จริง', 'เพื่อที่จะ', 'แค่ไหน', 'ใช้', 'ก่อนหน้านี้', 'นิด', 'ต่างๆ', 'น่าจะ', 'โต', 'พื้นๆ', 'ภายภาค', 'พวกท่าน', 'เมื่อก่อน', 'ครานี้', 'จวบ', 'ก็จะ', 'ไกลๆ', 'ถึงจะ', 'เพียง', 'คิด', 'ช้านาน', 'นางสาว', 'เป็นเพราะ', 'ตลอดจน', 'พอ', 'ย่อย', 'ไป่', 'ถ้าหาก', 'แล้ว', 'ได้มา', 'จวนเจียน', 'กันดีกว่า', 'ยิ่งเมื่อ', 'เกิด', 'มั้ยล่ะ', 'เท่าใด', 'มั๊ย', 'แล้วแต่', 'อื่น', 'นํา', 'อยู่', 'เมื่อวันวาน', 'อย่าง', 'แห่งนั้น', 'ระยะๆ', 'เหตุนั้น', 'ระหว่าง', 'ณ', 'นู้น', 'อะไร', 'ทีเถอะ', 'นี้เอง', 'เมื่อใด', 'ด้วยกัน', 'นอกจากที่', 'พอตัว', 'ยังงั้น', 'ตามๆ', 'เฉกเช่น', 'แค่นั้น', 'ทันใดนั้น', 'คล้าย', 'ช่วงก่อน', 'ตลอดระยะเวลา', 'แท้', 'เนื่องจาก', 'รึว่า', 'คำ', 'ถึงแก่', 'บ่อยกว่า', 'ยืนยัน', 'ทุกอย่าง', 'ถึงเมื่อ', 'ส่วนใด', 'คุณ', 'ไม่ใช่', 'เพิ่ง', 'ทั้งนี้', 'ยังโง้น', 'ปรับ', 'เคย', 'เป็นด้วย', 'ของ', 'ช้าๆ', 'เต็มๆ', 'ภาค', 'เท่าไหร่', 'บางที่', 'นักๆ', 'พวกเขา', 'ทั่ว', 'ภายใต้', 'ทั้งหมด', 'เพื่อที่', 'จวนจะ', 'จัดการ', 'ช่วงหลัง', 'ตลอดปี', 'แต่จะ', 'ร่วมกัน', 'ครับ', 'นับแต่ที่', 'สูงส่ง', 'คราวละ', 'ครั้งๆ', 'สูงๆ', 'มุ่งหมาย', 'วัน', 'อย่างไรก็ได้', 'อย่างๆ', 'จนกระทั่ง', 'เมื่อเช้า', 'ครานั้น', 'เล็กน้อย', 'อย่างไรก็', 'เหลือเกิน', 'กลุ่มก้อน', 'ตามด้วย', 'พร้อมกับ', 'คงจะ', 'ครั้ง', 'แต่ต้อง', 'เมื่อวาน', 'ดังเก่า', 'แท้จริง', 'พร้อมเพียง', 'ทั้งปวง', 'ทุกตัว', 'คราวไหน', 'ตนเอง', 'ตลอดทั้ง', 'ส่วนใหญ่', 'เรื่อยๆ', 'แห่งนี้', 'เยอะๆ', 'ทุกทาง', 'ครัน', 'ไม่ค่อยจะ', 'จับ', 'จนกว่า', 'ถ้า', 'เพียงพอ', 'เสียนั่น', 'ด้าน', 'ที่สุด', 'ชาว', 'เป็นต้นมา', 'เกี่ยวข้อง', 'เยอะแยะ', 'นั้นๆ', 'เท่าที่', 'จ๋า', 'นับแต่นั้น', 'อย่างที่', 'ทั้งเป็น', 'สืบเนื่อง', 'เกินๆ', 'เท่านี้', 'ยังงี้', 'ภายหลัง', 'บัดเดี๋ยวนี้', 'ครบถ้วน', 'ซึ่ง', 'เพียงแค่', 'ค่อนข้างจะ', 'แยะๆ', 'รือว่า', 'เช่นไร', 'แต่อย่างใด', 'พอควร', 'นอกเหนือ', 'นั้น', 'อย่างละ', 'ด้วยประการฉะนี้', 'จัง', 'กันนะ', 'เป็นเพื่อ', 'เช่นที่เคย', 'ด้วยเช่นกัน', 'เป็นแต่', 'ยังแต่', 'เหตุนี้', 'ฉัน', 'ประมาณ', 'ก็ดี', 'นั่น', 'วันไหน', 'ต่างหาก', 'ตลอดทั่ว', 'ช่วงต่อไป', 'ไม่ค่อยเป็น', 'ด้วยว่า', 'บ่อยๆ', 'ค่ะ', 'ซึ่งก็', 'แต่เมื่อ', 'พา', 'เมื่อคราวก่อน', 'ครั้งที่', 'จัดทำ', 'คราวหน้า', 'ส่วนดี', 'ขาด', 'ต่างก็', 'เมื่อคราว', 'เก็บ', 'แค่จะ', 'ยาก', 'ยอมรับ', 'รวมๆ', 'คล้ายกับ', 'ตนฯ', 'ก่อนๆ', 'ก็', 'เช่นเดียวกับ', 'นับตั้งแต่', 'นี้', 'จน', 'ในที่', 'แหละ', 'ยิ่งกว่า', 'เสียนี่', 'เมื่อ', 'สมัยนี้', 'อย่างเช่น', 'แค่', 'สั้นๆ', 'ด้วยที่', 'ลง', 'เน้น', 'สูง', 'เขา', 'แต่ว่า', 'จวบกับ', 'มักจะ', 'ฉะนั้น', 'กระนั้น', 'บัดดล', 'อย่างน้อย', 'เสียจนถึง', 'บางครา', 'เพื่อว่า', 'อย่างหนึ่ง', 'ประกอบ', 'ประการ', 'รับรอง', 'เปิด', 'ที่แท้', 'เช่นใด', 'ตลอดวัน', 'หลังจาก', 'นาง', 'ช่วงนั้น', 'จะได้', 'แต่ไร', 'ต่อกัน', 'ทุกแห่ง', 'อย่างไหน', 'ครั้งหนึ่ง', 'พยายาม', 'พวกมึง', 'แรก', 'แต่นั้น', 'จึงจะ', 'เหล่านั้น', 'ถึงแม้จะ', 'พอเหมาะ', 'เหล่านี้', 'พร้อมกัน', 'มิได้', 'ใต้', 'น่ะ', 'ใหม่ๆ', 'ทํา', 'แต่', 'สั้น', 'นี่ไง', 'ใหญ่โต', 'ทั้งที', 'ด้วยเหตุว่า', 'ทีๆ', 'ครบครัน', 'คุณๆ', 'นับ', 'ที', 'แม้กระทั่ง', 'ขณะใดๆ', 'สิ่งนั้น', 'พร้อม', 'ทุก', 'เช่นดังว่า', 'คราวหนึ่ง', 'คราวๆ', 'แสดงว่า', 'เช่นดังที่', 'ด้วยเพราะ', 'กำลัง', 'ดัง', 'ยิ่งขึ้นไป', 'ซึ่งก็คือ', 'น้อยๆ', 'คราวใด', 'จาก', 'หรือไม่', 'พอๆ', 'พวกโน้น', 'ส่วนมาก', 'ออก', 'เถิด', 'บอก', 'ทีละ', 'หรือเปล่า', 'ใช่', 'ตลอดทั่วถึง', 'เสร็จสิ้น', 'เป็นๆ', 'สิ้น', 'ฝ่าย', 'หมดกัน', 'แม้นว่า', 'ให้มา', 'ทุกๆ', 'ค่อนมาทาง', 'เรียก', 'ทันทีทันใด', 'ครั้งหลังสุด', 'กระทั่ง', 'กระทำ', 'เสร็จแล้ว', 'ใหญ่ๆ', 'เห็นว่า', 'ซึ่งได้แก่', 'หรือยัง', 'เกี่ยวเนื่อง', 'ตั้ง', 'ทั้งตัว', 'เป็นที่', 'แบบ', 'ได้แก่', 'นี่แหละ', 'กู', 'เพิ่มเติม', 'ทั้ง', 'เอง', 'หรือ', 'ให้แก่', 'อาจเป็น', 'บางๆ', 'อาจจะ', 'ภาย', 'ล้วนแต่', 'แต่เพียง', 'เข้า', 'ทาง', 'จนแม้น', 'แต่เดิม', 'จนขณะนี้', 'สบาย', 'พอเพียง', 'เช่นนี้', 'ดังกับ', 'แต่ถ้า', 'ครั้งนี้', 'แก่', 'สูงกว่า', 'ในเมื่อ', 'ค่อนข้าง', 'มิฉะนั้น', 'เช่นดังก่อน', 'ไม่เป็นไร', 'เป็นต้น', 'แม้', 'เชื่อว่า', 'นัก', 'ช่วงๆ', 'ครั้งก่อน', 'เนี่ย', 'มัน', 'ช่วงถัดไป', 'เนี่ยเอง', 'เร็วๆ', 'เสียแล้ว', 'ยิ่งขึ้น', 'ซะ', 'เช่นที่', 'เห็นแก่', 'ตลอดกาลนาน', 'ผล', 'ขวางๆ', 'ซะจนถึง', 'เป็นอัน', 'เท่ากัน', 'สําหรับ', 'กว้างๆ', 'พอจะ', 'สุด', 'บางครั้ง', 'เถอะ', 'ทุกเมื่อ', 'รวมกัน', 'ไกล', 'ดั่งกับว่า', 'พวกที่', 'อย่างยิ่ง', 'ดังเคย', 'จะ', 'ถึงบัดนี้', 'อย่างไรเสีย', 'เชื่อ', 'ก็คือ', 'พอที่', 'จากนั้น', 'คล้ายกันกับ', 'อย่างเดียว', 'บางแห่ง', 'ครั้งไหน', 'มุ่งเน้น', 'ตามที่', 'นอกจาก', 'กว่า', 'หนอ', 'อาจ', 'เพียงไร', 'ก็ได้', 'บ้าง', 'ขณะนี้', 'ทุกวันนี้', 'เร็ว', 'โตๆ', 'จังๆ', 'ยิ่ง', 'เป็นอันว่า', 'พอสมควร', 'มิใช่', 'หลัง', 'เมื่อคืน', 'เชื่อมั่น', 'ที่ว่า', 'ใช่ไหม', 'รึ', 'ตรงๆ', 'ก็ตามที', 'รวมถึง', 'ให้ไป', 'เลย', 'นะ', 'และ', 'ล้วน', 'ราย', 'เหตุผล', 'มากมาย', 'คราหนึ่ง', 'เพียงใด', 'นี่เอง', 'ดังกล่าว', 'ครา', 'จัด', 'ซะจนกระทั่ง', 'สิ่งไหน', 'ที่', 'นั่นไง', 'กันดีไหม', 'แค่นี้', 'ดั่งกับ', 'เผื่อที่', 'สำคัญ', 'มา', 'ถึงบัดนั้น', 'ทุกสิ่ง', 'ยิ่งจะ', 'ทุกครั้ง', 'เป็นแต่เพียง', 'มัก', 'ขั้น', 'หากแม้น', 'กัน', 'อื่นๆ', 'แล้วกัน', 'อันได้แก่', 'ขณะที่', 'ไหน', 'สมัยโน้น', 'คราวที่', 'กล่าว', 'มั้ยนั่น', 'อันที่จะ', 'ได้', 'เสร็จสมบูรณ์', 'แก้ไข', 'คราใด', 'เดียวกัน', 'เพียงเพราะ', 'ย่อม', 'ทันที', 'อย่างมาก', 'ขณะ', 'ครั้งใด', 'ล้วนจน', 'ยิ่งแล้ว', 'ร่วมด้วย', 'ฝ่ายใด', 'เกือบ', 'วันนี้', 'ผิด', 'อยาก', 'ไร', 'ยัง'}\n"
          ]
        }
      ],
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.corpus.common import thai_stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(set(thai_stopwords()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (10706, 3615)\n",
            "Val shape: (1339, 3615)\n",
            "Test shape: (1340, 3615)\n",
            "Number of features: 3615\n",
            "Sample TF-IDF Features (First 5 training samples):\n",
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 15 stored elements and shape (1, 3615)>\n",
            "  Coords\tValues\n",
            "  (0, 2582)\t0.15335071962729047\n",
            "  (0, 1065)\t0.10887956336518148\n",
            "  (0, 2376)\t0.12784073325007023\n",
            "  (0, 1445)\t0.2091753985526012\n",
            "  (0, 3216)\t0.24593021912326413\n",
            "  (0, 177)\t0.24833353650083592\n",
            "  (0, 434)\t0.27233973099167436\n",
            "  (0, 1499)\t0.1642673698623802\n",
            "  (0, 1349)\t0.4665220808838139\n",
            "  (0, 1714)\t0.2926490948729209\n",
            "  (0, 761)\t0.48161481885581436\n",
            "  (0, 1974)\t0.17203910879251177\n",
            "  (0, 2390)\t0.19466884830085984\n",
            "  (0, 2526)\t0.257246993019674\n",
            "  (0, 1017)\t0.11098951226265677\n"
          ]
        }
      ],
      "source": [
        "pythainlp_tokenizer = lambda x: word_tokenize(x, engine=\"newmm\", keep_whitespace=False)\n",
        "\n",
        "# Extract tokenized text and labels\n",
        "train_texts, train_labels = dataset[\"train\"][\"input\"], dataset[\"train\"][\"label\"]\n",
        "val_texts, val_labels = dataset[\"val\"][\"input\"], dataset[\"val\"][\"label\"]\n",
        "test_texts, test_labels = dataset[\"test\"][\"input\"], dataset[\"test\"][\"label\"]\n",
        "\n",
        "# Initialize and fit TF-IDF Vectorizer on training data\n",
        "vectorizer = TfidfVectorizer(tokenizer=pythainlp_tokenizer, max_df=0.7, min_df=1)\n",
        "X_train_tfidf = vectorizer.fit_transform(train_texts)  # Fit and transform training data\n",
        "\n",
        "X_val_tfidf = vectorizer.transform(val_texts)  # Transform validation data\n",
        "X_test_tfidf = vectorizer.transform(test_texts)  # Transform test data\n",
        "\n",
        "# Print shape of TF-IDF matrices\n",
        "print(\"Train shape:\", X_train_tfidf.shape)\n",
        "print(\"Val shape:\", X_val_tfidf.shape)\n",
        "print(\"Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# vectorizer get feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"Number of features:\", len(feature_names))\n",
        "\n",
        "# Print first 5 samples of processed train data\n",
        "print(\"Sample TF-IDF Features (First 5 training samples):\")\n",
        "print(X_train_tfidf[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of OOV words in validation set: 190\n",
            "Number of OOV words in test set: 185\n",
            "OOV ratio in validation set: 0.05255878284923928\n",
            "OOV ratio in test set: 0.051175656984785614\n"
          ]
        }
      ],
      "source": [
        "# check for oov in test and val set\n",
        "word_dict = vectorizer.get_feature_names_out()\n",
        "\n",
        "oov_set = set()\n",
        "\n",
        "def get_oov_words(texts):\n",
        "    oov_set = set()\n",
        "    for text in texts:\n",
        "        for word in pythainlp_tokenizer(text):\n",
        "            if word not in word_dict:\n",
        "                oov_set.add(word)\n",
        "    return oov_set\n",
        "\n",
        "oov_val = get_oov_words(val_texts)\n",
        "oov_test = get_oov_words(test_texts)\n",
        "\n",
        "print(\"Number of OOV words in validation set:\", len(oov_val))\n",
        "print(\"Number of OOV words in test set:\", len(oov_test))\n",
        "print(\"OOV ratio in validation set:\", len(oov_val) / len(word_dict))\n",
        "print(\"OOV ratio in test set:\", len(oov_test) / len(word_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define a LogisticRegression model with tf-idf as feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import from sklearn that automatically select the best hyperparameter\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
        "    \"penalty\": [\"l1\", \"l2\"],\n",
        "    \"solver\": [\"liblinear\"]\n",
        "}\n",
        "\n",
        "# Initialize the GridSearchCV object\n",
        "grid_search = GridSearchCV( estimator=LogisticRegression(max_iter=1000, class_weight=\"balanced\"), \n",
        "                            param_grid=param_grid, \n",
        "                            cv=5, \n",
        "                            n_jobs=-1, \n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.2s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.2s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.5s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.5s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.6s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.5s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.8s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.8s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.8s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.8s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.9s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.8s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.0s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.9s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.9s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   0.9s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.3s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.2s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.3s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.4s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.4s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.2s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.7s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   2.7s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   2.7s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   2.0s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.6s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.6s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   3.9s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.1s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.4s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.3s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.4s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.1s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   8.5s\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/svm/_base.py:1249: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=  11.2s\n"
          ]
        }
      ],
      "source": [
        "# Fit the GridSearchCV object on the training data\n",
        "grid_search.fit(X_train_tfidf, train_labels)\n",
        "\n",
        "# get the best model\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=10, class_weight='balanced', max_iter=1000,\n",
              "                   solver='liblinear')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7326362957430919\n",
            "Test Accuracy: 0.7231343283582089\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        payment       0.64      0.73      0.68        64\n",
            "        package       0.76      0.69      0.72       180\n",
            "        suspend       0.77      0.81      0.79        73\n",
            "       internet       0.75      0.77      0.76       179\n",
            "   phone_issues       0.63      0.72      0.67        58\n",
            "        service       0.85      0.70      0.77       211\n",
            "    nontruemove       0.42      0.64      0.51        25\n",
            "        balance       0.85      0.74      0.80       149\n",
            "         detail       0.44      0.52      0.47        33\n",
            "           bill       0.67      0.83      0.74        54\n",
            "         credit       0.71      0.88      0.79        17\n",
            "      promotion       0.72      0.68      0.70       115\n",
            " mobile_setting       0.48      0.50      0.49        28\n",
            "       iservice       1.00      1.00      1.00         2\n",
            "        roaming       0.81      0.88      0.85        25\n",
            "      truemoney       0.89      0.68      0.77        25\n",
            "    information       0.51      0.70      0.59        30\n",
            "    lost_stolen       0.81      0.91      0.86        23\n",
            "balance_minutes       0.60      0.60      0.60         5\n",
            "            idd       0.86      0.90      0.88        20\n",
            "        garbage       0.00      0.00      0.00         5\n",
            "       ringtone       0.67      0.75      0.71         8\n",
            "           rate       0.17      0.33      0.22         3\n",
            "   loyalty_card       0.83      0.83      0.83         6\n",
            "        contact       0.00      0.00      0.00         1\n",
            "        officer       0.00      0.00      0.00         1\n",
            "\n",
            "       accuracy                           0.72      1340\n",
            "      macro avg       0.61      0.65      0.62      1340\n",
            "   weighted avg       0.74      0.72      0.73      1340\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the best model on the validation data\n",
        "val_preds = best_model.predict(X_val_tfidf)\n",
        "val_acc = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_acc)\n",
        "\n",
        "test_preds = best_model.predict(X_test_tfidf)\n",
        "test_acc = accuracy_score(test_labels, test_preds)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "\n",
        "# Generate classification report on test data\n",
        "print(classification_report(test_labels, test_preds, target_names=num_2_label_map.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wql2YeU8qFQ6"
      },
      "source": [
        "# Model 2 MUSE\n",
        "\n",
        "Build a simple logistic regression model using features from the MUSE model.\n",
        "\n",
        "Which MUSE model will you use? Why?\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "MUSE is typically used with tensorflow. However, there are some pytorch conversions made by some people.\n",
        "\n",
        "https://huggingface.co/sentence-transformers/use-cmlm-multilingual\n",
        "https://huggingface.co/dayyass/universal-sentence-encoder-multilingual-large-3-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3UtkpaLnctH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDHfX377rnp_"
      },
      "source": [
        "# Model 3 WangchanBERTa\n",
        "\n",
        "We ask you to train a WangchanBERTa-based model.\n",
        "\n",
        "We recommend you use the thaixtransformers fork (which we used in the PoS homework).\n",
        "https://github.com/PyThaiNLP/thaixtransformers\n",
        "\n",
        "The structure of the code will be very similar to the PoS homework. You will also find the huggingface [tutorial](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) useful. Or you can also add a softmax layer by yourself just like in the previous homework.\n",
        "\n",
        "Which WangchanBERTa model will you use? Why? (Don't forget to clean your text accordingly).\n",
        "\n",
        "**Ans:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI8SvILyub0m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D7qsVL0BaXS"
      },
      "source": [
        "After you"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr9_0DnMBcFZ"
      },
      "source": [
        "# Comparison\n",
        "\n",
        "After you have completed the 3 models, compare the accuracy, ease of implementation, and inference speed (from cleaning, tokenization, till model compute) between the three models in mycourseville."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "colab-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
