{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Thai N-NER: Thai Nested Named Entity Recognition"
      ],
      "metadata": {
        "id": "JtbN817bgMKl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This demo notebook provides a tutorial on using Thai N-NER, with references from [Thai N-NER](https://medium.com/airesearch-in-th/thai-n-ner-thai-nested-named-entity-recognition-1969f8fe91f0)\n",
        "\n",
        "Learn more about Thai N-NER here : [Thai N-NER](https://medium.com/airesearch-in-th/thai-n-ner-thai-nested-named-entity-recognition-1969f8fe91f0)"
      ],
      "metadata": {
        "id": "Qx3LanXugYwR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FOy4tFSvbUUF"
      },
      "source": [
        "## 1. Setup and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "OCej2IpilGT1",
        "outputId": "3b55ed1f-905a-41e5-92d9-f45600e50a84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seqeval in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.26.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.11/dist-packages (from seqeval) (1.6.1)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.5.0)\n",
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.11/dist-packages (5.0.5)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp) (2024.12.14)\n",
            "Requirement already satisfied: transformers==4.29.2 in /usr/local/lib/python3.11/dist-packages (4.29.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2) (2.32.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2) (0.13.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.29.2) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.2) (2024.10.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers==4.29.2) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.29.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.29.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.29.2) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.29.2) (2024.12.14)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: thai_nner in /usr/local/lib/python3.11/dist-packages (0.3)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.11/dist-packages (from thai_nner) (2.5.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from thai_nner) (0.20.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from thai_nner) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from thai_nner) (4.67.1)\n",
            "Requirement already satisfied: tensorboard>=1.14 in /usr/local/lib/python3.11/dist-packages (from thai_nner) (2.17.1)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (from thai_nner) (4.29.2)\n",
            "Requirement already satisfied: pythainlp in /usr/local/lib/python3.11/dist-packages (from thai_nner) (5.0.5)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from thai_nner) (0.2.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->thai_nner) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->thai_nner) (1.69.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->thai_nner) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->thai_nner) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->thai_nner) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->thai_nner) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->thai_nner) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->thai_nner) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.14->thai_nner) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (3.17.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (12.1.105)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.1->thai_nner) (1.13.1)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.1->thai_nner) (12.6.85)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.1->thai_nner) (1.3.0)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.11/dist-packages (from pythainlp->thai_nner) (2.32.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision->thai_nner) (11.1.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /usr/local/lib/python3.11/dist-packages (from transformers->thai_nner) (0.27.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers->thai_nner) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers->thai_nner) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.11/dist-packages (from transformers->thai_nner) (0.13.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp->thai_nner) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp->thai_nner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp->thai_nner) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.22.0->pythainlp->thai_nner) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.14->thai_nner) (3.0.2)\n",
            "Collecting protobuf==3.20.3\n",
            "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
            "Downloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-metadata 1.16.1 requires protobuf<6.0.0dev,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "d2255d64c5c249aea1a0cfb7713e1806"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install seqeval\n",
        "!pip install pythainlp\n",
        "!pip install transformers==4.29.2\n",
        "!pip install sentencepiece\n",
        "!pip install gdown\n",
        "!pip install thai_nner\n",
        "!pip install protobuf==3.20.3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model checkpoints"
      ],
      "metadata": {
        "id": "OmmNNtCZuc84"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Thai N-NER provides necessary resources, including models, datasets, and pre-trained language models, available here : [Thai N-NER (resources)](https://drive.google.com/drive/folders/1Dy-360iZ9hIA-xA0yizSwmpM8sx6rrjJ?usp=sharing)"
      ],
      "metadata": {
        "id": "5THh4l5miJmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To utilize this, please follow these steps::\n",
        "\n",
        "1. Add the Shared Folder [Thai N-NER (resources)](https://drive.google.com/drive/folders/1Dy-360iZ9hIA-xA0yizSwmpM8sx6rrjJ?usp=sharing)  to Your Google Drive.\n",
        "* first open the shared folder link in your web browser\n",
        "* Click the folder named \"thai-nner\" at the top of the page.\n",
        "* In the menu bar, click \"Organize\", then click \"Add shortcut\" to Drive (you may see an icon that looks like a Drive logo with a plus sign)\n",
        "* Select \"My Drive\"\n"
      ],
      "metadata": {
        "id": "97UzrHEUuTEg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nt6m1CowIy4N",
        "outputId": "3d32f3bc-2577-4968-90c0-4ce89599941d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Thai-NNER'...\n",
            "remote: Enumerating objects: 274, done.\u001b[K\n",
            "remote: Counting objects: 100% (35/35), done.\u001b[K\n",
            "remote: Compressing objects: 100% (33/33), done.\u001b[K\n",
            "remote: Total 274 (delta 16), reused 5 (delta 2), pack-reused 239 (from 1)\u001b[K\n",
            "Receiving objects: 100% (274/274), 5.23 MiB | 10.03 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n",
            "/content/Thai-NNER\n"
          ]
        }
      ],
      "source": [
        "# Clone github\n",
        "!git clone https://github.com/vistec-AI/Thai-NNER.git\n",
        "%cd /content/Thai-NNER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSwO2C8bbXy9"
      },
      "source": [
        "# Mount your drive to Google Colab."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lSWhdrPSQdLT",
        "outputId": "8c9f85a4-a2e2-4852-aaf6-dd1aab45251d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "# Load data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "# Create symbolic links\n",
        "!ln -s \"/content/drive/MyDrive/thai-nner/lm\" ./data/lm\n",
        "!ln -s \"/content/drive/MyDrive/thai-nner/checkpoints\" ./data/checkpoints"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK0rqX03a5k4"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIPgzaFwbFHI"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import torch\n",
        "import argparse\n",
        "from tqdm import tqdm\n",
        "from tabulate import tabulate\n",
        "\n",
        "from utils.unique import unique\n",
        "import model.loss as module_loss\n",
        "import model.model as module_arch\n",
        "import model.metric as module_metric\n",
        "from parse_config import ConfigParser\n",
        "import data_loader.data_loaders as module_data\n",
        "\n",
        "PAD = '<pad>'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NCCAfGMa9rI"
      },
      "outputs": [],
      "source": [
        "resume = 'data/checkpoints/1102_151935/checkpoint.pth'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9KF4xBfbGDz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22984f39-6b1b-47b8-ba1e-2fa222411588"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint: data/checkpoints/1102_151935/checkpoint.pth ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-31-31ceea9251e1>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(config.resume)\n"
          ]
        }
      ],
      "source": [
        "args = argparse.ArgumentParser(description='PyTorch Template')\n",
        "args.add_argument('-c', '--config', default=None, type=str, help='config file path (default: None)')\n",
        "args.add_argument('-r', '--resume', default=f\"{resume}\", type=str, help='path to latest checkpoint (default: None)')\n",
        "args.add_argument('-d', '--device', default=None, type=str, help='indices of GPUs to enable (default: all)')\n",
        "args.add_argument('-f', '--file', default=None, type=str, help='Error')\n",
        "config = ConfigParser.from_args(args)\n",
        "logger = config.get_logger('test')\n",
        "\n",
        "# build model architecturea\n",
        "model = config.init_obj('arch', module_arch)\n",
        "\n",
        "# get function handles of loss and metrics\n",
        "criterion = getattr(module_loss, config['loss'])\n",
        "metric_fns = [getattr(module_metric, met) for met in config['metrics']]\n",
        "\n",
        "logger.info('Loading checkpoint: {} ...'.format(config.resume))\n",
        "checkpoint = torch.load(config.resume)\n",
        "state_dict = checkpoint['state_dict']\n",
        "\n",
        "if config['n_gpu'] > 1:\n",
        "    model = torch.nn.DataParallel(model)\n",
        "\n",
        "model.load_state_dict(state_dict)\n",
        "layers_train = config._config['trainer']['layers_train']\n",
        "\n",
        "# prepare model for testing\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "total_loss = 0.0\n",
        "total_metrics = torch.zeros(len(metric_fns))\n",
        "# logger.info(model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading only few testing examples.\n",
        "config.config['data_loader']['args']['sample_data'] = True\n",
        "\n",
        "data_loader = config.init_obj('data_loader', module_data)\n",
        "test_data_loader = data_loader.get_test()"
      ],
      "metadata": {
        "id": "o_DMcY49-3nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Now, Let's try using the pre-trained Thai N-NER model checkpoint to perform inference and predict NE tags."
      ],
      "metadata": {
        "id": "ohj_vlyCmnV1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quYDawPSbLAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2775ff1c-c2aa-4c28-dc0c-fcb203822490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>||วันนี้|วันที่||27||มกราคม||25|68||เป็น|วันที่||อากาศ||ดีมาก||</s> \n",
            "\n",
            "[2, 3]         rel            วันนี้\n",
            "[3, 6]         day            วันที่27\n",
            "[3, 11]        date           วันที่27มกราคม2568\n",
            "[5, 6]         cardinal       27\n",
            "[7, 8]         month          มกราคม\n",
            "[9, 11]        year           2568\n"
          ]
        }
      ],
      "source": [
        "from utils.prediction import predict, get_dict_prediction, show\n",
        "\n",
        "\n",
        "\n",
        "text = \" วันนี้วันที่ 27 มกราคม 2568 เป็นวันที่อากาศดีมาก \"\n",
        "\n",
        "\n",
        "tokens, out = predict(model, text, data_loader, config)\n",
        "tokens = [tk for tk in tokens if tk!=PAD]\n",
        "print(\"|\".join(tokens), \"\\n\")\n",
        "[show(x) for x in out];"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"คณะกรรมการ 40 ปี 14 ตุลาเพื่อประชาธิปไตรสมบูรณ์\"\n",
        "tokens, out = predict(model, text, data_loader, config)\n",
        "tokens = [tk for tk in tokens if tk!=PAD]\n",
        "print(\"|\".join(tokens), \"\\n\")\n",
        "[show(x) for x in out];"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "am_9zGIwpeTD",
        "outputId": "76e69cf5-1828-47e1-d245-873f1ca9eb48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>||คณะกรรมการ||40||ปี||14|||ตุ|ลา|เพื่อ||ประชา||ธิ|ป||ไต|ร||สมบูรณ์|</s> \n",
            "\n",
            "[4, 5]         cardinal       40\n",
            "[4, 7]         duration       40ปี\n",
            "[6, 7]         unit           ปี\n",
            "[8, 9]         day            14\n",
            "[8, 13]        date           14ตุลา\n",
            "[10, 13]       month          ตุลา\n",
            "[14, 24]       norp_political ประชาธิปไตรสมบูรณ์\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" วันที่ 18 มกราคม 2568 เมื่อเวลา 11.15 น. ที่จ.นครพนม นายทักษิณ ชินวัตร อดีตนายกฯ ให้สัมภาษณ์กรณีนายชาดา ไทยเศรษฐ์ อดีต รมช.มหาดไทย เซ็นคำสั่งเพิกถอนที่ดินสนามกอล์ฟอัลไพน์ กลับคืนเป็นที่ธรณีสงฆ์ ก่อนหมดวาระเพียงไม่กี่วัน \"\n",
        "tokens, out = predict(model, text, data_loader, config)\n",
        "tokens = [tk for tk in tokens if tk!=PAD]\n",
        "print(\"|\".join(tokens), \"\\n\")\n",
        "[show(x) for x in out];"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6ZNz615w_Qv",
        "outputId": "fa402d8d-6997-4296-b17f-f9ac33442a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>||วันที่||18||มกราคม||25|68||เมื่อ|เวลา||11.|15||น|.||ที่|จ|.||นคร|พ|นม||นาย||ทักษิณ|||ชิน|วั|ตร|||อดีต|นาย|ก|ฯ||ให้||สัมภาษณ์||กรณี|นาย||ชา||ดา|||ไทย||เศรษฐ|์|||อดีต|||รม|ช|.|ม|หาด|ไทย|||เซ็น||คําสั่ง||เพ|ิก|ถอน||ที่ดิน||สนาม|กอล์ฟ||อัล|ไพ|น์|||กลับ|คืน|เป็น|ที่|ธร|ณี|สงฆ์||ก่อน||หมด|วา|ระ||เพียง|ไม่||กี่|วัน||</s> \n",
            "\n",
            "[2, 5]         day            วันที่18\n",
            "[2, 10]        date           วันที่18มกราคม2568\n",
            "[4, 5]         cardinal       18\n",
            "[6, 7]         month          มกราคม\n",
            "[8, 10]        year           2568\n",
            "[12, 19]       time           เวลา11.15น.\n",
            "[14, 16]       cardinal       11.15\n",
            "[14, 19]       time           11.15น.\n",
            "[17, 19]       unit           น.\n",
            "[21, 27]       province       จ.นครพนม\n",
            "[23, 27]       province       นครพนม\n",
            "[28, 29]       title          นาย\n",
            "[28, 36]       person         นายทักษิณชินวัตร\n",
            "[29, 31]       firstname      ทักษิณ\n",
            "[32, 36]       last           ชินวัตร\n",
            "[37, 42]       role           อดีตนายกฯ\n",
            "[48, 49]       title          นาย\n",
            "[48, 59]       person         นายชาดาไทยเศรษฐ์\n",
            "[49, 53]       firstname      ชาดา\n",
            "[54, 59]       last           ไทยเศรษฐ์\n",
            "[60, 70]       role           อดีตรมช.มหาดไทย\n",
            "[67, 70]       goverment      มหาดไทย\n",
            "[81, 88]       facility_other สนามกอล์ฟอัลไพน์\n",
            "[84, 88]       facility_other อัลไพน์\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \" สธ.กางตัวเลขเบื้องต้นคนป่วยจากปัญหาฝุ่น PM2.5 แค่ 3 สัปดาห์ของเดือน ม.ค.พุ่ง 144,000 คนส่วนใหญ่ผิวหนัง ตาอักเสบ โรคหืด พบ 5 จังหวัดค่าฝุ่นเกิน 75 มคก.ต่อ ลบ.ม.ต่อเนื่องเกิน 3 ในระดับสีแดง \"\n",
        "tokens, out = predict(model, text, data_loader, config)\n",
        "tokens = [tk for tk in tokens if tk!=PAD]\n",
        "print(\"|\".join(tokens), \"\\n\")\n",
        "[show(x) for x in out];"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BoB0-oIFnd0E",
        "outputId": "ad4488c0-842e-4c96-9f79-df27133edb56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s>||ส|ธ||.||กา|ง||ตัวเลข||เบื้องต้น|คน|ป่วย|จาก||ปัญหา||ฝุ่น||PM|2.5|||แค่||3|||สัปดาห์|ของ|เดือน||ม|.|ค|.||พุ่ง||14|4,000||คน||ส่วนใหญ่||ผิวหนัง|||ตา||อักเสบ|||โรค|ห|ืด|||พบ||5||จังหวัด|ค่า||ฝุ่น||เกิน||75||ม|ค|ก|.|ต่อ|||ลบ||.|ม|.||ต่อเนื่อง||เกิน||3||ใน||ระดับ||สีแดง||</s> \n",
            "\n",
            "[2, 6]         goverment      สธ.\n",
            "[21, 23]       natural_disasterPM2.5\n",
            "[22, 23]       cardinal       2.5\n",
            "[26, 31]       duration       3สัปดาห์\n",
            "[27, 28]       cardinal       3\n",
            "[29, 31]       unit           สัปดาห์\n",
            "[32, 38]       month          เดือนม.ค.\n",
            "[34, 38]       month          ม.ค.\n",
            "[41, 43]       cardinal       144,000\n",
            "[41, 45]       quantity       144,000คน\n",
            "[44, 45]       unit           คน\n",
            "[50, 54]       disease        ตาอักเสบ\n",
            "[63, 64]       cardinal       5\n",
            "[63, 66]       quantity       5จังหวัด\n",
            "[65, 66]       unit           จังหวัด\n",
            "[72, 73]       cardinal       75\n",
            "[91, 92]       cardinal       3\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}