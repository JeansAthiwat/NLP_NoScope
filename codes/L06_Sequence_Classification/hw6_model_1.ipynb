{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8FRFIYMc5X"
      },
      "source": [
        "# HOMEWORK 6: TEXT CLASSIFICATION\n",
        "In this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n",
        "1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancle)\n",
        "2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming)\n",
        "\n",
        "We will focus only on the Object Classification task for this homework.\n",
        "\n",
        "In this homework, you are asked compare different text classification models in terms of accuracy and inference time.\n",
        "\n",
        "You will need to build 3 different models.\n",
        "\n",
        "1. A model based on tf-idf\n",
        "2. A model based on MUSE\n",
        "3. A model based on wangchanBERTa\n",
        "\n",
        "**You will be ask to submit 3 different files (.pdf from .ipynb) that does the 3 different models. Finally, answer the accuracy and runtime numbers in MCV.**\n",
        "\n",
        "This homework is quite free form, and your answer may vary. We hope that the processing during the course of this assignment will make you think more about the design choices in text classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRlx5Mb5zkXw",
        "outputId": "18d913e0-aa6d-435b-931d-591386cb4ba8"
      },
      "outputs": [],
      "source": [
        "# !wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv\n",
        "# !pip install pythainlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YprqbOPMc5a"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "heICP79cMc5e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from IPython.display import display\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#My import \n",
        "np.random.seed(42)\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaUf4PLMc5k"
      },
      "source": [
        "## Loading data\n",
        "First, we load the data from disk into a Dataframe.\n",
        "\n",
        "A Dataframe is essentially a table, or 2D-array/Matrix with a name for each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JhZ2eBAWMc5l"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('clean-phone-data-for-students.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cje3yruTMc5p"
      },
      "source": [
        "Let's preview the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "aNqRNz1PMc5q",
        "outputId": "e129a502-1420-476c-dc50-46c293a01b56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>payment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>package</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n",
              "      <td>report</td>\n",
              "      <td>suspend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>internet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n",
              "      <td>report</td>\n",
              "      <td>phone_issues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Sentence Utterance   Action        Object\n",
              "0   <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire       payment\n",
              "1               internet ยังความเร็วอยุ่เท่าไหร ครับ  enquire       package\n",
              "2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   report       suspend\n",
              "3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...  enquire      internet\n",
              "4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   report  phone_issues"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show the top 5 rows\n",
        "display(data_df.head())\n",
        "# Summarize the data\n",
        "data_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGd8BNvMMc5y"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "We call the DataFrame.describe() again.\n",
        "Notice that there are 33 unique labels/classes for object and 10 unique labels for action that the model will try to predict.\n",
        "But there are unwanted duplications e.g. Idd,idd,lotalty_card,Lotalty_card\n",
        "\n",
        "Also note that, there are 13389 unqiue sentence utterances from 16175 utterances. You have to clean that too!\n",
        "\n",
        "## #TODO 0.1:\n",
        "You will have to remove unwanted label duplications as well as duplications in text inputs.\n",
        "Also, you will have to trim out unwanted whitespaces from the text inputs.\n",
        "This shouldn't be too hard, as you have already seen it in the demo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "V0bGLblVMc5z",
        "outputId": "1a65aff5-6196-4674-fb5d-36aa1afcfdba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
              "       'service', 'nonTrueMove', 'balance', 'detail', 'bill', 'credit',\n",
              "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
              "       'information', 'lost_stolen', 'balance_minutes', 'idd',\n",
              "       'TrueMoney', 'garbage', 'Payment', 'IDD', 'ringtone', 'Idd',\n",
              "       'rate', 'loyalty_card', 'contact', 'officer', 'Balance', 'Service',\n",
              "       'Loyalty_card'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['enquire', 'report', 'cancel', 'Enquire', 'buy', 'activate',\n",
              "       'request', 'Report', 'garbage', 'change'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(data_df.describe())\n",
        "display(data_df.Object.unique())\n",
        "display(data_df.Action.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "19onNNUZMc54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>clean_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13385</td>\n",
              "      <td>13385</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13385</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       input clean_label\n",
              "count                                  13385       13385\n",
              "unique                                 13385          26\n",
              "top     สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ     service\n",
              "freq                                       1        2108"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO.1: Data cleaning\n",
        "\n",
        "# select only the columns that we need\n",
        "data_df = data_df[['Sentence Utterance', 'Object']]\n",
        "data_df.columns = ['input', 'raw_label']\n",
        "\n",
        "# remove duplicate labels\n",
        "data_df['clean_label'] = data_df['raw_label'].str.lower().copy()\n",
        "data_df.drop('raw_label', axis=1, inplace=True)\n",
        "\n",
        "# ! input to lower case (helps with OOV token)\n",
        "data_df['input'] = data_df['input'].str.lower()\n",
        "\n",
        "# remove duplicate input rows\n",
        "data_df = data_df.drop_duplicates(\"input\", keep=\"first\")\n",
        "display(data_df.describe())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# map label to number and convert to numpy \"data\"\n",
        "data = data_df.to_numpy()\n",
        "unique_label = data_df.clean_label.unique()\n",
        "\n",
        "label_2_num_map = dict(zip(unique_label, range(len(unique_label))))\n",
        "num_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n",
        "\n",
        "# convert label to number\n",
        "data[:,1] = np.vectorize(label_2_num_map.get)(data[:,1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Input string cleaning\n",
        "def strip_str(string):\n",
        "    return string.strip()\n",
        "     \n",
        "# Trim of extra begining and trailing whitespace in the string\n",
        "data[:,0] = np.vectorize(strip_str)(data[:,0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Keep in mind class is imbalance type shi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIxnPRiAmrhN"
      },
      "source": [
        "Split data into train, valdation, and test sets (normally the ratio will be 80:10:10 , respectively). We recommend to use train_test_spilt from scikit-learn to split the data into train, validation, test set.\n",
        "\n",
        "In addition, it should split the data that distribution of the labels in train, validation, test set are similar. There is **stratify** option to handle this issue.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "Make sure the same data splitting is used for all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EYzMrvb7nYR2"
      },
      "outputs": [],
      "source": [
        "X = data[:,0]\n",
        "y = data[:,1]\n",
        "\n",
        "X_class_24, y_class_24 = X[y == 24], y[y == 24] #handle class 24 with only 4 samples\n",
        "X, y = X[y != 24], y[y != 24] # remove class 24 from the data to add it later\n",
        "\n",
        "random_idx = np.random.choice(len(X_class_24), 2, replace=False)\n",
        "\n",
        "X_class_24_val, X_class_24_test = X_class_24[random_idx[0]], X_class_24[random_idx[1]]\n",
        "y_class_24_val, y_class_24_test = y_class_24[random_idx[0]], y_class_24[random_idx[1]]\n",
        "\n",
        "X_class_24_train = np.delete(X_class_24, random_idx)\n",
        "y_class_24_train = np.delete(y_class_24, random_idx)\n",
        "\n",
        "# train val test split 80:10:10\n",
        "X_train, X_tmp, y_train, y_tmp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_tmp, y_tmp, test_size=0.5, stratify=y_tmp, random_state=42)\n",
        "\n",
        "# add class 24 to the train, val, test set\n",
        "X_train, y_train = np.append(X_train, X_class_24_train), np.append(y_train, y_class_24_train)\n",
        "X_val, y_val = np.append(X_val, X_class_24_val), np.append(y_val, y_class_24_val)\n",
        "X_test, y_test = np.append(X_test, X_class_24_test), np.append(y_test, y_class_24_test)\n",
        "\n",
        "#check label distribution\n",
        "# display(np.unique(y_train, return_counts=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['อยากจะสอบถามทรูมูฟ เอช 3g ที่ตำบลบ้านกลาง มีสัญญาณหรือเปล่าค่ะ', 'เติมเงินแล้วไม่ได้', 'จะเติมเงินต้องทำยังไง', 'ถ้าจะซื้อ เดอะ นิวไอแพด ใช้บัตรอะไรรูดได้บ้าง', 'เมื่อคืนนี้ผมโทรมาแจ้งเรื่องโทรศัพท์หาไม่เจอ และระงับไว้ ตอนนี้เจอ อยู่ใต้เบาะรถ ต้องการเปิดสัญญาณการใช้งาน']\n",
            "[4, 0, 0, 16, 5]\n",
            "{'payment': 0, 'package': 1, 'suspend': 2, 'internet': 3, 'phone_issues': 4, 'service': 5, 'nontruemove': 6, 'balance': 7, 'detail': 8, 'bill': 9, 'credit': 10, 'promotion': 11, 'mobile_setting': 12, 'iservice': 13, 'roaming': 14, 'truemoney': 15, 'information': 16, 'lost_stolen': 17, 'balance_minutes': 18, 'idd': 19, 'garbage': 20, 'ringtone': 21, 'rate': 22, 'loyalty_card': 23, 'contact': 24, 'officer': 25}\n"
          ]
        }
      ],
      "source": [
        "def create_dataset_dict(dataset, data_split, split_name, keep_ws=False):\n",
        "    for input_str, label in data_split:\n",
        "        dataset[split_name][\"input\"].append(input_str)\n",
        "        dataset[split_name][\"label\"].append(label)\n",
        "\n",
        "dataset = { \"train\": {\"input\": [], \"label\": []},\n",
        "            \"val\": {\"input\": [], \"label\": []},\n",
        "            \"test\": {\"input\": [], \"label\": []} ,\n",
        "            'label_2_num_map': label_2_num_map,\n",
        "            'num_2_label_map': num_2_label_map\n",
        "            }\n",
        "\n",
        "create_dataset_dict(dataset, zip(X_train, y_train), \"train\")\n",
        "create_dataset_dict(dataset, zip(X_val, y_val), \"val\")\n",
        "create_dataset_dict(dataset, zip(X_test, y_test), \"test\")\n",
        "\n",
        "# save as pickle\n",
        "import pickle\n",
        "with open('template_cleaned_dataset.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset, f)\n",
        "\n",
        "print(dataset[\"train\"][\"input\"][:5])\n",
        "print(dataset[\"train\"][\"label\"][:5])\n",
        "print(dataset[\"label_2_num_map\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx6gllzrnVVU"
      },
      "source": [
        "# Model 1 TF-IDF\n",
        "\n",
        "Build a model to train a tf-idf text classifier. Use a simple logistic regression model for the classifier.\n",
        "\n",
        "For this part, you may find this [tutorial](https://scikit-learn.org/stable/auto_examples/text/plot_document_classification_20newsgroups.html#sphx-glr-auto-examples-text-plot-document-classification-20newsgroups-py) helpful.\n",
        "\n",
        "Below are some design choices you need to consider to accomplish this task. Be sure to answer them when you submit your model.\n",
        "\n",
        "What tokenizer will you use? Why?\n",
        "\n",
        "**Ans:** -> **\"newmm\"** . fast and efficient (Good enough acc on BEST test benchmark word level tokenization)\n",
        "\n",
        "Will you ignore some stop words (a, an, the, to, etc. for English) in your tf-idf? Is it important?\n",
        "PythaiNLP provides a list of stopwords if you want to use (https://pythainlp.org/docs/2.0/api/corpus.html#pythainlp.corpus.common.thai_stopwords)\n",
        "\n",
        "**Ans:** I will not use stop word. but instead use the TfidfVectorizer()'s 'max_df' to cut out to frequent words.\n",
        "\n",
        "The dictionary of TF-IDF is usually based on the training data. How many words in the test set are OOVs?\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "- Number of OOV words in validation set: 190\n",
        "- Number of OOV words in test set: 185\n",
        "- OOV ratio in validation set: 0.05255878284923928\n",
        "- OOV ratio in test set: 0.051175656984785614"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9vOqTqmfufsT"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'รับ', 'ไม่ใช่', 'เอง', 'เช่นดังว่า', 'นั่น', 'ช่วงท้าย', 'จรดกับ', 'ซึ่งกันและกัน', 'จัด', 'กันนะ', 'เช่นที่', 'จนแม้', 'กว้าง', 'นี้แหล่', 'ถึงบัดนี้', 'คราวนั้น', 'ที่แห่งนั้น', 'ถึงแม้ว่า', 'เอ็ง', 'จำ', 'ที่ได้', 'จังๆ', 'เผื่อที่', 'ต่างหาก', 'ทุกเมื่อ', 'ทุกคราว', 'ล้วนจน', 'ทุกๆ', 'ถึง', 'ไม่ว่า', 'เป็นต้น', 'บางกว่า', 'แค่', 'หมดกัน', 'แต่ก็', 'ด้าน', 'จนขณะนี้', 'พอสมควร', 'ฝ่าย', 'มั้ยเนี่ย', 'จู่ๆ', 'ครั้งหนึ่ง', 'นับจากนี้', 'ดังเคย', 'จรด', 'พึ่ง', 'เชื่อ', 'ครั้งไหน', 'สิ่งใด', 'มา', 'ปิด', 'จ๊ะ', 'กับ', 'เป็นๆ', 'พวกกัน', 'พวกคุณ', 'รึว่า', 'ช่วงถัดไป', 'ถึงอย่างไร', 'กลุ่ม', 'ก็ต่อเมื่อ', 'ช้า', 'คล้าย', 'ซะจนถึง', 'หรือไง', 'ส่วนที่', 'เช่นก่อน', 'ตลอดทั่ว', 'กลับ', 'ทุกอย่าง', 'เสียนี่กระไร', 'เสียนั่นเอง', 'นิดๆ', 'เป็นเพียง', 'ทั่ว', 'แต่เมื่อ', 'ยืนยง', 'เห็นจะ', 'น้อยๆ', 'นอกจากนั้น', 'แค่ไหน', 'เป็นการ', 'แสดง', 'หรือยัง', 'ด้วยเหตุเพราะ', 'ก่อนหน้า', 'พวกนู้น', 'เช่นดังที่', 'มิใช่', 'ช่วง', 'ให้มา', 'เพียงใด', 'เช่นเดียวกับ', 'ครั้งละ', 'เมื่อคราวก่อน', 'หลาย', 'ยัง', 'สมัยนั้น', 'สมัยก่อน', 'เช่นใด', 'เชื่อถือ', 'ซึ่งก็คือ', 'วันใด', 'อดีต', 'เกิน', 'อย่างเช่น', 'เผื่อ', 'ทีเถอะ', 'แค่นี้', 'อย่างดี', 'กันและกัน', 'เรียก', 'ตั้ง', 'คล้ายกับว่า', 'ราย', 'มัก', 'เสียยิ่งนัก', 'เพิ่ง', 'อย่างใด', 'ไหนๆ', 'ทั้งปวง', 'มันๆ', 'บน', 'ผ่าน', 'พวกเธอ', 'นาย', 'บางแห่ง', 'คราว', 'ขณะหนึ่ง', 'ยังแต่', 'เช่นไร', 'หน่อย', 'เร็วๆ', 'ภายใน', 'คงอยู่', 'มากกว่า', 'วันนั้น', 'จากนี้ไป', 'เหตุนี้', 'ครั้งกระนั้น', 'นี่นา', 'มั้ยนะ', 'เผื่อว่า', 'ถ้า', 'อันที่จะ', 'นอกจากว่า', 'เป็นอันมาก', 'เฉกเช่น', 'ตลอดกาลนาน', 'จ้า', 'บอกแล้ว', 'ซะจนกระทั่ง', 'มั้ย', 'พร้อมกับ', 'คราไหน', 'ขณะที่', 'เพื่อว่า', 'ช่วงนี้', 'ด้วยเช่นกัน', 'เช่นกัน', 'เต็มไปหมด', 'คือ', 'จัดตั้ง', 'ไป', 'ยังไง', 'ใกล้', 'นาง', 'ค่อนมาทาง', 'ตลอดทั้ง', 'เดียว', 'ซะก่อน', 'ตรง', 'อาจเป็นด้วย', 'คราวละ', 'ยิ่งเมื่อ', 'สําหรับ', 'สิ้น', 'จัดหา', 'พวกนี้', 'ใหม่ๆ', 'ทีเดียว', 'นับแต่นี้', 'เพื่อที่จะ', 'เสมือนว่า', 'ด้วยเพราะ', 'เห็น', 'คล้ายกันกับ', 'ทําให้', 'ทั้งหมด', 'นู้น', 'พวกมัน', 'เพียงเพราะ', 'เปลี่ยน', 'เนื่องจาก', 'ต่อกัน', 'ใหญ่ๆ', 'ประการใด', 'เพื่อให้', 'จริง', 'เมื่อเช้า', 'ต่าง', 'ดังเก่า', 'เอา', 'ทาง', 'จนทั่ว', 'ประการหนึ่ง', 'ตนเอง', 'กระนั้น', 'แห่ง', 'คง', 'หลัง', 'แต่ไหน', 'นับแต่', 'พบว่า', 'ทันใดนั้น', 'ทัน', 'สุดๆ', 'กันเถอะ', 'ช่วงต่อไป', 'ช้านาน', 'ต่างๆ', 'แต่นั้น', 'เข้าใจ', 'ไม่เป็นไร', 'ได้แต่', 'จับ', 'ไป่', 'ครั้งก่อน', 'ด้วยว่า', 'ครั้งหลังสุด', 'เป็นเพราะ', 'คราหนึ่ง', 'จัดทำ', 'ซึ่งก็', 'พอ', 'สูงๆ', 'ละ', 'กำลังจะ', 'พอจะ', 'ถ้าหาก', 'น่ะ', 'กัน', 'ที่ใด', 'อันไหน', 'วัน', 'สิ่งนั้น', 'นอกจาก', 'ดั่งเคย', 'กันดีกว่า', 'ส่วนด้อย', 'ช่วงหน้า', 'ล้วนแต่', 'เกี่ยวข้อง', 'เช่นดังก่อน', 'จากนั้น', 'นี่เอง', 'ยิ่งใหญ่', 'มั๊ย', 'ข้างล่าง', 'แท้', 'ก็ตาม', 'ทุกตัว', 'เช่นดังเก่า', 'เหตุไร', 'เมื่อนั้น', 'อันเนื่องมาจาก', 'ครั้งที่', 'ขณะ', 'ทั้งคน', 'นิดหน่อย', 'ฉัน', 'เล็กๆ', 'คราวนี้', 'ด้วยเหมือนกัน', 'คราวๆ', 'นี่แน่ะ', 'คงจะ', 'กว้างๆ', 'ตลอดไป', 'ได้มา', 'รวดเร็ว', 'ให้ไป', 'ตน', 'มุ่งหมาย', 'นั่นเอง', 'พอเหมาะ', 'เท่ากัน', 'จัดงาน', 'จัดให้', 'สำคัญ', 'นำมา', 'แต่ละ', 'ถึงเมื่อ', 'ครั้งหลัง', 'กระผม', 'บ่อยๆ', 'มาก', 'อย่างไหน', 'ที่ละ', 'เพียงพอ', 'ผู้ใด', 'เป็นด้วย', 'หนอย', 'ด้วยเหตุนี้', 'ค่อนข้าง', 'หาใช่', 'เท่านี้', 'รึ', 'ทั้งนั้นด้วย', 'เกี่ยวๆ', 'ใคร่', 'ร่วมด้วย', 'เหลือเกิน', 'ฝ่ายใด', 'คราที่', 'เป็นที', 'ไม่ค่อย', 'ยังจะ', 'พอที่', 'ทั้งๆ', 'ปรากฏ', 'จนถึง', 'ใครๆ', 'จนบัดนี้', 'มุ่ง', 'ขณะใด', 'จัดแจง', 'พร้อมกัน', 'แหละ', 'ร่วมมือ', 'ยังคง', 'เริ่ม', 'พอดี', 'นอกจากที่', 'ผู้', 'มิ', 'สมัยโน้น', 'ค่ะ', 'ง่ายๆ', 'ล้วน', 'จากนี้', 'ที่นี้', 'ส่วนน้อย', 'ยิ่งจน', 'อันได้แก่', 'พวกท่าน', 'ใคร', 'ตลอดปี', 'ยาวนาน', 'แต่ต้อง', 'ส่ง', 'สิ่งไหน', 'ยืนยัน', 'ถูกต้อง', 'เสียก่อน', 'หนอ', 'เป็นที่สุด', 'จึง', 'ตลอดมา', 'ยาก', 'ชาว', 'ฉะนี้', 'แต่ไร', 'เกือบๆ', 'หรือ', 'เหล่า', 'ฯล', 'จ้ะ', 'คิดว่า', 'ทีๆ', 'ยก', 'ไม่', 'ครัน', 'อันใด', 'ถึงเมื่อไร', 'ปฏิบัติ', 'ครบถ้วน', 'นั่นแหละ', 'แก', 'ทุกวันนี้', 'เปิด', 'ไกล', 'นานๆ', 'ครั้งใด', 'ตลอดวัน', 'เถอะ', 'แต่เพียง', 'ปรากฏว่า', 'คุณๆ', 'เพียงเพื่อ', 'จวบกับ', 'แม้แต่', 'ทั้งนั้นเพราะ', 'เพราะฉะนั้น', 'กันไหม', 'พอๆ', 'อัน', 'นิด', 'ภายหน้า', 'ครบครัน', 'นอกเหนือจาก', 'พื้นๆ', 'จวบจน', 'จนเมื่อ', 'ทันทีทันใด', 'นำพา', 'ยกให้', 'อย่างๆ', 'นี้', 'พบ', 'เมื่อคืน', 'ตามด้วย', 'แห่งนี้', 'โดย', 'สู่', 'เถิด', 'แค่นั้น', 'เดียวกัน', 'ที่ๆ', 'หรือไร', 'ทำๆ', 'พวกที่', 'ยิ่งขึ้นไป', 'ข้างต้น', 'รวมกัน', 'ทุกหน', 'น่า', 'ตลอดทั่วทั้ง', 'อย่างนี้', 'ด้วยเหตุที่', 'เสมือนกับ', 'เยอะ', 'ใดๆ', 'เสร็จสิ้น', 'ระหว่าง', 'เมื่อก่อน', 'สูง', 'แห่งไหน', 'เฉพาะ', 'เป็นต้นมา', 'นักๆ', 'เร็ว', 'อันๆ', 'แล้วแต่', 'ตลอดระยะเวลา', 'สามารถ', 'ทุกอัน', 'มิฉะนั้น', 'อีก', 'จำพวก', 'นั่นไง', 'เลย', 'บางๆ', 'ที่สุด', 'เช่นนี้', 'ครานั้น', 'ไม่ค่อยเป็น', 'ๆ', 'อื่น', 'เต็มๆ', 'ตาม', 'ทุกชิ้น', 'เฉยๆ', 'สั้น', 'ให้ดี', 'บางครา', 'แต่เดิม', 'ยิ่งจะ', 'รวม', 'แบบ', 'เยอะๆ', 'บ้าง', 'นอกจากนี้', 'มุ่งเน้น', 'ด้วยเหตุนั้น', 'ตามๆ', 'เรื่อย', 'ตลอดกาล', 'ที่ไหน', 'ใน', 'ช่วงที่', 'เป็นดัง', 'ย่อย', 'อะไร', 'บางที่', 'พอตัว', 'ส่วนใหญ่', 'จวนจะ', 'เช่นนั้นเอง', 'จนกว่า', 'สุด', 'ส่วน', 'แต่', 'อย่างไร', 'นางสาว', 'แสดงว่า', 'น้อย', 'ทุกที', 'ดังกับว่า', 'สมัย', 'จด', 'บอกว่า', 'จริงๆ', 'แห่งใด', 'ซึ่งได้แก่', 'ยิ่งขึ้น', 'ดั่ง', 'ประกอบ', 'หาความ', 'เท่าที่', 'เนี่ยเอง', 'ยังงี้', 'ทั้งมวล', 'กำหนด', 'นี้เอง', 'เท่าไหร่', 'ครับ', 'เชื่อว่า', 'ใหญ่โต', 'คราวที่', 'เกือบ', 'แค่เพียง', 'ค่อนข้างจะ', 'คราวหลัง', 'เชื่อมั่น', 'ขณะใดๆ', 'เพิ่มเติม', 'ในเมื่อ', 'กว่า', 'เช่นดัง', 'คะ', 'นาน', 'ถึงเมื่อใด', 'เพื่อที่', 'อันจะ', 'วันนี้', 'มี', 'พร้อมเพียง', 'แก่', 'ไร', 'คราวไหน', 'ยิ่งแล้ว', 'ภายหลัง', 'สูงกว่า', 'หนึ่ง', 'ภายภาคหน้า', 'สูงส่ง', 'ทุก', 'พอเพียง', 'จะได้', 'พยายาม', 'หากแม้นว่า', 'ถึงแม้จะ', 'น้อยกว่า', 'เสร็จ', 'ตลอดถึง', 'อันที่จริง', 'ไม่ค่อยจะ', 'เมื่อ', 'หลังจาก', 'คล้ายว่า', 'ดัง', 'รวด', 'แยะ', 'ถ้าจะ', 'เช่นนั้น', 'เมื่อไร', 'กว้างขวาง', 'ร่วมกัน', 'มิได้', 'มีแต่', 'เท่ากับ', 'เสียจนกระทั่ง', 'คิด', 'พวกเขา', 'เพื่อ', 'ซะ', 'ให้แด่', 'ทุกที่', 'ถือ', 'ควร', 'อนึ่ง', 'ส่วนดี', 'เหล่านี้', 'ขวางๆ', 'ก็แล้วแต่', 'ทุกแห่ง', 'เช่นที่ว่า', 'พวกนั้น', 'พอควร', 'พวกโน้น', 'ยิ่งนัก', 'หาก', 'ใหม่', 'สิ่งนี้', 'ระยะๆ', 'ข้างๆ', 'มากมาย', 'ด้วยกัน', 'ทว่า', 'ขอ', 'บางคราว', 'เหตุ', 'อาจจะ', 'ข้างบน', 'เปิดเผย', 'ทีใด', 'ช่วงหลัง', 'มั้ยล่ะ', 'ในที่', 'เคย', 'นี่แหละ', 'กล่าวคือ', 'ทั้งหลาย', 'เล็ก', 'กลุ่มๆ', 'นั่นเป็น', 'ช่วงระหว่าง', 'แม้', 'อย่างละ', 'จง', 'พร้อมทั้ง', 'หมด', 'เน้น', 'ออก', 'ทั้งที่', 'ทั้งที', 'นับตั้งแต่', 'เขียน', 'ไฉน', 'อย่าง', 'ยาว', 'แม้ว่า', 'อย่างไรก็', 'ถึงจะ', 'เก็บ', 'ที่ว่า', 'เกี่ยวกับ', 'พา', 'เช่นเมื่อ', 'เมื่อเย็น', 'ได้แก่', 'ใช่', 'อย่างมาก', 'ก็ตามแต่', 'ช่วย', 'จนกระทั่ง', 'จัง', 'ขั้น', 'พวกกู', 'แต่ที่', 'กันดีไหม', 'เพียงไหน', 'แต่อย่างใด', 'ปัจจุบัน', 'ข้าฯ', 'ได้รับ', 'ภาย', 'คราวก่อน', 'ใกล้ๆ', 'ส่วนใด', 'ทรง', 'เยอะแยะ', 'ค่อย', 'เกี่ยวกัน', 'จึงจะ', 'เสร็จกัน', 'เหล่านั้น', 'อย่างเดียว', 'นัก', 'เพิ่งจะ', 'อย่างไรเสีย', 'ใหญ่', 'เป็นเพราะว่า', 'ตลอดศก', 'อันที่', 'เสียจนถึง', 'มักจะ', 'ไกลๆ', 'เสียนั่น', 'ด้วยเหตุว่า', 'บัดนี้', 'ปรับ', 'นะ', 'โตๆ', 'คราวโน้น', 'พวกฉัน', 'ตนฯ', 'เช่น', 'บ่อย', 'นั้นๆ', 'ซึ่งกัน', 'ทั้งนี้', 'ซะจน', 'บางครั้ง', 'ที่จริง', 'แต่ทว่า', 'คราใด', 'สั้นๆ', 'ครบ', 'จึงเป็น', 'เช่นที่เคย', 'ด้วยประการฉะนี้', 'เพราะ', 'จ๋า', 'นี่', 'ประสบ', 'สูงสุด', 'เหลือ', 'เป็นอันว่า', 'อย่างนั้น', 'เสียจน', 'คล้ายกัน', 'ภายใต้', 'มองว่า', 'ด้วยที่', 'ฯลฯ', 'ที', 'ลง', 'ครา', 'มัน', 'ประการ', 'เมื่อคราวที่', 'นอก', 'ขณะนั้น', 'ใช้', 'รือว่า', 'จำเป็น', 'ทำไร', 'เสร็จแล้ว', 'เมื่อครั้งก่อน', 'จนแม้น', 'เกิด', 'เนี่ย', 'ตลอดทั่วถึง', 'แท้จริง', 'ไหน', 'ของ', 'แล้วเสร็จ', 'เมื่อใด', 'แม้กระทั่ง', 'เกี่ยวเนื่อง', 'พวกมึง', 'ก่อน', 'อื่นๆ', 'คุณ', 'ทุกครา', 'แต่ว่า', 'จะ', 'โต', 'นับแต่นั้น', 'เป็นต้นไป', 'ให้', 'อาจ', 'ทันที', 'เท่าไร', 'นับ', 'เต็มไปด้วย', 'หารือ', 'ล่าสุด', 'ข้าพเจ้า', 'แค่ว่า', 'ก็ได้', 'ตลอด', 'เพราะว่า', 'ตลอดเวลา', 'เขา', 'ช่วงๆ', 'ที่นั้น', 'ซึ่งๆ', 'รวมทั้ง', 'เป็นแต่', 'ผิด', 'ถูกๆ', 'ภายภาค', 'ขาด', 'นอกเหนือ', 'ครั้งนี้', 'เสีย', 'คล้ายกับ', 'รวมๆ', 'ทุกวัน', 'อย่างไรก็ได้', 'ในช่วง', 'เล็กน้อย', 'นับจากนั้น', 'กันเอง', 'ข้างเคียง', 'ไว้', 'ก่อนๆ', 'เห็นว่า', 'เราๆ', 'เช่นเคย', 'ส่วนเกิน', 'ดั่งกับว่า', 'พอกัน', 'ผิดๆ', 'ทุกทาง', 'เมื่อไหร่', 'เมื่อครั้ง', 'ทีไร', 'ย่อม', 'เป็นที่', 'ทั้งนั้น', 'พอแล้ว', 'เห็นควร', 'พึง', 'เพียงไร', 'ที่แท้', 'ดังกล่าว', 'ก็แค่', 'หน', 'แล้วกัน', 'ใช่ไหม', 'อาจเป็น', 'ไง', 'ยิ่ง', 'พวก', 'เปลี่ยนแปลง', 'ตามแต่', 'พร้อมด้วย', 'ก็ดี', 'จวน', 'เผื่อจะ', 'ทั้งตัว', 'ทํา', 'ยอมรับ', 'นับแต่ที่', 'ครั้งนั้น', 'ว่า', 'กล่าว', 'ร่วม', 'พร้อมที่', 'บ่อยครั้ง', 'เป็นเพื่อ', 'แต่ถ้า', 'พร้อม', 'ค่อยไปทาง', 'ก็คือ', 'ด้วย', 'บัดดล', 'เคยๆ', 'ขณะนี้', 'ครานี้', 'ประการฉะนี้', 'แห่งโน้น', 'หากว่า', 'เห็นแก่', 'ถูก', 'ฉะนั้น', 'ซึ่ง', 'ง่าย', 'ตามที่', 'เธอ', 'ภาคฯ', 'ตั้งแต่', 'ใต้', 'ผ่านๆ', 'นำ', 'สบาย', 'เรื่อยๆ', 'ค่อยๆ', 'ให้แก่', 'ขวาง', 'แรก', 'แห่งนั้น', 'ต่างก็', 'กำลัง', 'ทั้งสิ้น', 'ช่วงก่อน', 'ยังงั้น', 'บอก', 'กระทั่ง', 'อันละ', 'เรียบ', 'อยู่', 'เพียง', 'แยะๆ', 'บางที', 'คำ', 'จริงๆจังๆ', 'ขึ้น', 'มอง', 'ทำให้', 'จวบ', 'ที่แท้จริง', '\\ufeffๆ', 'ตรงๆ', 'เข้า', 'บางขณะ', 'ต่อ', 'แล้ว', 'ที่', 'ได้ที่', 'สิ่ง', 'แก้ไข', 'นํา', 'หรือเปล่า', 'ส่วนนั้น', 'พวกแก', 'เสียยิ่ง', 'นี่ไง', 'น่าจะ', 'ภาค', 'ที่ซึ่ง', 'ครั้งๆ', 'ทุกครั้ง', 'ครั้งคราว', 'แต่จะ', 'ยืนนาน', 'อย่างน้อย', 'บ่อยกว่า', 'เป็นอัน', 'แม้นว่า', 'เหตุผล', 'ดั่งกับ', 'ทั้ง', 'กลุ่มก้อน', 'ครั้งครา', 'ตลอดจน', 'ช้าๆ', 'รวมด้วย', 'ถึงบัดนั้น', 'ในระหว่าง', 'สิ้นกาลนาน', 'อย่างยิ่ง', 'เมื่อวาน', 'ณ', 'บาง', 'จนตลอด', 'กู', 'ก็', 'เมื่อวันวาน', 'นู่น', 'ทำไม', 'หากแม้', 'ถึงแก่', 'เป็นอันๆ', 'แต่ก่อน', 'อย่างโน้น', 'เป็นเพียงว่า', 'คราวใด', 'เสียด้วย', 'ต้อง', 'เมื่อนี้', 'ดังกับ', 'เป็นอาทิ', 'เท่าใด', 'ครั้ง', 'นั้น', 'รือ', 'อยาก', 'ถือว่า', 'ใคร่จะ', 'ยังโง้น', 'ยิ่งกว่า', 'ข้า', 'จน', 'ถึงแม้', 'กระทำ', 'ประมาณ', 'รับรอง', 'ได้', 'ค่อน', 'ที่แล้ว', 'ข้าง', 'เรา', 'มั้ยนั่น', 'จัดการ', 'เท่า', 'สืบเนื่อง', 'จริงจัง', 'ดั่งเก่า', 'ผล', 'คราวหนึ่ง', 'ส่วนมาก', 'พูด', 'มึง', 'ก็จะ', 'หรือไม่', 'เป็นแต่เพียง', 'พอที', 'ฯ', 'ช่วงนั้น', 'เพียงแต่', 'เหตุนั้น', 'ก่อนหน้านี้', 'แค่จะ', 'ยอม', 'ระยะ', 'เพียงแค่', 'อย่างหนึ่ง', 'เสียนี่', 'เช่นเดียวกัน', 'พอสม', 'เฉย', 'เท่านั้น', 'ก็ตามที', 'ทุกสิ่ง', 'เล่าว่า', 'บัดเดี๋ยวนี้', 'สมัยนี้', 'การ', 'เมื่อคราว', 'เพิ่ม', 'ความ', 'และ', 'จาก', 'เสียแล้ว', 'ขณะเดียวกัน', 'ทุกคน', 'นั้นไว', 'วันไหน', 'หมดสิ้น', 'ทั้งเป็น', 'เกินๆ', 'บัดนั้น', 'ยืนยาว', 'เสร็จสมบูรณ์', 'เป็น', 'ช่วงแรก', 'จวนเจียน', 'หากแม้น', 'นอกนั้น', 'รวมถึง', 'เกือบจะ', 'ทีละ', 'ภายนอก', 'อย่างที่', 'คราวหน้า'}\n"
          ]
        }
      ],
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.corpus.common import thai_stopwords\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(set(thai_stopwords()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:517: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train shape: (10706, 3615)\n",
            "Val shape: (1339, 3615)\n",
            "Test shape: (1340, 3615)\n",
            "Number of features: 3615\n",
            "Sample TF-IDF Features (First 5 training samples):\n",
            "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
            "\twith 15 stored elements and shape (1, 3615)>\n",
            "  Coords\tValues\n",
            "  (0, 2582)\t0.15335071962729047\n",
            "  (0, 1065)\t0.10887956336518148\n",
            "  (0, 2376)\t0.12784073325007023\n",
            "  (0, 1445)\t0.2091753985526012\n",
            "  (0, 3216)\t0.24593021912326413\n",
            "  (0, 177)\t0.24833353650083592\n",
            "  (0, 434)\t0.27233973099167436\n",
            "  (0, 1499)\t0.1642673698623802\n",
            "  (0, 1349)\t0.4665220808838139\n",
            "  (0, 1714)\t0.2926490948729209\n",
            "  (0, 761)\t0.48161481885581436\n",
            "  (0, 1974)\t0.17203910879251177\n",
            "  (0, 2390)\t0.19466884830085984\n",
            "  (0, 2526)\t0.257246993019674\n",
            "  (0, 1017)\t0.11098951226265677\n"
          ]
        }
      ],
      "source": [
        "pythainlp_tokenizer = lambda x: word_tokenize(x, engine=\"newmm\", keep_whitespace=False)\n",
        "\n",
        "# Extract tokenized text and labels\n",
        "train_texts, train_labels = dataset[\"train\"][\"input\"], dataset[\"train\"][\"label\"]\n",
        "val_texts, val_labels = dataset[\"val\"][\"input\"], dataset[\"val\"][\"label\"]\n",
        "test_texts, test_labels = dataset[\"test\"][\"input\"], dataset[\"test\"][\"label\"]\n",
        "\n",
        "# Initialize and fit TF-IDF Vectorizer on training data\n",
        "vectorizer = TfidfVectorizer(tokenizer=pythainlp_tokenizer, max_df=0.7, min_df=1)\n",
        "X_train_tfidf = vectorizer.fit_transform(train_texts)  # Fit and transform training data\n",
        "\n",
        "X_val_tfidf = vectorizer.transform(val_texts)  # Transform validation data\n",
        "X_test_tfidf = vectorizer.transform(test_texts)  # Transform test data\n",
        "\n",
        "# Print shape of TF-IDF matrices\n",
        "print(\"Train shape:\", X_train_tfidf.shape)\n",
        "print(\"Val shape:\", X_val_tfidf.shape)\n",
        "print(\"Test shape:\", X_test_tfidf.shape)\n",
        "\n",
        "# vectorizer get feature names\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "print(\"Number of features:\", len(feature_names))\n",
        "\n",
        "# Print first 5 samples of processed train data\n",
        "print(\"Sample TF-IDF Features (First 5 training samples):\")\n",
        "print(X_train_tfidf[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of OOV words in validation set: 190\n",
            "Number of OOV words in test set: 185\n",
            "OOV ratio in validation set: 0.05255878284923928\n",
            "OOV ratio in test set: 0.051175656984785614\n"
          ]
        }
      ],
      "source": [
        "# check for oov in test and val set\n",
        "word_dict = vectorizer.get_feature_names_out()\n",
        "\n",
        "oov_set = set()\n",
        "\n",
        "def get_oov_words(texts):\n",
        "    oov_set = set()\n",
        "    for text in texts:\n",
        "        for word in pythainlp_tokenizer(text):\n",
        "            if word not in word_dict:\n",
        "                oov_set.add(word)\n",
        "    return oov_set\n",
        "\n",
        "oov_val = get_oov_words(val_texts)\n",
        "oov_test = get_oov_words(test_texts)\n",
        "\n",
        "print(\"Number of OOV words in validation set:\", len(oov_val))\n",
        "print(\"Number of OOV words in test set:\", len(oov_test))\n",
        "print(\"OOV ratio in validation set:\", len(oov_val) / len(word_dict))\n",
        "print(\"OOV ratio in test set:\", len(oov_test) / len(word_dict))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Define a LogisticRegression model with tf-idf as feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "#import from sklearn that automatically select the best hyperparameter\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define the hyperparameter grid\n",
        "param_grid = {\n",
        "    \"C\": [0.01, 0.1, 1, 10, 100],\n",
        "    \"penalty\": [\"l1\", \"l2\"],\n",
        "    \"solver\": [\"liblinear\"]\n",
        "}\n",
        "\n",
        "# Initialize the GridSearchCV object\n",
        "grid_search = GridSearchCV( estimator=LogisticRegression(max_iter=1000, class_weight=\"balanced\"), \n",
        "                            param_grid=param_grid, \n",
        "                            cv=5, \n",
        "                            n_jobs=-1, \n",
        "                            verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/model_selection/_split.py:805: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.2s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
            "[CV] END ...............C=0.01, penalty=l1, solver=liblinear; total time=   0.3s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.4s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.5s\n",
            "[CV] END ...............C=0.01, penalty=l2, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.7s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l1, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.6s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.7s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.7s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.8s\n",
            "[CV] END ................C=0.1, penalty=l2, solver=liblinear; total time=   0.8s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   0.9s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.0s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.0s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.1s\n",
            "[CV] END ..................C=1, penalty=l1, solver=liblinear; total time=   1.0s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.0s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.1s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.3s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.3s\n",
            "[CV] END ..................C=1, penalty=l2, solver=liblinear; total time=   1.4s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.5s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.4s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.8s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.6s\n",
            "[CV] END .................C=10, penalty=l2, solver=liblinear; total time=   1.6s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   2.8s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   3.0s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   3.0s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.9s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   3.0s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.5s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.5s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.5s\n",
            "[CV] END ................C=100, penalty=l2, solver=liblinear; total time=   1.4s\n",
            "[CV] END .................C=10, penalty=l1, solver=liblinear; total time=   4.2s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.0s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.2s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.1s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.1s\n",
            "[CV] END ................C=100, penalty=l1, solver=liblinear; total time=   4.1s\n"
          ]
        }
      ],
      "source": [
        "# Fit the GridSearchCV object on the training data\n",
        "grid_search.fit(X_train_tfidf, train_labels)\n",
        "\n",
        "# get the best model\n",
        "best_model = grid_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {\n",
              "  /* Definition of color scheme common for light and dark mode */\n",
              "  --sklearn-color-text: #000;\n",
              "  --sklearn-color-text-muted: #666;\n",
              "  --sklearn-color-line: gray;\n",
              "  /* Definition of color scheme for unfitted estimators */\n",
              "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
              "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
              "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
              "  --sklearn-color-unfitted-level-3: chocolate;\n",
              "  /* Definition of color scheme for fitted estimators */\n",
              "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
              "  --sklearn-color-fitted-level-1: #d4ebff;\n",
              "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
              "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
              "\n",
              "  /* Specific color for light theme */\n",
              "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
              "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
              "  --sklearn-color-icon: #696969;\n",
              "\n",
              "  @media (prefers-color-scheme: dark) {\n",
              "    /* Redefinition of color scheme for dark theme */\n",
              "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
              "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
              "    --sklearn-color-icon: #878787;\n",
              "  }\n",
              "}\n",
              "\n",
              "#sk-container-id-1 {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 pre {\n",
              "  padding: 0;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-hidden--visually {\n",
              "  border: 0;\n",
              "  clip: rect(1px 1px 1px 1px);\n",
              "  clip: rect(1px, 1px, 1px, 1px);\n",
              "  height: 1px;\n",
              "  margin: -1px;\n",
              "  overflow: hidden;\n",
              "  padding: 0;\n",
              "  position: absolute;\n",
              "  width: 1px;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-dashed-wrapped {\n",
              "  border: 1px dashed var(--sklearn-color-line);\n",
              "  margin: 0 0.4em 0.5em 0.4em;\n",
              "  box-sizing: border-box;\n",
              "  padding-bottom: 0.4em;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-container {\n",
              "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
              "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
              "     so we also need the `!important` here to be able to override the\n",
              "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
              "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
              "  display: inline-block !important;\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-text-repr-fallback {\n",
              "  display: none;\n",
              "}\n",
              "\n",
              "div.sk-parallel-item,\n",
              "div.sk-serial,\n",
              "div.sk-item {\n",
              "  /* draw centered vertical line to link estimators */\n",
              "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
              "  background-size: 2px 100%;\n",
              "  background-repeat: no-repeat;\n",
              "  background-position: center center;\n",
              "}\n",
              "\n",
              "/* Parallel-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item::after {\n",
              "  content: \"\";\n",
              "  width: 100%;\n",
              "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
              "  flex-grow: 1;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel {\n",
              "  display: flex;\n",
              "  align-items: stretch;\n",
              "  justify-content: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  position: relative;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
              "  align-self: flex-end;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
              "  align-self: flex-start;\n",
              "  width: 50%;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
              "  width: 0;\n",
              "}\n",
              "\n",
              "/* Serial-specific style estimator block */\n",
              "\n",
              "#sk-container-id-1 div.sk-serial {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "  align-items: center;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  padding-right: 1em;\n",
              "  padding-left: 1em;\n",
              "}\n",
              "\n",
              "\n",
              "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
              "clickable and can be expanded/collapsed.\n",
              "- Pipeline and ColumnTransformer use this feature and define the default style\n",
              "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
              "*/\n",
              "\n",
              "/* Pipeline and ColumnTransformer style (default) */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable {\n",
              "  /* Default theme specific background. It is overwritten whether we have a\n",
              "  specific estimator or a Pipeline/ColumnTransformer */\n",
              "  background-color: var(--sklearn-color-background);\n",
              "}\n",
              "\n",
              "/* Toggleable label */\n",
              "#sk-container-id-1 label.sk-toggleable__label {\n",
              "  cursor: pointer;\n",
              "  display: flex;\n",
              "  width: 100%;\n",
              "  margin-bottom: 0;\n",
              "  padding: 0.5em;\n",
              "  box-sizing: border-box;\n",
              "  text-align: center;\n",
              "  align-items: start;\n",
              "  justify-content: space-between;\n",
              "  gap: 0.5em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
              "  font-size: 0.6rem;\n",
              "  font-weight: lighter;\n",
              "  color: var(--sklearn-color-text-muted);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
              "  /* Arrow on the left of the label */\n",
              "  content: \"▸\";\n",
              "  float: left;\n",
              "  margin-right: 0.25em;\n",
              "  color: var(--sklearn-color-icon);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
              "  color: var(--sklearn-color-text);\n",
              "}\n",
              "\n",
              "/* Toggleable content - dropdown */\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content {\n",
              "  max-height: 0;\n",
              "  max-width: 0;\n",
              "  overflow: hidden;\n",
              "  text-align: left;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content pre {\n",
              "  margin: 0.2em;\n",
              "  border-radius: 0.25em;\n",
              "  color: var(--sklearn-color-text);\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
              "  /* Expand drop-down */\n",
              "  max-height: 200px;\n",
              "  max-width: 100%;\n",
              "  overflow: auto;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
              "  content: \"▾\";\n",
              "}\n",
              "\n",
              "/* Pipeline/ColumnTransformer-specific style */\n",
              "\n",
              "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator-specific style */\n",
              "\n",
              "/* Colorize estimator box */\n",
              "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  /* The background is the default theme color */\n",
              "  color: var(--sklearn-color-text-on-default-background);\n",
              "}\n",
              "\n",
              "/* On hover, darken the color of the background */\n",
              "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "/* Label box, darken color on hover, fitted */\n",
              "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
              "  color: var(--sklearn-color-text);\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Estimator label */\n",
              "\n",
              "#sk-container-id-1 div.sk-label label {\n",
              "  font-family: monospace;\n",
              "  font-weight: bold;\n",
              "  display: inline-block;\n",
              "  line-height: 1.2em;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-label-container {\n",
              "  text-align: center;\n",
              "}\n",
              "\n",
              "/* Estimator-specific */\n",
              "#sk-container-id-1 div.sk-estimator {\n",
              "  font-family: monospace;\n",
              "  border: 1px dotted var(--sklearn-color-border-box);\n",
              "  border-radius: 0.25em;\n",
              "  box-sizing: border-box;\n",
              "  margin-bottom: 0.5em;\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-0);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-0);\n",
              "}\n",
              "\n",
              "/* on hover */\n",
              "#sk-container-id-1 div.sk-estimator:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-2);\n",
              "}\n",
              "\n",
              "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-2);\n",
              "}\n",
              "\n",
              "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
              "\n",
              "/* Common style for \"i\" and \"?\" */\n",
              "\n",
              ".sk-estimator-doc-link,\n",
              "a:link.sk-estimator-doc-link,\n",
              "a:visited.sk-estimator-doc-link {\n",
              "  float: right;\n",
              "  font-size: smaller;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1em;\n",
              "  height: 1em;\n",
              "  width: 1em;\n",
              "  text-decoration: none !important;\n",
              "  margin-left: 0.5em;\n",
              "  text-align: center;\n",
              "  /* unfitted */\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted,\n",
              "a:link.sk-estimator-doc-link.fitted,\n",
              "a:visited.sk-estimator-doc-link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
              ".sk-estimator-doc-link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover,\n",
              "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
              ".sk-estimator-doc-link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "/* Span, style for the box shown on hovering the info icon */\n",
              ".sk-estimator-doc-link span {\n",
              "  display: none;\n",
              "  z-index: 9999;\n",
              "  position: relative;\n",
              "  font-weight: normal;\n",
              "  right: .2ex;\n",
              "  padding: .5ex;\n",
              "  margin: .5ex;\n",
              "  width: min-content;\n",
              "  min-width: 20ex;\n",
              "  max-width: 50ex;\n",
              "  color: var(--sklearn-color-text);\n",
              "  box-shadow: 2pt 2pt 4pt #999;\n",
              "  /* unfitted */\n",
              "  background: var(--sklearn-color-unfitted-level-0);\n",
              "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link.fitted span {\n",
              "  /* fitted */\n",
              "  background: var(--sklearn-color-fitted-level-0);\n",
              "  border: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "\n",
              ".sk-estimator-doc-link:hover span {\n",
              "  display: block;\n",
              "}\n",
              "\n",
              "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link {\n",
              "  float: right;\n",
              "  font-size: 1rem;\n",
              "  line-height: 1em;\n",
              "  font-family: monospace;\n",
              "  background-color: var(--sklearn-color-background);\n",
              "  border-radius: 1rem;\n",
              "  height: 1rem;\n",
              "  width: 1rem;\n",
              "  text-decoration: none;\n",
              "  /* unfitted */\n",
              "  color: var(--sklearn-color-unfitted-level-1);\n",
              "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
              "  /* fitted */\n",
              "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
              "  color: var(--sklearn-color-fitted-level-1);\n",
              "}\n",
              "\n",
              "/* On hover */\n",
              "#sk-container-id-1 a.estimator_doc_link:hover {\n",
              "  /* unfitted */\n",
              "  background-color: var(--sklearn-color-unfitted-level-3);\n",
              "  color: var(--sklearn-color-background);\n",
              "  text-decoration: none;\n",
              "}\n",
              "\n",
              "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
              "  /* fitted */\n",
              "  background-color: var(--sklearn-color-fitted-level-3);\n",
              "}\n",
              "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>LogisticRegression</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(C=10, class_weight=&#x27;balanced&#x27;, max_iter=1000,\n",
              "                   solver=&#x27;liblinear&#x27;)</pre></div> </div></div></div></div>"
            ],
            "text/plain": [
              "LogisticRegression(C=10, class_weight='balanced', max_iter=1000,\n",
              "                   solver='liblinear')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "best_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Accuracy: 0.7326362957430919\n",
            "Test Accuracy: 0.7231343283582089\n",
            "                 precision    recall  f1-score   support\n",
            "\n",
            "        payment       0.64      0.73      0.68        64\n",
            "        package       0.76      0.69      0.72       180\n",
            "        suspend       0.77      0.81      0.79        73\n",
            "       internet       0.75      0.77      0.76       179\n",
            "   phone_issues       0.63      0.72      0.67        58\n",
            "        service       0.85      0.70      0.77       211\n",
            "    nontruemove       0.42      0.64      0.51        25\n",
            "        balance       0.85      0.74      0.80       149\n",
            "         detail       0.44      0.52      0.47        33\n",
            "           bill       0.67      0.83      0.74        54\n",
            "         credit       0.71      0.88      0.79        17\n",
            "      promotion       0.72      0.68      0.70       115\n",
            " mobile_setting       0.48      0.50      0.49        28\n",
            "       iservice       1.00      1.00      1.00         2\n",
            "        roaming       0.81      0.88      0.85        25\n",
            "      truemoney       0.89      0.68      0.77        25\n",
            "    information       0.51      0.70      0.59        30\n",
            "    lost_stolen       0.81      0.91      0.86        23\n",
            "balance_minutes       0.60      0.60      0.60         5\n",
            "            idd       0.86      0.90      0.88        20\n",
            "        garbage       0.00      0.00      0.00         5\n",
            "       ringtone       0.67      0.75      0.71         8\n",
            "           rate       0.17      0.33      0.22         3\n",
            "   loyalty_card       0.83      0.83      0.83         6\n",
            "        contact       0.00      0.00      0.00         1\n",
            "        officer       0.00      0.00      0.00         1\n",
            "\n",
            "       accuracy                           0.72      1340\n",
            "      macro avg       0.61      0.65      0.62      1340\n",
            "   weighted avg       0.74      0.72      0.73      1340\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/home/jaf/anaconda3/envs/colab-env/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the best model on the validation data\n",
        "val_preds = best_model.predict(X_val_tfidf)\n",
        "val_acc = accuracy_score(val_labels, val_preds)\n",
        "print(\"Validation Accuracy:\", val_acc)\n",
        "\n",
        "test_preds = best_model.predict(X_test_tfidf)\n",
        "test_acc = accuracy_score(test_labels, test_preds)\n",
        "print(\"Test Accuracy:\", test_acc)\n",
        "\n",
        "\n",
        "# Generate classification report on test data\n",
        "print(classification_report(test_labels, test_preds, target_names=num_2_label_map.values()))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wql2YeU8qFQ6"
      },
      "source": [
        "# Model 2 MUSE\n",
        "\n",
        "Build a simple logistic regression model using features from the MUSE model.\n",
        "\n",
        "Which MUSE model will you use? Why?\n",
        "\n",
        "**Ans:**\n",
        "\n",
        "MUSE is typically used with tensorflow. However, there are some pytorch conversions made by some people.\n",
        "\n",
        "https://huggingface.co/sentence-transformers/use-cmlm-multilingual\n",
        "https://huggingface.co/dayyass/universal-sentence-encoder-multilingual-large-3-pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d3UtkpaLnctH"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDHfX377rnp_"
      },
      "source": [
        "# Model 3 WangchanBERTa\n",
        "\n",
        "We ask you to train a WangchanBERTa-based model.\n",
        "\n",
        "We recommend you use the thaixtransformers fork (which we used in the PoS homework).\n",
        "https://github.com/PyThaiNLP/thaixtransformers\n",
        "\n",
        "The structure of the code will be very similar to the PoS homework. You will also find the huggingface [tutorial](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) useful. Or you can also add a softmax layer by yourself just like in the previous homework.\n",
        "\n",
        "Which WangchanBERTa model will you use? Why? (Don't forget to clean your text accordingly).\n",
        "\n",
        "**Ans:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI8SvILyub0m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D7qsVL0BaXS"
      },
      "source": [
        "After you"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr9_0DnMBcFZ"
      },
      "source": [
        "# Comparison\n",
        "\n",
        "After you have completed the 3 models, compare the accuracy, ease of implementation, and inference speed (from cleaning, tokenization, till model compute) between the three models in mycourseville."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "colab-env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
