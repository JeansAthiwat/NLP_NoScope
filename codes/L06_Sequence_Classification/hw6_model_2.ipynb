{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8FRFIYMc5X"
      },
      "source": [
        "# HOMEWORK 6: TEXT CLASSIFICATION\n",
        "In this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n",
        "1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancle)\n",
        "2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming)\n",
        "\n",
        "We will focus only on the Object Classification task for this homework.\n",
        "\n",
        "In this homework, you are asked compare different text classification models in terms of accuracy and inference time.\n",
        "\n",
        "You will need to build 3 different models.\n",
        "\n",
        "1. A model based on tf-idf\n",
        "2. A model based on MUSE\n",
        "3. A model based on wangchanBERTa\n",
        "\n",
        "**You will be ask to submit 3 different files (.pdf from .ipynb) that does the 3 different models. Finally, answer the accuracy and runtime numbers in MCV.**\n",
        "\n",
        "This homework is quite free form, and your answer may vary. We hope that the processing during the course of this assignment will make you think more about the design choices in text classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRlx5Mb5zkXw",
        "outputId": "18d913e0-aa6d-435b-931d-591386cb4ba8"
      },
      "outputs": [],
      "source": [
        "# !wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv\n",
        "# !pip install pythainlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YprqbOPMc5a"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "heICP79cMc5e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from IPython.display import display\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#My import \n",
        "np.random.seed(42)\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaUf4PLMc5k"
      },
      "source": [
        "## Loading cleaned dataset from my folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "with open('template_cleaned_dataset.pkl', 'rb') as f:\n",
        "    dataset = pickle.load(f)\n",
        "\n",
        "# Extract tokenized text and labels\n",
        "label_2_num_map, num_2_label_map = dataset[\"label_2_num_map\"], dataset[\"num_2_label_map\"]\n",
        "train_texts, train_labels = dataset[\"train\"][\"input\"], dataset[\"train\"][\"label\"]\n",
        "val_texts, val_labels = dataset[\"val\"][\"input\"], dataset[\"val\"][\"label\"]\n",
        "test_texts, test_labels = dataset[\"test\"][\"input\"], dataset[\"test\"][\"label\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wql2YeU8qFQ6"
      },
      "source": [
        "# Model 2 MUSE\n",
        "\n",
        "Build a simple logistic regression model using features from the MUSE model.\n",
        "\n",
        "Which MUSE model will you use? Why?\n",
        "\n",
        "**Ans:** \n",
        "\n",
        "- I use sentence-transformers/use-cmlm-multilingual. as there are more likes and the other one doesn't have native support for hugging face.\n",
        "\n",
        "MUSE is typically used with tensorflow. However, there are some pytorch conversions made by some people.\n",
        "\n",
        "- https://huggingface.co/sentence-transformers/use-cmlm-multilingual\n",
        "- https://huggingface.co/dayyass/universal-sentence-encoder-multilingual-large-3-pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libs for MUSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "d3UtkpaLnctH"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jaf/anaconda3/envs/nlp/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'พอสม', 'ช่วงหลัง', 'ฉัน', 'เมื่อก่อน', 'เมื่อไร', 'ที่', 'ทำไม', 'หากว่า', 'เยอะ', 'เช่นดังก่อน', 'เช่นนี้', 'เมื่อคืน', 'เธอ', 'ใกล้', 'สั้น', 'จะ', 'ด้วยว่า', 'แห่งนั้น', 'สิ่งนั้น', 'แม้ว่า', 'ในช่วง', 'หากแม้นว่า', 'คราวไหน', 'ช่วงแรก', 'หนอย', 'พวกฉัน', 'พา', 'มัก', 'ตลอดถึง', 'ทั้งคน', 'คราวก่อน', 'ครั้งใด', 'ภายภาคหน้า', 'อย่างเดียว', 'ถึงเมื่อใด', 'ตั้ง', 'ไม่ค่อยเป็น', 'เพิ่มเติม', 'มากมาย', 'เยอะๆ', 'รวมถึง', 'พร้อมเพียง', 'ใหญ่ๆ', 'แท้', 'ในที่', 'คราวละ', 'ควร', 'ช่วงๆ', 'เอา', 'เป็นดัง', 'จวบกับ', 'เช่นดัง', 'จึง', 'หรือไม่', 'ประการใด', 'วันใด', 'ซึ่งกัน', 'แม้นว่า', 'คล้ายว่า', 'กระทั่ง', 'ต่อ', 'แห่งใด', 'เป็นต้นไป', 'ระหว่าง', 'กว่า', 'บ้าง', 'ดั่งกับว่า', 'เมื่อเย็น', 'คล้ายกัน', 'เสียนี่', 'เป็นที', 'นั้นไว', 'ง่ายๆ', 'รึว่า', 'ว่า', 'เป็นแต่', 'หลัง', 'บางกว่า', 'เคย', 'คราวนั้น', 'ดังกล่าว', 'ซะจนกระทั่ง', 'ถ้าจะ', 'พอเหมาะ', 'ช่วงนี้', 'ข้าพเจ้า', 'ด้วยกัน', 'ช่วงต่อไป', 'คงจะ', 'ด้วยประการฉะนี้', 'ที', 'เสียนี่กระไร', 'สุดๆ', 'มุ่ง', 'เห็น', 'ตั้งแต่', 'ทันใดนั้น', 'ถึงเมื่อไร', 'เกี่ยวกับ', 'เพียงเพื่อ', 'แห่งไหน', 'มันๆ', 'อื่นๆ', 'ดั่งเคย', 'เพื่อที่จะ', 'อันไหน', 'จำพวก', 'ฝ่าย', 'แต่ไหน', 'ไว้', 'เช่นกัน', 'พร้อมทั้ง', 'อดีต', 'ที่นี้', 'คงอยู่', 'จริงๆจังๆ', 'จนกว่า', 'หลาย', 'เมื่อคราวก่อน', 'กระนั้น', 'อยาก', 'ตามๆ', 'ดั่งกับ', 'แล้วกัน', 'ก็ต่อเมื่อ', 'มุ่งหมาย', 'ชาว', 'บางที่', 'ในระหว่าง', 'สิ้นกาลนาน', 'พวกกัน', 'บางคราว', 'พวกเธอ', 'จึงจะ', 'เช่นเมื่อ', 'ที่ใด', 'เป็นเพียงว่า', 'นั่นเอง', 'ช่วงถัดไป', 'สิ้น', 'เดียวกัน', 'และ', 'คุณ', 'กำหนด', 'ที่นั้น', 'ทุกครา', 'ได้', 'เท่านั้น', 'ยังโง้น', 'คิด', 'ได้แก่', 'เพิ่ม', 'อัน', 'ดั่ง', 'ด้วย', 'ประการฉะนี้', 'เกือบ', 'มุ่งเน้น', 'ก็จะ', 'ยังงี้', 'เข้า', 'ทันทีทันใด', 'ทีใด', 'หน่อย', 'คราวๆ', 'เก็บ', 'นานๆ', 'ค่อยๆ', 'ได้ที่', 'เช่น', 'ดั่งเก่า', 'ค่อนมาทาง', 'เช่นนั้น', 'นั้นๆ', 'โดย', 'ทั้งนั้น', 'กล่าว', 'สามารถ', 'อย่างที่', 'อย่างละ', 'วันไหน', 'ด้วยเหมือนกัน', 'ถึงอย่างไร', 'สมัย', 'กลุ่มก้อน', 'เอ็ง', 'เถิด', 'เผื่อจะ', 'ถึงบัดนี้', 'มั้ยล่ะ', 'เกี่ยวๆ', 'ข้างต้น', 'ถึงแม้จะ', 'เห็นจะ', 'พวกท่าน', 'จึงเป็น', 'มั้ยนั่น', 'ระยะ', 'กันดีกว่า', 'แห่ง', 'ให้ไป', 'แต่ทว่า', 'บัดดล', 'คราวหน้า', 'ทั้งๆ', 'ยืนยาว', 'จวบจน', 'นี้', 'เพียงพอ', 'เช่นก่อน', 'เกิด', 'เมื่อครั้ง', 'คราวหลัง', 'มึง', 'พื้นๆ', 'ใช่', 'พวกนี้', 'ตนเอง', 'ฯล', 'บางที', 'เช่นดังที่', 'นอก', 'พอๆ', 'ที่ว่า', 'จับ', 'ฝ่ายใด', 'ใหญ่', 'น่า', 'ไฉน', 'ที่ละ', 'ตลอด', 'ยิ่งเมื่อ', 'เมื่อวาน', 'เดียว', 'สมัยโน้น', 'อันได้แก่', 'ผิด', 'แม้', 'เพียงใด', 'ใต้', 'แต่ที่', 'ภายภาค', 'เปิดเผย', 'ช่วงที่', 'ส่ง', 'คราวโน้น', 'ปฏิบัติ', 'ทำๆ', 'พวกกู', 'อย่างนั้น', 'กลุ่มๆ', 'ขั้น', 'ปรากฏว่า', 'ช่วย', 'ก่อนหน้า', 'จนแม้', 'อันเนื่องมาจาก', 'แล้วเสร็จ', 'เปลี่ยนแปลง', 'เสียยิ่ง', 'ตลอดวัน', 'แล้ว', 'ทุกเมื่อ', 'จนบัดนี้', 'มิ', 'จรด', 'ข้างเคียง', 'ซึ่งก็คือ', 'ผ่านๆ', 'ๆ', 'หารือ', 'ยกให้', 'แต่', 'เป็นอัน', 'เสร็จสิ้น', 'เผื่อที่', 'นอกจากนั้น', 'ส่วนด้อย', 'ก็ตามแต่', 'แค่', 'ใหญ่โต', 'หมดสิ้น', 'ถูกต้อง', 'พวกแก', 'นับ', 'ใหม่ๆ', 'อย่างยิ่ง', 'แต่นั้น', 'น้อยกว่า', 'เสร็จกัน', 'พอ', 'เนื่องจาก', 'ถึง', 'ขาด', 'จวนจะ', 'ใช้', 'ไร', 'นิดๆ', 'พยายาม', 'สูงสุด', 'เป็นอันว่า', 'ยิ่งจะ', 'อันละ', 'แท้จริง', 'ขณะใดๆ', 'ยังงั้น', 'ทุกอย่าง', 'เต็มไปด้วย', 'ต่อกัน', 'ก็คือ', 'ที่แล้ว', 'เนี่ยเอง', 'ร่วมด้วย', 'ไง', 'ครั้งนี้', 'เรื่อย', 'ส่วนใหญ่', 'กันเถอะ', 'สู่', 'ครั้งหนึ่ง', 'ตลอดกาลนาน', 'จ้า', 'คง', 'หมด', 'คราวที่', 'จ๋า', 'ทั้งนั้นเพราะ', '\\ufeffๆ', 'ฉะนี้', 'อาจจะ', 'เสมือนกับ', 'เกิน', 'พอที่', 'พวกมัน', 'เมื่อครั้งก่อน', 'ไหนๆ', 'ทุกวัน', 'ซึ่งก็', 'อย่างมาก', 'ประกอบ', 'นับจากนั้น', 'การ', 'จนแม้น', 'ทำไร', 'บัดนี้', 'สบาย', 'เกี่ยวเนื่อง', 'ภาค', 'คล้าย', 'ทุกทาง', 'เขา', 'ละ', 'แต่ว่า', 'พูด', 'แต่อย่างใด', 'บางๆ', 'คราวหนึ่ง', 'ฯลฯ', 'ด้วยเหตุว่า', 'คือ', 'ครั้งๆ', 'นำ', 'เห็นควร', 'น่าจะ', 'พึ่ง', 'ลง', 'นักๆ', 'นาย', 'เร็วๆ', 'พอควร', 'กำลัง', 'จรดกับ', 'แต่เพียง', 'ครานี้', 'ร่วมกัน', 'บ่อยครั้ง', 'ทุกที', 'ถือว่า', 'ทัน', 'จนกระทั่ง', 'ล่าสุด', 'พอกัน', 'ต่างๆ', 'เพื่อ', 'เช่นที่', 'เลย', 'นับตั้งแต่', 'บ่อยๆ', 'นับแต่ที่', 'จวนเจียน', 'คำ', 'ก็ดี', 'ซึ่งกันและกัน', 'กำลังจะ', 'เสร็จแล้ว', 'เชื่อถือ', 'เกือบจะ', 'กระผม', 'ทั้งเป็น', 'ยิ่งขึ้น', 'นอกจากว่า', 'เรื่อยๆ', 'ปัจจุบัน', 'ทีๆ', 'ง่าย', 'พวกที่', 'ถึงแม้ว่า', 'ครั้งครา', 'สิ่ง', 'ค่อนข้าง', 'ที่ๆ', 'ทุกๆ', 'เมื่อคราวที่', 'เสียจนกระทั่ง', 'นู้น', 'อาจ', 'พอที', 'บางแห่ง', 'ยิ่ง', 'ไม่', 'ที่แท้จริง', 'จากนี้ไป', 'ยืนนาน', 'นอกเหนือจาก', 'ทําให้', 'ถูกๆ', 'ตลอดไป', 'ได้รับ', 'ฉะนั้น', 'ผิดๆ', 'กล่าวคือ', 'ตาม', 'นิดหน่อย', 'ทั้งหลาย', 'เสียแล้ว', 'กว้างๆ', 'นอกจาก', 'ใดๆ', 'อย่างใด', 'มิฉะนั้น', 'สำคัญ', 'ต่างก็', 'ถ้าหาก', 'ถือ', 'นั้น', 'พอจะ', 'ใครๆ', 'ด้วยที่', 'เพิ่ง', 'ก่อนๆ', 'บาง', 'เผื่อ', 'ปิด', 'เมื่อเช้า', 'เล่าว่า', 'ครบครัน', 'อย่างโน้น', 'ตน', 'ไม่ว่า', 'แห่งโน้น', 'ยอมรับ', 'เท่าที่', 'ยัง', 'รวด', 'หรือเปล่า', 'ค่อย', 'พวกนั้น', 'นับจากนี้', 'คล้ายกับว่า', 'อันที่จะ', 'กว้างขวาง', 'สูงกว่า', 'ส่วนเกิน', 'ครั้งหลัง', 'ยาก', 'ซึ่งๆ', 'ยิ่งแล้ว', 'เสมือนว่า', 'เป็น', 'จนตลอด', 'เผื่อว่า', 'เป็นๆ', 'รวมทั้ง', 'เฉพาะ', 'ดัง', 'จัง', 'จด', 'ให้แก่', 'ช่วงก่อน', 'กลุ่ม', 'วัน', 'นำมา', 'เท่าไร', 'ทุกอัน', 'หาความ', 'จู่ๆ', 'นิด', 'ไกล', 'ผู้ใด', 'เข้าใจ', 'ให้', 'พวกมึง', 'ทรง', 'จง', 'เพียงเพราะ', 'ระยะๆ', 'เสียด้วย', 'ล้วนจน', 'จัดให้', 'ด้วยเหตุเพราะ', 'ส่วนดี', 'อย่างๆ', 'เอง', 'นี่แหละ', 'พอตัว', 'ไป่', 'ใน', 'หนึ่ง', 'เป็นเพื่อ', 'ไม่เป็นไร', 'บอกว่า', 'นั่น', 'นี่นา', 'โต', 'ทุกตัว', 'ออก', 'มีแต่', 'กันและกัน', 'ตรง', 'เสียจน', 'ช่วงระหว่าง', 'แหละ', 'ภาคฯ', 'นะ', 'เช่นเคย', 'นี้แหล่', 'รับรอง', 'พวกเขา', 'แค่จะ', 'พบ', 'จำเป็น', 'ได้มา', 'เน้น', 'แก่', 'ที่สุด', 'เสียก่อน', 'นั่นแหละ', 'ด้วยเพราะ', 'ขณะ', 'เป็นต้นมา', 'เป็นที่', 'หลังจาก', 'เสียยิ่งนัก', 'อย่างเช่น', 'ยังคง', 'มา', 'จวบ', 'เต็มไปหมด', 'น้อย', 'ประมาณ', 'อย่างหนึ่ง', 'ตลอดเวลา', 'รับ', 'ให้ดี', 'ต่าง', 'ถึงจะ', 'รวมด้วย', 'เสร็จ', 'เหตุไร', 'อย่างไรก็ได้', 'ร่วม', 'รือว่า', 'อยู่', 'ซะ', 'ทว่า', 'เรียบ', 'คราวนี้', 'มอง', 'ความ', 'ที่ซึ่ง', 'จ๊ะ', 'เกี่ยวกัน', 'จำ', 'จน', 'ดังกับว่า', 'ตลอดทั่วทั้ง', 'เสียจนถึง', 'ด้วยเหตุนี้', 'ตามด้วย', 'ทั้งสิ้น', 'เชื่อมั่น', 'มั้ย', 'ตลอดทั่วถึง', 'บน', 'ครา', 'มิได้', 'คราที่', 'ขอ', 'เคยๆ', 'กันเอง', 'ภายนอก', 'พวกโน้น', 'มากกว่า', 'นี้เอง', 'มั๊ย', 'เห็นว่า', 'ทั้งที', 'อย่างดี', 'ข้าฯ', 'ยิ่งขึ้นไป', 'ในเมื่อ', 'คราว', 'พอแล้ว', 'ครับ', 'อย่างไรเสีย', 'ถ้า', 'เป็นเพียง', 'ฯ', 'ยังแต่', 'แต่เดิม', 'จังๆ', 'ช่วงนั้น', 'ครบ', 'ก่อนหน้านี้', 'ขณะหนึ่ง', 'บ่อยกว่า', 'เถอะ', 'ตลอดปี', 'บ่อย', 'จัดการ', 'ประการ', 'ขณะใด', 'นอกจากที่', 'จริงจัง', 'เหล่านั้น', 'นอกเหนือ', 'ขวางๆ', 'เช่นดังว่า', 'แค่ว่า', 'พร้อมกัน', 'ทั่ว', 'ตรงๆ', 'ยิ่งนัก', 'มัน', 'กู', 'นับแต่นั้น', 'จะได้', 'อันใด', 'เมื่อวันวาน', 'บางครั้ง', 'ค่อยไปทาง', 'เพื่อว่า', 'จัดทำ', 'เช่นดังเก่า', 'สั้นๆ', 'เหตุผล', 'ปรับ', 'ใช่ไหม', 'จริงๆ', 'ไม่ค่อยจะ', 'เชื่อ', 'มั้ยเนี่ย', 'แค่นี้', 'ทั้ง', 'ช่วงท้าย', 'หากแม้', 'ทํา', 'จัด', 'แก', 'ปรากฏ', 'สมัยนั้น', 'คล้ายกับ', 'ณ', 'นั่นไง', 'หากแม้น', 'เห็นแก่', 'จนทั่ว', 'เท่ากับ', 'ยาว', 'ราย', 'สําหรับ', 'หาใช่', 'ค่อนข้างจะ', 'เป็นแต่เพียง', 'ครั้งนั้น', 'ยก', 'มาก', 'เพื่อที่', 'หมดกัน', 'ส่วนใด', 'จัดหา', 'ที่จริง', 'พอดี', 'เป็นด้วย', 'นำพา', 'ให้แด่', 'เหตุ', 'ก็ตาม', 'อันจะ', 'ทั้งมวล', 'ช้า', 'ตนฯ', 'ช้าๆ', 'เริ่ม', 'ข้างๆ', 'ประการหนึ่ง', 'ครัน', 'ไกลๆ', 'เปลี่ยน', 'เสีย', 'หน', 'เล็กน้อย', 'ใคร่จะ', 'นี่', 'สมัยก่อน', 'จนเมื่อ', 'จัดงาน', 'สิ่งใด', 'เหตุนี้', 'แต่ละ', 'แค่เพียง', 'อย่างไหน', 'ไป', 'ทุกคน', 'เต็มๆ', 'ถึงแก่', 'จนถึง', 'สูงๆ', 'ล้วน', 'ขณะเดียวกัน', 'พึง', 'ใคร่', 'คราใด', 'มองว่า', 'เกี่ยวข้อง', 'ตลอดมา', 'ทุก', 'ครั้งละ', 'ด้วยเหตุนั้น', 'เขียน', 'บัดเดี๋ยวนี้', 'ถูก', 'รือ', 'แต่ถ้า', 'ภายใต้', 'คราวใด', 'ทุกคราว', 'ถึงบัดนั้น', 'ภาย', 'ครั้งที่', 'เหล่านี้', 'ครั้งไหน', 'จริง', 'แต่จะ', 'ส่วนนั้น', 'หรือ', 'ยังไง', 'แยะ', 'ขณะที่', 'อาจเป็นด้วย', 'จากนั้น', 'บางขณะ', 'เพราะว่า', 'เพิ่งจะ', 'เพียง', 'กลับ', 'ต้อง', 'นางสาว', 'ทั้งปวง', 'ตลอดทั้ง', 'ขึ้น', 'ขณะนี้', 'อันที่จริง', 'เป็นอันมาก', 'รึ', 'คล้ายกันกับ', 'ทุกหน', 'ไหน', 'อย่าง', 'แบบ', 'นับแต่นี้', 'เนี่ย', 'ตามแต่', 'จวน', 'เช่นใด', 'ตลอดระยะเวลา', 'ภายใน', 'ไม่ใช่', 'ข้างล่าง', 'โตๆ', 'เหตุนั้น', 'ผู้', 'ช้านาน', 'เฉยๆ', 'นาน', 'ที่ไหน', 'คราไหน', 'กันนะ', 'ดังกับ', 'ทีละ', 'ประสบ', 'เชื่อว่า', 'แห่งนี้', 'แค่ไหน', 'ผ่าน', 'ยาวนาน', 'หรือไง', 'ที่แท้', 'เมื่อคราว', 'ได้แต่', 'เหล่า', 'เป็นการ', 'จากนี้', 'เหลือ', 'ก็ได้', 'ซะจนถึง', 'เล็ก', 'ซึ่ง', 'ยิ่งกว่า', 'ด้วยเช่นกัน', 'เสียนั่นเอง', 'คิดว่า', 'ด้วยเหตุที่', 'พร้อมกับ', 'เมื่อใด', 'แต่ต้อง', 'เหลือเกิน', 'นาง', 'สุด', 'นัก', 'เช่นไร', 'จ้ะ', 'ทาง', 'นอกจากนี้', 'วันนี้', 'มักจะ', 'เรียก', 'เฉกเช่น', 'อีก', 'อันที่', 'ตลอดทั่ว', 'ตลอดกาล', 'ดังเคย', 'สืบเนื่อง', 'ซะก่อน', 'ข้างบน', 'พร้อมด้วย', 'กันดีไหม', 'นํา', 'ข้า', 'ซึ่งได้แก่', 'เกือบๆ', 'ที่ได้', 'ส่วนที่', 'ครั้งกระนั้น', 'ทีเดียว', 'สูงส่ง', 'ทุกชิ้น', 'ยืนยง', 'พอเพียง', 'แม้แต่', 'วันนั้น', 'บัดนั้น', 'เพราะฉะนั้น', 'แรก', 'พวกนู้น', 'อย่างไร', 'นี่แน่ะ', 'แยะๆ', 'ขวาง', 'กันไหม', 'มิใช่', 'ส่วนน้อย', 'พร้อมที่', 'อันๆ', 'ครานั้น', 'คุณๆ', 'ขณะนั้น', 'กัน', 'ผล', 'เพียงแค่', 'รวม', 'มั้ยนะ', 'เสร็จสมบูรณ์', 'ครั้งหลังสุด', 'เกินๆ', 'ถึงเมื่อ', 'เปิด', 'เป็นเพราะ', 'รวดเร็ว', 'เช่นที่เคย', 'ดังเก่า', 'ทันที', 'สิ่งนี้', 'เยอะแยะ', 'ใกล้ๆ', 'ครั้งก่อน', 'พวกคุณ', 'ทุกที่', 'ทั้งนั้นด้วย', 'รวมๆ', 'ให้มา', 'ย่อม', 'สมัยนี้', 'พอสมควร', 'พบว่า', 'แสดงว่า', 'ร่วมมือ', 'เพียงแต่', 'อย่างไรก็', 'ถึงแม้', 'แสดง', 'ใคร', 'แต่ก็', 'เฉย', 'นี่เอง', 'ด้าน', 'ภายหน้า', 'ของ', 'ทุกครั้ง', 'เป็นเพราะว่า', 'แต่ไร', 'เพียงไหน', 'แล้วแต่', 'เมื่อนี้', 'ทุกแห่ง', 'กว้าง', 'เราๆ', 'ช่วงหน้า', 'นี่ไง', 'เป็นอันๆ', 'ส่วนมาก', 'ส่วน', 'หรือยัง', 'อย่างนี้', 'ครบถ้วน', 'ค่อน', 'รวมกัน', 'ก่อน', 'ก็แค่', 'ตลอดศก', 'เพราะ', 'ก็ตามที', 'เรา', 'แค่นั้น', 'อนึ่ง', 'เช่นที่ว่า', 'ตามที่', 'น่ะ', 'มี', 'คะ', 'ล้วนแต่', 'กับ', 'อย่างน้อย', 'เช่นเดียวกับ', 'แต่ก่อน', 'พวก', 'แก้ไข', 'เช่นนั้นเอง', 'เท่าไหร่', 'เช่นเดียวกัน', 'กระทำ', 'เล็กๆ', 'ยังจะ', 'ทุกวันนี้', 'ที่แห่งนั้น', 'เมื่อนั้น', 'เท่ากัน', 'หาก', 'จัดตั้ง', 'คราหนึ่ง', 'ทุกสิ่ง', 'ใหม่', 'นอกนั้น', 'ทั้งหมด', 'จนขณะนี้', 'เท่าใด', 'ยิ่งใหญ่', 'เสียนั่น', 'เป็นที่สุด', 'ช่วง', 'สิ่งไหน', 'ต่างหาก', 'พร้อม', 'เป็นอาทิ', 'ทำให้', 'อะไร', 'เมื่อไหร่', 'ทีไร', 'ยิ่งจน', 'จาก', 'เท่านี้', 'ซะจน', 'อื่น', 'ข้าง', 'ภายหลัง', 'แม้กระทั่ง', 'ตลอดจน', 'ทั้งตัว', 'บางครา', 'จัดแจง', 'อาจเป็น', 'น้อยๆ', 'ครั้ง', 'ทีเถอะ', 'ค่ะ', 'นับแต่', 'นู่น', 'ย่อย', 'เพื่อให้', 'ครั้งคราว', 'สูง', 'นั่นเป็น', 'หรือไร', 'บอก', 'บอกแล้ว', 'เร็ว', 'ก็', 'ก็แล้วแต่', 'เท่า', 'หนอ', 'เป็นต้น', 'แต่เมื่อ', 'ทั้งที่', 'ทั้งนี้', 'เมื่อ', 'ไม่ค่อย', 'ยืนยัน', 'เพียงไร', 'ยอม'}\n"
          ]
        }
      ],
      "source": [
        "from pythainlp.tokenize import word_tokenize\n",
        "from pythainlp.corpus.common import thai_stopwords\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "print(set(thai_stopwords()))\n",
        "\n",
        "MODEL_NAME = 'sentence-transformers/use-cmlm-multilingual'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'TfidfVectorizer' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[5], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m test_texts \u001b[38;5;241m=\u001b[39m [text\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m test_texts]\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# Initialize and fit TF-IDF Vectorizer on training data\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m vectorizer \u001b[38;5;241m=\u001b[39m \u001b[43mTfidfVectorizer\u001b[49m(tokenizer\u001b[38;5;241m=\u001b[39mpythainlp_tokenizer, max_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m, min_df\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     15\u001b[0m X_train_tfidf \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mfit_transform(train_texts)  \u001b[38;5;66;03m# Fit and transform training data\u001b[39;00m\n\u001b[1;32m     17\u001b[0m X_val_tfidf \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(val_texts)  \u001b[38;5;66;03m# Transform validation data\u001b[39;00m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'TfidfVectorizer' is not defined"
          ]
        }
      ],
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch import nn\n",
        "\n",
        "class ClassifierHead(nn.Module):\n",
        "    def __init__(self, in_features=768, out_features=len(label_2_num_map), dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(in_features, 256)\n",
        "        self.norm = nn.LayerNorm(out_features)\n",
        "        self.activation = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear2 = nn.Linear(256, out_features)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.linear1(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.activation(x)\n",
        "        x = self.dropout(x)\n",
        "        x = self.linear2(x)\n",
        "        return x\n",
        "\n",
        "class TrueObjectClassifier(pl.LightningModule):\n",
        "    def __init__(self, model_name, num_labels, lr=2e-5):\n",
        "        super().__init__()\n",
        "        self.encoder = SentenceTransformer(model_name)\n",
        "        "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initializing the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = SentenceTransformer(MODEL_NAME)\n",
        "embeddings = model.encode(sentences)\n",
        "print(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDHfX377rnp_"
      },
      "source": [
        "# Model 3 WangchanBERTa\n",
        "\n",
        "We ask you to train a WangchanBERTa-based model.\n",
        "\n",
        "We recommend you use the thaixtransformers fork (which we used in the PoS homework).\n",
        "https://github.com/PyThaiNLP/thaixtransformers\n",
        "\n",
        "The structure of the code will be very similar to the PoS homework. You will also find the huggingface [tutorial](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) useful. Or you can also add a softmax layer by yourself just like in the previous homework.\n",
        "\n",
        "Which WangchanBERTa model will you use? Why? (Don't forget to clean your text accordingly).\n",
        "\n",
        "**Ans:**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI8SvILyub0m"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6D7qsVL0BaXS"
      },
      "source": [
        "After you"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr9_0DnMBcFZ"
      },
      "source": [
        "# Comparison\n",
        "\n",
        "After you have completed the 3 models, compare the accuracy, ease of implementation, and inference speed (from cleaning, tokenization, till model compute) between the three models in mycourseville."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "nlp",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
